[{"id":"e948586c90ca41ff51fdf8e035fa5502","title":"fastcache源码分析","content":"fastcache \n特性:\n快速, 高性能, 多 CPU上 可扩展\n线程安全.  多个 goroutine 可以同时读写一个cache 实例\nfastcache 设计为 在存储大量的 entry 的场景下 GC free\nfastcache 当 缓存数量达到阈值时 可以自动 清理 old entry \n简单的API\n简单的源代码\ncacheData 可以 保存到文件(从文件中加载)\n在 Google App Engine 上工作\n\n\n\n\n\nfastcache 的一些概念bucket:  分桶,  默认 cache中有 512个 bucket,  减少锁粒度 (bucket 内部 会维护  lock, hashmap, chunk, stat(统计信息))\nchunks: [][]byte  用于 存储 kv 的 一个 ringbuffer.  这里二维数组 用来模拟 循环 数组.(减少扩容操作.)\n\n数据结构\nfastcache 代码比较简单. \n\n// Cache is a fast thread-safe inmemory cache optimized for big number\n// of entries.\n//\n// It has much lower impact on GC comparing to a simple `map[string][]byte`.\n//\n// Use New or LoadFromFile* for creating new cache instance.\n// Concurrent goroutines may call any Cache methods on the same cache instance.\n//\n// Call Reset when the cache is no longer needed. This reclaims the allocated\n// memory.\ntype Cache struct &#123;\n\tbuckets [bucketsCount]bucket // bucketCount default 512\n\n\tbigStats BigStats\n&#125;\n\n// 一个 bucket\ntype bucket struct &#123;\n\tmu sync.RWMutex\n\n\t// chunks is a ring buffer with encoded (k, v) pairs.\n\t// It consists of 64KB chunks.\n\t// 每个 块是64K, 也就是 chunkSize\n\tchunks [][]byte\n\n\t// m maps hash(k) to idx of (k, v) pair in chunks.\n\t// key: hash(key) value:  idx, value 在 chunk中的偏移量(byte) gen+idx\n\tm map[uint64]uint64\n\n\t// idx points to chunks for writing the next (k, v) pair.\n\t// 用于计算下一个chunk\n\tidx uint64 // 下一次 要写入的 位置\n\n\t// gen is the generation of chunks.\n\tgen uint64 // chunk 的循环次数\n\n\t// 一些统计信息\n\tgetCalls    uint64\n\tsetCalls    uint64\n\tmisses      uint64\n\tcollisions  uint64\n\tcorruptions uint64\n&#125;\n\n\n\n常用操作1. New\n// New returns new cache with the given maxBytes capacity in bytes.\n//\n// maxBytes must be smaller than the available RAM size for the app,\n// since the cache holds data in memory.\n//\n// If maxBytes is less than 32MB, then the minimum cache capacity is 32MB.   - 每个 bucket 最小  64K(一个chunk)\nfunc New(maxBytes int) *Cache &#123;\n\t// param check\n\tvar c Cache\n\t// 如果 maxByte / bucketCount 有余数的话, 把超出的部分 分填到  每个 bucket\n\tmaxBucketBytes := uint64((maxBytes + bucketsCount - 1) / bucketsCount)\n\tfor i := range c.buckets[:] &#123;\n\t\tc.buckets[i].Init(maxBucketBytes)\n\t&#125;\n\treturn &amp;c\n&#125;\n\n\n// bucket 初始化\nfunc (b *bucket) Init(maxBytes uint64) &#123;\n\t// param check ...\n\t// 同样的, 将多余的 字节分散到 每个  chunk\n\tmaxChunks := (maxBytes + chunkSize - 1) / chunkSize\n\tb.chunks = make([][]byte, maxChunks)\n\tb.m = make(map[uint64]uint64)\n\tb.Reset()\n&#125;\n\n\n\n\n2. Set\n// Set stores (k, v) in the cache.\n//\n// Get must be used for reading the stored entry.\n//\n// 当 发生 overflow  或者  不太可能的 hash Collision  时, entry  将会被丢弃 \n// - 如果 经常发生 entry丢失, 那么应该  调用 New()， 调大 最大字节数\n//\n// 超过64KB(chunkSize) 不能用 Set 进行存储,应该调用 SetBig.\n//\n// k and v contents may be modified after returning from Set.\nfunc (c *Cache) Set(k, v []byte) &#123;\n\th := xxhash.Sum64(k)\n\tidx := h % bucketsCount // 这里 可以 使用  位运算:  h &amp; (bucketsCount - 1)\n\tc.buckets[idx].Set(k, v, h)\n&#125;\n\n\n\nbucket.Set()\n\n// 2byte | 2byte | nbyte | nbyte\n// keylen|valLen|key|value\nfunc (b *bucket) Set(k, v []byte, h uint64) &#123;\n\tatomic.AddUint64(&amp;b.setCalls, 1)\n\tif len(k) >= (1&lt;&lt;16) || len(v) >= (1&lt;&lt;16) &#123;\n\t\t// Too big key or value - its length cannot be encoded\n\t\t// with 2 bytes (see below). Skip the entry.\n\t\treturn\n\t&#125;\n\t// 大端存储\n\tvar kvLenBuf [4]byte\n\tkvLenBuf[0] = byte(uint16(len(k)) >> 8)\n\tkvLenBuf[1] = byte(len(k))\n\tkvLenBuf[2] = byte(uint16(len(v)) >> 8)\n\tkvLenBuf[3] = byte(len(v))\n\tkvLen := uint64(len(kvLenBuf) + len(k) + len(v)) // 要写入的数据的长度\n\tif kvLen >= chunkSize &#123;\n\t\t// Do not store too big keys and values, since they do not\n\t\t// fit a chunk.\n\t\treturn\n\t&#125;\n\n\t// chunk\n\t// chunkIdx:  chunk\n\t// 0:[000000000000000000]  // 64K\n\t// 1:[000000000000000000]\n\t// 2:[000000000000000000]\n\t// 3:[000000000000000000]\n\tchunks := b.chunks\n\tneedClean := false\n\tb.mu.Lock()\n\tidx := b.idx\n\tidxNew := idx + kvLen\n\tchunkIdx := idx / chunkSize\n\tchunkIdxNew := idxNew / chunkSize\n\tif chunkIdxNew > chunkIdx &#123; //当前 chunk 放不下 该 kv, 往下一个 chunk 写 或者 循环写\n\t\tif chunkIdxNew >= uint64(len(chunks)) &#123; // 循环写\n\t\t\tidx = 0\n\t\t\tidxNew = kvLen\n\t\t\tchunkIdx = 0\n\t\t\tb.gen++                              // 循环次数\n\t\t\tif b.gen&amp;((1&lt;&lt;genSizeBits)-1) == 0 &#123; // b.gen&amp;maxGen == 0, 说明 b.gen == maxGen\n\t\t\t\tb.gen++ // 此处 ++ 的目的是为了 循环取余\n\t\t\t&#125;\n\t\t\tneedClean = true // 当 chunks 满了, 需要 从 头chunks[0]开始写, 需要把当前 chunk 全部清空.(清空  b.m)\n\t\t&#125; else &#123; // 大部分场景\n\t\t\tidx = chunkIdxNew * chunkSize\n\t\t\tidxNew = idx + kvLen\n\t\t\tchunkIdx = chunkIdxNew\n\t\t&#125;\n\t\tchunks[chunkIdx] = chunks[chunkIdx][:0] // 将该chunk清空\n\t&#125;\n\tchunk := chunks[chunkIdx]\n\t// 首次初始化 , chunk[i] == nil\n\tif chunk == nil &#123;\n\t\tchunk = getChunk() // 性能关键点: 堆外分配内存\n\t\tchunk = chunk[:0]\n\t&#125;\n\t// 正式写入数据\n\tchunk = append(chunk, kvLenBuf[:]...)\n\tchunk = append(chunk, k...)\n\tchunk = append(chunk, v...)\n\tchunks[chunkIdx] = chunk\n\tb.m[h] = idx | (b.gen &lt;&lt; bucketSizeBits) // gen + idx\n\tb.idx = idxNew\n\tif needClean &#123;\n\t\t// 清理 覆盖的  overflow 的 chunk(遍历 b.m,逐个 判断 清理)\n\t\tb.cleanLocked()\n\t&#125;\n\tb.mu.Unlock()\n&#125;\n\ngen: 循环次数, gen 在什么情况下 会 + 1?\nbucket.gen 在初始化时默认值是 1,  当 chunks 写满后, gen 会 +1, 表示循环次数.  当 gen  达到 maxGen(1 &lt;&lt; 24 -1) 后, gen 复位为1.\n了解了 gen: 相信下面这几个条件就可以看懂了:\n\n\n\n\n\n\n\n\n\ngen &#x3D;&#x3D; bGen &amp;&amp; idx &lt; b.idx: 在一个循环内gen+1 &#x3D;&#x3D; bGen &amp;&amp; idx &gt;&#x3D; b.idx: 不在一个循环内,数据没有覆盖gen &#x3D;&#x3D; maxGen &amp;&amp; bGen &#x3D;&#x3D; 1 &amp;&amp; idx &gt;&#x3D; b.idx: 重新开始循环,数据没有覆盖\n当 chunk 写满了, 使用下一个 chunk 时, 使用 getChunk() 初始化 chunk ?\ngetChunk() 在堆外分配内存, 而不是直接在堆上 分配, 减少GC压力. 这是 fastcache 高性能的一个关键点.\n在 malloc_mmap.go 维护了一个  chunk 池子,可以复用 chunk.\n\nconst chunksPerAlloc = 1024\n\nvar (\n\t//这里  相当于一个 chunk 池子\n\tfreeChunks     []*[chunkSize]byte\n\tfreeChunksLock sync.Mutex\n)\n\n// 预分配  chunkSize*chunksPerAlloc 的 字节数组,(offheap), 通过 mmap\n// 每次 getChunk 从中截取  chunkSize 大小的  []byte\nfunc getChunk() []byte &#123;\n\tfreeChunksLock.Lock()\n\t// 如果 freechunk 没有了, 从堆外申请.\n\tif len(freeChunks) == 0 &#123;\n\t\t// Allocate offheap memory, so GOGC won't take into account cache size.\n\t\t// This should reduce free memory waste.\n\t\t// 堆外申请内存, GOGC 不会考虑 缓存大小, 这应该会减少 free memory 浪费.\n\t\tdata, err := unix.Mmap(-1, 0, chunkSize*chunksPerAlloc, unix.PROT_READ|unix.PROT_WRITE, unix.MAP_ANON|unix.MAP_PRIVATE)\n\t\tif err != nil &#123;\n\t\t\tpanic(fmt.Errorf(\"cannot allocate %d bytes via mmap: %s\", chunkSize*chunksPerAlloc, err))\n\t\t&#125;\n\t\tfor len(data) > 0 &#123;\n\t\t\tp := (*[chunkSize]byte)(unsafe.Pointer(&amp;data[0]))\n\t\t\tfreeChunks = append(freeChunks, p)\n\t\t\tdata = data[chunkSize:]\n\t\t&#125;\n\t&#125;\n\tn := len(freeChunks) - 1\n\tp := freeChunks[n]\n\tfreeChunks[n] = nil\n\tfreeChunks = freeChunks[:n]\n\tfreeChunksLock.Unlock()\n\treturn p[:]\n&#125;\n\n\n\n\n\n\n\n\n3. Getcache.Get()\n\n// Get appends value by the key k to dst and returns the result.\n//\n// Get allocates new byte slice for the returned value if dst is nil.\n//\n// Get returns only values stored in c via Set.\n//\n// k contents may be modified after returning from Get.\nfunc (c *Cache) Get(dst, k []byte) []byte &#123;\n\th := xxhash.Sum64(k)\n\tidx := h % bucketsCount // 这里 可以 优化为 位运算.\n\tdst, _ = c.buckets[idx].Get(dst, k, h, true)\n\treturn dst\n&#125;\n\n\n\n\nbucket.Get()\nfunc (b *bucket) Get(dst, k []byte, h uint64, returnDst bool) ([]byte, bool) &#123;\n\tatomic.AddUint64(&amp;b.getCalls, 1)\n\tfound := false\n\tchunks := b.chunks\n\tb.mu.RLock()\n\tv := b.m[h] // 读取 value， 从中解析出  idx &amp; gen\n\tbGen := b.gen &amp; ((1 &lt;&lt; genSizeBits) - 1)\n\tif v > 0 &#123;\n\t\tgen := v >> bucketSizeBits\n\t\tidx := v &amp; ((1 &lt;&lt; bucketSizeBits) - 1)\n\t\t// gen == bGen &amp;&amp; idx &lt; b.idx: 在一个循环内\n\t\t// gen+1 == bGen &amp;&amp; idx >= b.idx: 不在一个循环内,数据没有覆盖\n\t\t// gen == maxGen &amp;&amp; bGen == 1 &amp;&amp; idx >= b.idx: 重新开始循环,数据没有覆盖\n\t\tif gen == bGen &amp;&amp; idx &lt; b.idx || gen+1 == bGen &amp;&amp; idx >= b.idx || gen == maxGen &amp;&amp; bGen == 1 &amp;&amp; idx >= b.idx &#123;\n\t\t\tchunkIdx := idx / chunkSize\n\t\t\tif chunkIdx >= uint64(len(chunks)) &#123;\n\t\t\t\t// Corrupted data during the load from file. Just skip it.\n\t\t\t\t// 文件加载时损坏的数据,跳过\n\t\t\t\tatomic.AddUint64(&amp;b.corruptions, 1)\n\t\t\t\tgoto end\n\t\t\t&#125;\n\t\t\tchunk := chunks[chunkIdx]\n\t\t\tidx %= chunkSize\n\t\t\tif idx+4 >= chunkSize &#123;\n\t\t\t\t// Corrupted data during the load from file. Just skip it.\n\t\t\t\t// 文件加载时损坏的数据,跳过\n\t\t\t\tatomic.AddUint64(&amp;b.corruptions, 1)\n\t\t\t\tgoto end\n\t\t\t&#125;\n\t\t\tkvLenBuf := chunk[idx : idx+4]\n\t\t\tkeyLen := (uint64(kvLenBuf[0]) &lt;&lt; 8) | uint64(kvLenBuf[1])\n\t\t\tvalLen := (uint64(kvLenBuf[2]) &lt;&lt; 8) | uint64(kvLenBuf[3])\n\t\t\tidx += 4\n\t\t\tif idx+keyLen+valLen >= chunkSize &#123;\n\t\t\t\t// Corrupted data during the load from file. Just skip it.\n\t\t\t\t// 文件加载时损坏的数据,跳过\n\t\t\t\tatomic.AddUint64(&amp;b.corruptions, 1)\n\t\t\t\tgoto end\n\t\t\t&#125;\n\t\t\t// hash 值相同, 判断 key 是否一致\n\t\t\tif string(k) == string(chunk[idx:idx+keyLen]) &#123;\n\t\t\t\t// dst = chunk[idx+keyLen:idx+valLen]\n\t\t\t\tidx += keyLen\n\t\t\t\tif returnDst &#123;\n\t\t\t\t\tdst = append(dst, chunk[idx:idx+valLen]...)\n\t\t\t\t&#125;\n\t\t\t\tfound = true\n\t\t\t&#125; else &#123;\n\t\t\t\t// 发生hash collision\n\t\t\t\tatomic.AddUint64(&amp;b.collisions, 1)\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\nend:\n\tb.mu.RUnlock()\n\tif !found &#123;\n\t\tatomic.AddUint64(&amp;b.misses, 1)\n\t&#125;\n\treturn dst, found\n&#125;\n\n\n\n\n\n\n4. Deldel 的 逻辑比较简单. 不处理 chunk, 直接 在 bucket的hash表m中进行删除\n\n\nfunc (b *bucket) Del(h uint64) &#123;\n\tb.mu.Lock()\n\tdelete(b.m, h)\n\tb.mu.Unlock()\n&#125;\n\n\n\n\nfile  Load | Save\n源码文件\n\nfile Save, 将缓存中的内容 按照一定的协议持久化写入文件中. 这个操作也比较常见.(比如 proto)\nfileSave:  多携程 并发的写入 file, 多个协程 根据 bucket 分任务, 分别 写入文件,加速 写入 效率.\n\n// SaveToFile atomically saves cache data to the given filePath using a single\n// CPU core.\n// 利用 但 cpu 保存  缓存数据到 filePath\n//\n// SaveToFile may be called concurrently with other operations on the cache.\n//\n// The saved data may be loaded with LoadFromFile*.\n//\n// See also SaveToFileConcurrent for faster saving to file.\nfunc (c *Cache) SaveToFile(filePath string) error &#123;\n\treturn c.SaveToFileConcurrent(filePath, 1)\n&#125;\n\n// SaveToFileConcurrent saves cache data to the given filePath using concurrency\n// CPU cores.\n// 利用 多 cpu 将 缓存数据并发保存到文件.\n// 这里参数的  filePath 也是一个 目录\n//\n// SaveToFileConcurrent may be called concurrently with other operations\n// on the cache.\n//\n// The saved data may be loaded with LoadFromFile*.\n//\n// See also SaveToFile.\nfunc (c *Cache) SaveToFileConcurrent(filePath string, concurrency int) error &#123;\n\t// Create dir if it doesn't exist.\n\tdir := filepath.Dir(filePath)\n\tif _, err := os.Stat(dir); err != nil &#123;\n\t\tif !os.IsNotExist(err) &#123;\n\t\t\treturn fmt.Errorf(\"cannot stat %q: %s\", dir, err)\n\t\t&#125;\n\t\tif err := os.MkdirAll(dir, 0755); err != nil &#123;\n\t\t\treturn fmt.Errorf(\"cannot create dir %q: %s\", dir, err)\n\t\t&#125;\n\t&#125;\n\n\t// Save cache data into a temporary directory.\n\ttmpDir, err := ioutil.TempDir(dir, \"fastcache.tmp.\")\n\tif err != nil &#123;\n\t\treturn fmt.Errorf(\"cannot create temporary dir inside %q: %s\", dir, err)\n\t&#125;\n\tdefer func() &#123;\n\t\tif tmpDir != \"\" &#123;\n\t\t\t_ = os.RemoveAll(tmpDir)\n\t\t&#125;\n\t&#125;()\n\tgomaxprocs := runtime.GOMAXPROCS(-1)\n\tif concurrency &lt;= 0 || concurrency > gomaxprocs &#123;\n\t\tconcurrency = gomaxprocs\n\t&#125;\n\t//  并发保存数据到 文件\n\tif err := c.save(tmpDir, concurrency); err != nil &#123;\n\t\treturn fmt.Errorf(\"cannot save cache data to temporary dir %q: %s\", tmpDir, err)\n\t&#125;\n\n\t// Remove old filePath contents, since os.Rename may return\n\t// error if filePath dir exists.\n\tif err := os.RemoveAll(filePath); err != nil &#123;\n\t\treturn fmt.Errorf(\"cannot remove old contents at %q: %s\", filePath, err)\n\t&#125;\n\t// 相当于 move\n\tif err := os.Rename(tmpDir, filePath); err != nil &#123;\n\t\treturn fmt.Errorf(\"cannot move temporary dir %q to %q: %s\", tmpDir, filePath, err)\n\t&#125;\n\ttmpDir = \"\"\n\treturn nil\n&#125;\n\n\n\n保存数据到文件. 这也是一种常见的多协程 编程模式. 利用协程和 chan.\n\nfunc (c *Cache) save(dir string, workersCount int) error &#123;\n\tif err :&#x3D; saveMetadata(c, dir); err !&#x3D; nil &#123;\n\t\treturn err\n\t&#125;\n\n\t&#x2F;&#x2F; Save buckets by workersCount concurrent workers.\n\tworkCh :&#x3D; make(chan int, workersCount)\n\tresults :&#x3D; make(chan error)\n\tfor i :&#x3D; 0; i &lt; workersCount; i++ &#123;\n\t\tgo func(workerNum int) &#123;\n\t\t\tresults &lt;- saveBuckets(c.buckets[:], workCh, dir, workerNum)\n\t\t&#125;(i)\n\t&#125;\n\t&#x2F;&#x2F; 给 work 分发工作. 传 bucketIndex. workCh 相当于一个任务队列.\n\t&#x2F;&#x2F; Feed workers with work\n\tfor i :&#x3D; range c.buckets[:] &#123;\n\t\tworkCh &lt;- i\n\t&#125;\n\tclose(workCh)\n\n\t&#x2F;&#x2F; Read results.  -- 如果使用 waitGroup 该怎么写呢?\n\tvar err error\n\tfor i :&#x3D; 0; i &lt; workersCount; i++ &#123;\n\t\tresult :&#x3D; &lt;-results\n\t\tif result !&#x3D; nil &amp;&amp; err &#x3D;&#x3D; nil &#123;\n\t\t\terr &#x3D; result\n\t\t&#125;\n\t&#125;\n\treturn err\n&#125;\n\nfunc saveBuckets(buckets []bucket, workCh &lt;-chan int, dir string, workerNum int) error &#123;\n\t&#x2F;&#x2F; 一个 协程 一个文件.\n\tdataPath :&#x3D; fmt.Sprintf(&quot;%s&#x2F;data.%d.bin&quot;, dir, workerNum)\n\tdataFile, err :&#x3D; os.Create(dataPath)\n\tif err !&#x3D; nil &#123;\n\t\treturn fmt.Errorf(&quot;cannot create %q: %s&quot;, dataPath, err)\n\t&#125;\n\tdefer func() &#123;\n\t\t_ &#x3D; dataFile.Close()\n\t&#125;()\n\t&#x2F;&#x2F; 数据进行压缩.\n\tzw :&#x3D; snappy.NewBufferedWriter(dataFile)\n\tfor bucketNum :&#x3D; range workCh &#123;\n\t\t&#x2F;&#x2F; save BucketNum\n\t\tif err :&#x3D; writeUint64(zw, uint64(bucketNum)); err !&#x3D; nil &#123;\n\t\t\treturn fmt.Errorf(&quot;cannot write bucketNum&#x3D;%d to %q: %s&quot;, bucketNum, dataPath, err)\n\t\t&#125;\n\t\t&#x2F;&#x2F; save BucketData\n\t\tif err :&#x3D; buckets[bucketNum].Save(zw); err !&#x3D; nil &#123;\n\t\t\treturn fmt.Errorf(&quot;cannot save bucket[%d] to %q: %s&quot;, bucketNum, dataPath, err)\n\t\t&#125;\n\t&#125;\n\tif err :&#x3D; zw.Close(); err !&#x3D; nil &#123;\n\t\treturn fmt.Errorf(&quot;cannot close snappy.Writer for %q: %s&quot;, dataPath, err)\n\t&#125;\n\treturn nil\n&#125;\n\n\n\nLoadFile:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[参考]fastcache内部原理讲解及核心源码分析golang本地缓存(bigcache&#x2F;freecache&#x2F;fastcache等)选型对比及原理总结\n","slug":"fastcache源码解析","date":"2023-05-06T07:52:35.000Z","categories_index":"","tags_index":"go,cache,fastcache","author_index":"majm"},{"id":"7b7fae18844a9a83dfd9701a806d24e8","title":"大数据-数据仓库大宽表","content":"什么是大宽表, 为什么要使用大宽表, 大宽表有什么优缺点,  设计大宽表要注意什么?\n\n\n\n\n\n\n\n参考一起聊聊数仓大宽表\n","slug":"大数据-数据仓库大宽表","date":"2023-03-01T13:17:02.000Z","categories_index":"bigdata","tags_index":"bigdata","author_index":"majm"},{"id":"993a22b9aed98844bcb1901957913e2a","title":"golang如何避免循环依赖","content":"golang 包引用之间不允许循环依赖.循环依赖的本质上是一个错误的设计, 在 golang中 循环依赖是 会产生编译时错误.\n\ngolang中为什么不允许循环依赖呢?\n1. 没有支持循环导入,目的是迫使 Go 程序员更多地考虑程序的依赖关系.\n  - 保持依赖关系图的简洁。\n  - 快速的程序构建。\n2. 如果支持循环导入，很容易会造成懒惰、不良的依赖性管理和缓慢的构建。这是设计者不希望看见的。\n  - 混乱的依赖关系。\n  - 缓慢的程序构建\n\ngolang中的循环依赖对编译的性能 和  程序的依赖关系的清晰非常不利, 所以在程序设计上,要保持 干净的 DAG.\n常见的循环依赖  和 优化代码技巧1. 抽象顶层包ddd 的项目结构 一般是  依赖倒置,  在 service层定义接口,   infrastrue 层实现,目的是为了解耦， 实现可替换.\n你可能将代码写成这样: \nrepo包代码如下:\nrepo包依赖 service包\npackage repo\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle/service\"\n)\n\ntype channelRepo struct &#123;\n&#125;\n\nfunc NewChannelRepo() *channelRepo &#123;\n\treturn &amp;channelRepo&#123;&#125;\n&#125;\n\nfunc (c channelRepo) GetByID(ctx context.Context, id int64) (*service.Channel, error) &#123;\n\tpanic(\"\")\n&#125;\n\n\nservice 包\npackage service\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle/repo\"\n)\n\ntype Channel struct &#123;\n\tID int64\n&#125;\n\ntype ChannelRepo interface &#123;\n\tGetByID(ctx context.Context, id int64) (*Channel, error)\n&#125;\n\ntype ChannelService struct &#123;\n\tchannelRepo ChannelRepo\n&#125;\n\nfunc NewChannelService() *ChannelService &#123;\n\treturn &amp;ChannelService&#123;\n\t\tchannelRepo: repo.NewChannelRepo(),\n\t&#125;\n&#125;\n\nfunc (cs *ChannelService) Get() &#123;\n\t\n&#125;\n\n\n解决方式之一是我们可以引入一个顶层包 handler, 依赖  service &amp; repo:\n形成如下依赖关系:\n\npackage repo\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle/service\"\n)\n\ntype channelRepo struct &#123;\n&#125;\n\nfunc NewChannelRepo() *channelRepo &#123;\n\treturn &amp;channelRepo&#123;&#125;\n&#125;\n\nfunc (c channelRepo) GetByID(ctx context.Context, id int64) (*service.Channel, error) &#123;\n\tpanic(\"\")\n&#125;\n\nservice包\npackage service\n\nimport (\n\t\"context\"\n)\n\ntype Channel struct &#123;\n\tID int64\n&#125;\n\ntype ChannelRepo interface &#123;\n\tGetByID(ctx context.Context, id int64) (*Channel, error)\n&#125;\n\ntype ChannelService struct &#123;\n\tchannelRepo ChannelRepo\n&#125;\n\nfunc NewChannelService(channelRepo ChannelRepo) *ChannelService &#123;\n\treturn &amp;ChannelService&#123;\n\t\tchannelRepo: channelRepo,\n\t&#125;\n&#125;\n\nfunc (cs *ChannelService) Get() &#123;&#125;\n\n\nhandler包代码如下:\npackage handler\n\nimport (\n\t\"github.com/xxx/cycle/repo\"\n\t\"github.com/xxx/cycle/service\"\n)\n\nfunc useCase() &#123;\n\tchannelRepo := repo.NewChannelRepo()\n\tchannelService := service.NewChannelService(channelRepo)\n\tchannelService.Get()\n&#125;\n\n\n\n2. 和上面的场景类似, 也是抽象一个顶层解决比如我们没用争取使用策略模式的分包.\n有下面这种场景,做 一些数据过滤, 在  filter 包里面定义了filter 接口, 将实现定义在子包里面.\ntype Filter interface &#123;\n\tPreAction(ctx context.Context, data map[string]interface&#123;&#125;) error\n&#125;\n\n1. 子包  wordword包引用了  filter包的  对象 DataContext\npackage word\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle\"\n)\n\ntype wordFilter struct &#123;\n&#125;\n\nfunc (w wordFilter) PreAction(ctx context.Context, data *cycle.DataContext) error &#123;\n\tpanic(\"implement me\")\n&#125;\n\nfunc NewWordFilter() *wordFilter &#123;\n\treturn &amp;wordFilter&#123;&#125;\n&#125;\n\n\n\n2. 子包 policyword包引用了  filter包的  对象 DataContext\npackage policy\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle\"\n)\n\ntype policyFilter struct &#123;\n&#125;\n\nfunc NewPolicyFilter() *policyFilter &#123;\n\treturn &amp;policyFilter&#123;&#125;\n&#125;\n\nfunc (p policyFilter) PreAction(ctx context.Context, data *cycle.DataContext) error &#123;\n\tpanic(\"implement me\")\n&#125;\n\n3. 在filter包中使用package filter\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle/policy\"\n\t\"github.com/xxx/cycle/word\"\n)\n\nvar filterRegistry map[string]Filter\n\nfunc init() &#123;\n\tfilterRegistry = map[string]Filter&#123;\n\t\t\"word\":   word.NewWordFilter(),\n\t\t\"policy\": policy.NewPolicyFilter(),\n\t&#125;\n&#125;\n\ntype DataContext struct &#123;\n&#125;\n\ntype Filter interface &#123;\n\tPreAction(ctx context.Context, data *DataContext) error\n&#125;\n\nfunc GetFilter(filterType string) Filter &#123;\n\treturn filterRegistry[filterType]\n&#125;\n\n\n|filter\n├── filter.go\n├── policy\n│   └── filter.go\n└── word\n    └── filter.go\n\n\n\n此时产生了循环依赖.\n解决的方式:  其实应该属于编程技巧:\n\n\n\n\n\n\n\n\n不要再 filter包中有使用 filter 的逻辑, filer包仅定义接口, 在 filter包之外进行调用\n修改后的方案: \n\nfilter包\npackage filter\n\nimport (\n\t\"context\"\n)\n\nfunc init() &#123;\n\tfilterRegistry = make(map[string]Filter)\n&#125;\n\nvar filterRegistry map[string]Filter\n\nfunc Register(filterKey string, filter Filter) &#123;\n\tfilterRegistry[filterKey] = filter\n&#125;\n\ntype DataContext struct &#123;\n&#125;\n\ntype Filter interface &#123;\n\tPreAction(ctx context.Context, data *DataContext) error\n&#125;\n\nfunc GetFilter(filterType string) Filter &#123;\n\treturn filterRegistry[filterType]()\n&#125;\n\n\nword子包\npackage word\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle/filter\"\n)\n\nfunc init() &#123;\n\tfilter.Register(\"word\", NewWordFilter())\n&#125;\n\ntype wordFilter struct &#123;\n&#125;\n\nfunc (w wordFilter) PreAction(ctx context.Context, data *filter.DataContext) error &#123;\n\t//TODO implement me\n\tpanic(\"implement me\")\n&#125;\n\nfunc NewWordFilter() *wordFilter &#123;\n\treturn &amp;wordFilter&#123;&#125;\n&#125;\n\n\npolicy子包\npackage policy\n\nimport (\n\t\"context\"\n\t\"github.com/xxx/cycle/filter\"\n)\n\nfunc init() &#123;\n\tfilter.Register(\"policy\", NewPolicyFilter())\n&#125;\n\ntype policyFilter struct &#123;\n&#125;\n\nfunc NewPolicyFilter() *policyFilter &#123;\n\treturn &amp;policyFilter&#123;&#125;\n&#125;\n\nfunc (p policyFilter) PreAction(ctx context.Context, data *filter.DataContext) error &#123;\n\t//TODO implement me\n\tpanic(\"implement me\")\n&#125;\n\n添加上层调用:\n\n\npackage cycle\n\nimport (\n\t\"github.com/xxx/cycle/filter\"\n\t_ \"github.com/xxx/cycle/filter/policy\"\n\t_ \"github.com/xxx/cycle/filter/word\"\n)\n\nfunc handle() &#123;\n\tfilter.GetFilter(\"word\")\n\tfilter.GetFilter(\"policy\")\n&#125;\n\n\n\n\n\n3. 使用事件总线解耦想分享的是上面两种方案， 之后又在网上看到了某些方案: 比如事件总线，简单说就是: 使用时如果不关心返回结果, 就可以通过消息的方式解耦.\n\neventBus 包\npackage eventBus\n \nimport (\n\t\"github.com/asaskevich/EventBus\"\n)\n \nvar globalEventBus EventBus.Bus\n \nfunc init() &#123;\n\tglobalEventBus = EventBus.New()\n&#125;\n \nfunc Subscribe(topic string, fn interface&#123;&#125;) error &#123;\n\treturn globalEventBus.Subscribe(topic, fn)\n&#125;\n \nfunc SubscribeAsync(topic string, fn interface&#123;&#125;, transactional bool) error &#123;\n\treturn globalEventBus.SubscribeAsync(topic, fn, transactional)\n&#125;\n \nfunc Publish(topic string, args ...interface&#123;&#125;) &#123;\n\tglobalEventBus.Publish(topic, args...)\n&#125;\n\n\npackageA\n\n\npackage package_a\n \nimport (\n\t\"cycle/eventBus\"\n\t\"fmt\"\n)\n \nfunc init() &#123;\n\teventBus.Subscribe(\"PrintA\", new(PackageA).PrintA)\n&#125;\n \ntype PackageA struct &#123;\n&#125;\n \nfunc (a PackageA) PrintA() &#123;\n\tfmt.Println(\"I'm a!\")\n&#125;\n \nfunc (a PackageA) PrintAll() &#123;\n\ta.PrintA()\n\teventBus.Publish(\"PrintB\")\n&#125;\n\n\n\npackageB\n\npackage package_b\n \nimport (\n\t\"cycle/eventBus\"\n\t\"fmt\"\n)\n \nfunc init() &#123;\n\teventBus.Subscribe(\"PrintB\", new(PackageB).PrintB)\n&#125;\n \ntype PackageB struct &#123;\n&#125;\n \nfunc (b PackageB) PrintB() &#123;\n\tfmt.Println(\"I'm b!\")\n&#125;\n \nfunc (b PackageB) PrintAll() &#123;\n\tb.PrintB()\n\teventBus.Publish(\"PrintA\")\n&#125;\n\n\n\n总结编写代码要符合规范，包的组织结构 和 依赖 要清晰, 符合规范.golang的包组织规范可以参考:  \n\ngolang-standards\nkratos-layout\n\n\n\n[参考]循环引用golang包循环引用的几种解决方案\n","slug":"golang如何避免循环依赖","date":"2022-11-18T13:12:04.000Z","categories_index":"golang","tags_index":"golang","author_index":"majm"},{"id":"03cc55fb6473717cac5c2d4cd07b1cc0","title":"Go-Test-Gomonkey使用","content":"golang的单测, 有一些约定, 例如文件名是  xxx.go, 测试文件名必须是 xxx_test.go, 且测试函数的方法名 都是以 Test开头, 使用go test 命令, 有时发现mock不住,一般都是内联(简短)函数mock失败,可以执行的时候加上编译条件禁止内联 -gcflags=all=-l.\nFeature:\n\nsupport a patch for a function\nsupport a patch for a public member method\nsupport a patch for a private member method\nsupport a patch for a interface\nsupport a patch for a function variable\nsupport a patch for a global variable\nsupport patches of a specified sequence for a function\nsupport patches of a specified sequence for a member method\nsupport patches of a specified sequence for a interface\nsupport patches of a specified sequence for a function variable\n\ngomonkey 使用github\ngomonkey 可以为函数打桩,做数据mock, 有如下功能:\n\n为函数打桩\n为成员方法打桩\n为全局变量打桩\n为函数变量打桩\n为函数打一个特定的桩序列\n为成员方法打一个特定桩序列\n为函数变量打一个特定的桩序列\n\n1. 为函数打桩\n// @param target: 被mock的函数\n// @param double: 桩函数定义\n// @return Patches: 测试完成后,通过patches调用 Reset() 删除桩\nfunc ApplyFunc(target, double interface&#123;&#125;) *Patches &#123;\n\treturn create().ApplyFunc(target, double)\n&#125;\n\n\n\nDemo: 使用 gomonkey.ApplyFunc mock netWorkFunc 函数\nfunc logicFunc(a, b int) (int, error) &#123;\n\tsum, err := netWorkFunc(a, b)\n\tif err != nil &#123;\n\t\treturn 0, err\n\t&#125;\n\treturn sum, nil\n&#125;\n\nfunc netWorkFunc(a, b int) (int, error) &#123;\n\tif a &lt; 0 &amp;&amp; b &lt; 0 &#123;\n\t\terrmsg := \"a&lt;0 &amp;&amp; b&lt;0\" //gomonkey有bug，函数一定要有栈分配变量，不然mock不住\n\t\treturn 0, fmt.Errorf(\"%v\", errmsg)\n\t&#125;\n\n\treturn a + b, nil\n&#125;\n\n\n\nfunc TestDemo(t *testing.T) &#123;\n\n\tpatches := gomonkey.ApplyFunc(netWorkFunc, func(a, b int) (int, error) &#123;\n\t\treturn 99999999, nil\n\t&#125;)\n\tdefer patches.Reset()\n    \n    // out:  99999999\n\tfmt.Println(logicFunc(12, 34))\n\n&#125;\n\n\n\n2.  为成员方法打桩method 与 Func 不同, method 属于类型的一部分, Func 属于包的一部分, 在函数地址分配的方式有所不同,因此不能直接去 ApplyFunc 去 mock, 需要使用 ApplyMethod\n// @param target      被mock类型  \n// @param methodName  方法名\n// @param double      桩函数定义\n// @return \nfunc ApplyMethod(target reflect.Type, methodName string, double interface&#123;&#125;) *Patches &#123;\n\treturn create().ApplyMethod(target, methodName, double)\n&#125;\n\n\n\n\n\n无法为 unexported 方法打桩\n\n\n\n类型为 T的 method只包含recever为 T 的method, 类型为*T 的包含receiver 为 T | *T 的\n\n\n\n写桩函数定义时,要把receiver写进去.\n\n\n\nDemo:  \n\ntype MyType struct &#123;\n&#125;\n\nfunc (mt *MyType) logicFunc(a, b int) (int, error) &#123;\n\tsum, err := mt.NetWorkFunc(a, b)\n\tif err != nil &#123;\n\t\treturn 0, err\n\t&#125;\n\treturn sum, nil\n&#125;\n\nfunc (mt *MyType) NetWorkFunc(a, b int) (int, error) &#123;\n\tif a &lt; 0 &amp;&amp; b &lt; 0 &#123;\n\t\terrmsg := \"a&lt;0 &amp;&amp; b&lt;0\" //gomonkey有bug，函数一定要有栈分配变量，不然mock不住\n\t\treturn 0, fmt.Errorf(\"%v\", errmsg)\n\t&#125;\n\treturn a + b, nil\n&#125;\n\n\n\n// test case\nfunc Test_ApplyMethod(t *testing.T) &#123;\n\n\tvar m *MyType\n\tpatches := gomonkey.ApplyMethod(reflect.TypeOf(m), \"NetWorkFunc\", func(_ *MyType, a, b int) (int, error) &#123;\n\t\treturn 99999999, nil\n\t&#125;)\n\tdefer patches.Reset()\n\tres, err := m.logicFunc(12, 34)\n\tassert.Equal(t, err, nil)\n\tassert.Equal(t, res, 99999999)\n&#125;\n\n\n3. 为全局变量打桩函数签名:\n\n// @param target : 全局变量地址\n// @param double : 全局变量的桩\n// @retrun Patches\n\nfunc ApplyGlobalVar(target, double interface&#123;&#125;) *Patches &#123;\n\treturn create().ApplyGlobalVar(target, double)\n&#125;\n\n\n\nvar (\n\tnum = 100\n\tmat map[string]string\n)\n\n\nfunc Test_ApplyGlobalVar(t *testing.T) &#123;\n\n\tpatches := gomonkey.ApplyGlobalVar(&amp;num, 150)\n\tdefer patches.Reset()\n\tassert.Equal(t, num, 150)\n\n\tpatches2 := gomonkey.ApplyGlobalVar(&amp;mat, map[string]string&#123;\"a\": \"b\"&#125;)\n\tdefer patches2.Reset()\n\tfmt.Println(mat)\n&#125;\n\n\n\n\n\n\n\n\n\n4. 为函数变量打桩// @param target 目标函数变量地址\n// @param double 目标函数的桩\n// @return patches \nfunc ApplyFuncVar(target, double interface&#123;&#125;) *Patches &#123;\n\treturn create().ApplyFuncVar(target, double)\n&#125;\n\n\n\nDemo: mock 一个函数变量的行为\nvar Marshal = func(v interface&#123;&#125;) ([]byte, error) &#123;\n\treturn nil, nil\n&#125;\n\nfunc Test_ApplyFuncVar(t *testing.T) &#123;\n\n\tstr := \"hello world.\"\n\n\tgomonkey.ApplyFuncVar(&amp;Marshal, func(v interface&#123;&#125;) ([]byte, error) &#123;\n\t\treturn []byte(str), nil\n\t&#125;)\n\n\tbytes, _ := Marshal(nil)\n\tassert.Equal(t, string(bytes), str)\n\n&#125;\n\n\n\n\n\n\n5. 为函数打一个特定的桩序列有时,我们需要多次调用同一个函数,且需要有不同的返回值, 且保持顺序, 如是果是你要怎么实实现?\n// @param target  目标函数\n// @param outputs 返回值序列\n// @return patches \nfunc ApplyFuncSeq(target interface&#123;&#125;, outputs []OutputCell) *Patches &#123;\n\treturn create().ApplyFuncSeq(target, outputs)\n&#125;\n\n\n\nDemo:\n\nfunc ReadLeaf(value string) (string, error) &#123;\n\treturn fmt.Sprintf(\"%s:%s\", \"hello\", \"world\"), nil\n&#125;\n\nfunc TestApplyFuncSeq(t *testing.T) &#123;\n\tinfo1 := \"hello world.\"\n\tinfo2 := \"majm.\"\n\tinfo3 := \"nancy.\"\n\n    // default time is 1 \n\toutputCells := []gomonkey.OutputCell&#123;\n\t\t&#123;Values: gomonkey.Params&#123;info1, nil&#125;&#125;,\n\t\t&#123;Values: gomonkey.Params&#123;info2, nil&#125;&#125;,\n\t\t&#123;Values: gomonkey.Params&#123;info3, nil&#125;&#125;,\n\t&#125;\n\n\tpatches := gomonkey.ApplyFuncSeq(ReadLeaf, outputCells)\n\tdefer patches.Reset()\n\n\tresult1, err := ReadLeaf(\"1\")\n\tassert.Equal(t, info1, result1)\n\tassert.Equal(t, err, nil)\n\tresult2, err := ReadLeaf(\"2\")\n\tassert.Equal(t, info2, result2)\n\tassert.Equal(t, err, nil)\n\tresult3, err := ReadLeaf(\"3\")\n\tassert.Equal(t, info3, result3)\n\tassert.Equal(t, err, nil)\n&#125;\n\n\ntype Params []interface&#123;&#125;\ntype OutputCell struct &#123;\n\tValues Params\n\tTimes  int\n&#125;\n\nParams: []interface{}: 返回结果Times: 出现的次数\n\n如果 outputs + times 声明了 N次,当调用超过N次后悔报错.\nTimes 默认是 1 次\n\n6. 为成员方法打一个特定桩序列// @param target    目标类型\n// @param methodName 目标类型方法\n// @param outputs    返回值序列\n// @return  patches\nfunc ApplyMethodSeq(target reflect.Type, methodName string, outputs []OutputCell) *Patches &#123;\n\treturn create().ApplyMethodSeq(target, methodName, outputs)\n&#125;\n\n\nDemo:\n\ntype Etcd struct &#123;\n&#125;\n\nfunc (e *Etcd) Retrieve(url string) (string, error) &#123;\n\toutput := fmt.Sprintf(\"%s, %s!\", \"Hello\", \"Etcd\")\n\treturn output, nil\n&#125;\n\nfunc Test_ApplyMethodSeq(t *testing.T) &#123;\n\n\tinfo1 := \"hello world.\"\n\tinfo2 := \"majm.\"\n\tinfo3 := \"nancy.\"\n\n\tvar e *Etcd\n\toutputs := []gomonkey.OutputCell&#123;\n\t\t&#123;Values: gomonkey.Params&#123;info1, nil&#125;&#125;,\n\t\t&#123;Values: gomonkey.Params&#123;info2, nil&#125;&#125;,\n\t\t&#123;Values: gomonkey.Params&#123;info3, nil&#125;&#125;,\n\t&#125;\n\tpatches := gomonkey.ApplyMethodSeq(reflect.TypeOf(e), \"Retrieve\", outputs)\n\tdefer patches.Reset()\n\n\tresult1, err := e.Retrieve(\"url1\")\n\tassert.Equal(t, info1, result1)\n\tassert.Equal(t, err, nil)\n\tresult2, err := e.Retrieve(\"url2\")\n\tassert.Equal(t, info2, result2)\n\tassert.Equal(t, err, nil)\n\tresult3, err := e.Retrieve(\"url3\")\n\tassert.Equal(t, info3, result3)\n\tassert.Equal(t, err, nil)\n&#125;\n\n\n7. 为函数变量打一个特定的桩序列\n// @param:  target  目标函数变量地址\n// @param:  outputs 返回结果序列\n// @return: patches\nfunc ApplyFuncVarSeq(target interface&#123;&#125;, outputs []OutputCell) *Patches &#123;\n\treturn create().ApplyFuncVarSeq(target, outputs)\n&#125;\n\n\n\nDemo:\nfunc Test_ApplyFuncVarSeq(t *testing.T) &#123;\n\n\tinfo1 := []byte(\"hello world.\")\n\tinfo2 := []byte(\"majm.\")\n\tinfo3 := []byte(\"nancy.\")\n\n\toutputCells := []gomonkey.OutputCell&#123;\n\t\t&#123;Values: gomonkey.Params&#123;info1, nil&#125;&#125;,\n\t\t&#123;Values: gomonkey.Params&#123;info2, nil&#125;&#125;,\n\t\t&#123;Values: gomonkey.Params&#123;info3, nil&#125;&#125;,\n\t&#125;\n\n\tpatches := gomonkey.ApplyFuncVarSeq(&amp;Marshal, outputCells)\n\tdefer patches.Reset()\n\n\tresult1, err := Marshal(\"1\")\n\tassert.Equal(t, result1, info1)\n\tassert.Equal(t, err, nil)\n\n\tresult2, err := Marshal(\"2\")\n\tassert.Equal(t, result2, info2)\n\tassert.Equal(t, err, nil)\n\n\tresult3, err := Marshal(\"3\")\n\tassert.Equal(t, result3, info3)\n\tassert.Equal(t, err, nil)\n&#125;\n\n\n\n\n\n","slug":"Go-Test-Gomonkey使用","date":"2022-11-14T11:54:08.000Z","categories_index":"golang","tags_index":"golang,test,gomonkey","author_index":"majm"},{"id":"7197218ba2b31b3e36651d378424a532","title":"Go-Test-Convey使用","content":"ConveyWiki\nFeature:\n\n直接与  go test 集成\n全自动的 WEBUI(与 go test 一起工作)\n大量的回归测试\n展示测试覆盖率\n可读的,彩色控制台输出(可以被其他人理解)\n测试代码自动生成\n桌面通知(optional)\n立即打开问题行.\n\n\n\n\n\n1. Why goconveyGoconvey 提供了人性化的断言使用方式, 优雅的写出测试代码, 同时能够在终端输出彩色的测试结果,还支持WebUI查看\n2. 断言使用2.1. 普通判等So(thing1, ShouldEqual, thing2)\nSo(thing1, ShouldNotEqual, thing2)\nSo(thing1, ShouldResemble, thing2)\t\t// a deep equals for arrays, slices, maps, and structs\nSo(thing1, ShouldNotResemble, thing2)\nSo(thing1, ShouldPointTo, thing2)\nSo(thing1, ShouldNotPointTo, thing2)\nSo(thing1, ShouldBeNil)\nSo(thing1, ShouldNotBeNil)\nSo(thing1, ShouldBeTrue)\nSo(thing1, ShouldBeFalse)\nSo(thing1, ShouldBeZeroValue)\n\n\n2.2. 数值类型比较So(1, ShouldBeGreaterThan, 0)\nSo(1, ShouldBeGreaterThanOrEqualTo, 0)\nSo(1, ShouldBeLessThan, 2)\nSo(1, ShouldBeLessThanOrEqualTo, 2)\nSo(1.1, ShouldBeBetween, .8, 1.2)\nSo(1.1, ShouldNotBeBetween, 2, 3)\nSo(1.1, ShouldBeBetweenOrEqual, .9, 1.1)\nSo(1.1, ShouldNotBeBetweenOrEqual, 1000, 2000)\nSo(1.0, ShouldAlmostEqual, 0.99999999, .0001)   // tolerance is optional; default 0.0000000001\nSo(1.0, ShouldNotAlmostEqual, 0.9, .0001)\n\n\n2.3. 集合类型So([]int&#123;2, 4, 6&#125;, ShouldContain, 4)\nSo([]int&#123;2, 4, 6&#125;, ShouldNotContain, 5)\nSo(4, ShouldBeIn, ...[]int&#123;2, 4, 6&#125;)\nSo(4, ShouldNotBeIn, ...[]int&#123;1, 3, 5&#125;)\nSo([]int&#123;&#125;, ShouldBeEmpty)\nSo([]int&#123;1&#125;, ShouldNotBeEmpty)\nSo(map[string]string&#123;\"a\": \"b\"&#125;, ShouldContainKey, \"a\")\nSo(map[string]string&#123;\"a\": \"b\"&#125;, ShouldNotContainKey, \"b\")\nSo(map[string]string&#123;\"a\": \"b\"&#125;, ShouldNotBeEmpty)\nSo(map[string]string&#123;&#125;, ShouldBeEmpty)\nSo(map[string]string&#123;\"a\": \"b\"&#125;, ShouldHaveLength, 1) // supports map, slice, chan, and string\n\n\n2.4. 字符串So(\"asdf\", ShouldStartWith, \"as\")\nSo(\"asdf\", ShouldNotStartWith, \"df\")\nSo(\"asdf\", ShouldEndWith, \"df\")\nSo(\"asdf\", ShouldNotEndWith, \"df\")\nSo(\"asdf\", ShouldContainSubstring, \"sd\")\t\t// optional 'expected occurences' arguments?\nSo(\"asdf\", ShouldNotContainSubstring, \"er\")\nSo(\"adsf\", ShouldBeBlank)\nSo(\"asdf\", ShouldNotBeBlank)\n\n\n\n2.5. panicSo(func(), ShouldPanic)\nSo(func(), ShouldNotPanic)\nSo(func(), ShouldPanicWith, \"\")\t\t// or errors.New(\"something\")\nSo(func(), ShouldNotPanicWith, \"\")\t// or errors.New(\"something\")\n\n\n\n2.6. 类型检查So(1, ShouldHaveSameTypeAs, 0)\nSo(1, ShouldNotHaveSameTypeAs, \"asdf\")\n\n\n2.7. 时间类型So(time.Now(), ShouldHappenBefore, time.Now())\nSo(time.Now(), ShouldHappenOnOrBefore, time.Now())\nSo(time.Now(), ShouldHappenAfter, time.Now())\nSo(time.Now(), ShouldHappenOnOrAfter, time.Now())\nSo(time.Now(), ShouldHappenBetween, time.Now(), time.Now())\nSo(time.Now(), ShouldHappenOnOrBetween, time.Now(), time.Now())\nSo(time.Now(), ShouldNotHappenOnOrBetween, time.Now(), time.Now())\nSo(time.Now(), ShouldHappenWithin, duration, time.Now())\nSo(time.Now(), ShouldNotHappenWithin, duration, time.Now())\n\n\n3. Convey 使用3.1\nfunc StringSliceEqual(a, b []string) bool &#123;\n\tif len(a) != len(b) &#123;\n\t\treturn false\n\t&#125;\n\tif (a == nil) != (b == nil) &#123;\n\t\treturn false\n\t&#125;\n\tfor i, v := range a &#123;\n\t\tif v != b[i] &#123;\n\t\t\treturn false\n\t\t&#125;\n\t&#125;\n\treturn true\n&#125;\n\nfunc TestStringSliceEqual(t *testing.T) &#123;\n\n\tConvey(\"TestStringSliceEqual should return true when a != nil  &amp;&amp; b != nil\", t, func() &#123;\n\t\ta := []string&#123;\"hello\", \"convey\"&#125;\n\t\tb := []string&#123;\"hello\", \"convey1\"&#125;\n\t\tSo(StringSliceEqual(a, b), ShouldBeTrue)\n\t&#125;)\n\n&#125;\n\n3.2 Convey 语句的嵌套func TestStringSliceEqual(t *testing.T) &#123;\n\n\tConvey(\"TestStringSliceEqual\", t, func() &#123;\n\t\tConvey(\"should return true when a != nil  &amp;&amp; b != nil\", func() &#123;\n\t\t\ta := []string&#123;\"hello\", \"goconvey\"&#125;\n\t\t\tb := []string&#123;\"hello\", \"goconvey\"&#125;\n\t\t\tSo(StringSliceEqual(a, b), ShouldBeTrue)\n\t\t&#125;)\n\n\t\tConvey(\"should return true when a ＝= nil  &amp;&amp; b ＝= nil\", func() &#123;\n\t\t\tSo(StringSliceEqual(nil, nil), ShouldBeTrue)\n\t\t&#125;)\n\n\t\tConvey(\"should return false when a ＝= nil  &amp;&amp; b != nil\", func() &#123;\n\t\t\ta := []string(nil)\n\t\t\tb := []string&#123;&#125;\n\t\t\tSo(StringSliceEqual(a, b), ShouldBeFalse)\n\t\t&#125;)\n\n\t\tConvey(\"should return false when a != nil  &amp;&amp; b != nil\", func() &#123;\n\t\t\ta := []string&#123;\"hello\", \"world\"&#125;\n\t\t\tb := []string&#123;\"hello\", \"goconvey\"&#125;\n\t\t\tSo(StringSliceEqual(a, b), ShouldBeFalse)\n\t\t&#125;)\n\t&#125;)\n&#125;\n\n\n\n只有最外层的  Convey 需要传入 *testing.T\n\n4. 最佳实践\nimport goconvey包时，前面加点号”.”，以减少冗余的代码.凡是在测试代码中看到Convey和So两个方法,肯定是convey包的,不要在产品代码中定义相同的函数名\n测试函数的名字必须以Test开头，而且参数类型必须为*testing.T\n每个测试用例必须使用Convey函数包裹起来\n\n\n它的第一个参数为string类型的测试描述\n第二个参数为测试函数的入参(类型为*testing.T)\n第三个参数为不接收任何参数也不返回任何值的函数(习惯使用闭包)\n\n\nConvey函数的第三个参数闭包的实现中通过So函数完成断言判断,\n\n\n第一个参数为实际值\n第二个参数为断言函数变量\n第三个参数或者没有(当第二个参数为类ShouldBeTrue形式的函数变量)或者有(当第二个函数为类ShouldEqual形式的函数变量)\n\n\n使用嵌套的形式包裹多个测试用例, 输出结果看起来优雅\n\n5.  WebUI在 test文件所在目录下执行  $GOBIN/goconvey 命令\n之后可以通过 localhost:8080 查看webUI界面\n\n[参考]\n\nGoConvey框架使用指南\nGo单测从零到溜系列5—goconvey的使用\n\n","slug":"Go-Test-Convey使用","date":"2022-11-14T11:53:51.000Z","categories_index":"golang","tags_index":"golang,test,convey","author_index":"majm"},{"id":"301b2e78436f0e9c40fa9a9acf52a404","title":"Go-Test-gomock使用","content":"写出可测试 的代码 至关重要.  可以保证代码的稳定性.  帮助程序员减少bug.\ngomock 是一个go官方的模拟框架.gomock的使用场景:\n\nIO类型的数据, 本地文件,数据库,网络API,RPC等\n依赖的服务还没有开发好, 这时候可以自己模拟一个服务, 加快开发进度提升开发效率\n压力性能测试的时候屏蔽外部依赖, 专注测试本模块\n依赖的内部函数非常复杂, 要构造数据非常不方便，这也是一种\n\ngomock\n\n\n\ninstallgo get github.com&#x2F;golang&#x2F;mock\n\ngo install github.com&#x2F;golang&#x2F;mock&#x2F;mockgen@latest\n\n使用gomock在许多 开源项目中都有使用.   可以参考一些开源项目。  比如 [gocache](https://github.com/eko/gocache)\n使用mockgen 支持两种 自动生成代码的方式.\n\n指定source,从源文件生成 mock接口\nmockgen -source&#x3D;.&#x2F;foo.go  -destination&#x3D;..&#x2F;test&#x2F;mock&#x2F; -pakcage&#x3D;mock\n\n通过 reflect 的方式, 这种方式需要传递两种非标志参数来启动. 导入路径 import  和  逗号分隔的需要mock的接口列表\n\n\nmockgen database&#x2F;sql&#x2F;driver  Conn,Driver\n\n\n\nmockgen 相关参数\n-source: 要模拟的接口文件\n-desitination: mock文件输出的地方,如不设置,默认输出到标准输出中.\n-package: 生成的 mock 文件的包名, 如不设置则为 mock_ 前缀加上输入的文件名。\n-imports: 应该在生成的源码文件中显示的导入的包列表.  声明为  foo=bar/baz 形式的并且以逗号分隔的列表. foo表示生成的源码文件中报的标识符, bar/baz 是要导入的包.\n-aux_files: 应查阅的附加文件列表, 已解决例如在不同文件中定义的嵌入式接口(embbed interface). 声明为  foo=bar/baz.go 形式的并且以逗号分隔的列表.  bar/baz.go 是指定的源文件.  foo 是-source 指定的文件的包名.\n-build_flags: 这个参数只在 reflect模式下使用. 用于 go build 中使用. \n-mock_names: 自定义生成mock的文件列表.  使用逗号分隔. 例如: Repository=MockSensorRepository,Endpoint=MockSensorEndpoint. Repository Endpoint 是要模拟的接口, MockSensorRepository 和 MockSensorEndpoint 是模拟的实现类名.  如果不指定,则使用默认值.\n\nExamplegomock.NewController: 返回 gomock.Controller，它代表 mock 生态系统中的顶级控件。定义了 mock 对象的范围、生命周期和期待值。另外它在多个 goroutine 中是安全的mock.NewMockMale: 创建一个新的 mock 实例gomock.InOrder: 声明给定的调用应按顺序进行(是对 gomock.After 的二次封装)mockMale.EXPECT().Get(id).Return(nil): 这里有三个步骤，EXPECT()返回一个允许调用者设置期望和返回值的对象. Get(id) 是设置入参并调用 mock 实例中的方法. Return(nil) 是设置先前调用的方法出参。简单来说，就是设置入参并调用，最后设置返回值NewUser(mockMale): 创建 User 实例, 值得注意的是，在这里注入了 mock 对象,因此实际在随后的 user.GetUserInfo(id) 调用(入参：id 为 1)中. 它调用的是我们事先模拟好的 mock 方法ctrl.Finish(): 进行 mock 用例的期望值断言，一般会使用 defer 延迟执行，以防止我们忘记这一操作\n官方Demo\n参数匹配器[Matcher](https://github.com/golang/mock/blob/main/gomock/matchers.go#L25) 表示values 的类型.  通常用于表示  mock方法的期望参数.\nMatcher接口定义:\n// A Matcher is a representation of a class of values.\n// It is used to represent the valid or expected arguments to a mocked method.\ntype Matcher interface &#123;\n\t// Matches returns whether x is a match.\n\tMatches(x interface&#123;&#125;) bool\n\n\t// String describes what the matcher matches.\n\tString() string\n&#125;\n\n\n有时,不关心 调用mock时的特定参数,使用 gomock, 可以预期参数 具有固定值(通过 指定预期的 参数值),与谓词匹配, 称为匹配器.  \ngomock.Any():匹配任何值(任何类型)\ngomock.Eq(x):使用反射来匹配是值DeepEqual 到 x\ngomock.Nil(): 火柴 nil\ngomock.Not(m):(m 匹配器在哪里)匹配匹配器不匹配的值 m, gomock.Not(x)(式中， x 是 不 一个Matcher)匹配的值不 DeepEqual 至 x\n\n\n\n\n需要掌握的\n使用  mockgen 生成代码 一节   使用 go:generate  批量生成代码\n了解 gomock 是对接口的mock\n期望入参\n期望返回值\n调用次数\n调用顺序\n执行 Do mock逻辑\n\n\n\n\n参考gomock 使用GoMock快速上手教程Gomock文档\n","slug":"Go-Test-gomock使用","date":"2022-11-14T11:53:38.000Z","categories_index":"golang","tags_index":"golang,test,gomock","author_index":"majm"},{"id":"33024321d4d721b36bc422db43cf754d","title":"freecache源码解析","content":"代码仓库地址\nfreeCache 相比较  golang 的原生map实现缓存,可以通过减少指针的数量避免 GC压力,无论存储了多少数据,内部只会占用 512个指针, 数据集 通过 hash(key) 被分片256个 segment,每个 segment 有两个指针,\n\n一个存储键和值的唤醒缓冲区\n另一个是用于查找索引条目的索引切片每个 segment 都有自己的  sync.Mutex,所以支持多线程访问.\n\n\n\n[TOC]\n特性:\n存储百万的 entrys\nZero GC overhead\n线程安全的并发访问\n纯Golang实现\n支持数据过期\nLRU缓存替换策略\n严格限制内存使用\n附带一个 demo server,支持 一些带有管道(pipeline)的 redis命令\n迭代支持\n\n1. 数据结构\n将 缓存分为  256 个段 segment, 每个 segment 分为  256 个slot. 采用 开发寻址发 解决 hash冲突问题.\n\n每个segment 一把锁, 减小锁粒度\n每个 slot 存储数据的索引(在 ringBuffer中的偏移量)\nrinbBuffer 循环数组,实际存储数据.\n\nCache// Cache is a freecache instance.\ntype Cache struct &#123;\n\tlocks    [segmentCount]sync.Mutex // 减小锁粒度, 每个 segment 一把锁\n\tsegments [segmentCount]segment\n&#125;\n\nsegment// a segment contains 256 slots, a slot is an array of entry pointers ordered by hash16 value\n// the entry can be looked up by hash value of the key.\ntype segment struct &#123;\n\trb    RingBuf // ring buffer that stores data 环形缓冲区 存储数据\n\tsegId int\n\t_     uint32\n\n\t// 一些 统计信息\n\tmissCount     int64\n\thitCount      int64\n\tentryCount    int64\n\ttotalCount    int64 // number of entries in ring buffer, including deleted entries.\n\ttotalTime     int64 // used to calculate least recent used entry.\n\ttotalEvacuate int64 // used for debug\n\ttotalExpired  int64 // used for debug\n\toverwrites    int64 // used for debug\n\ttouched       int64 // used for debug\n\n\ttimer     Timer      // Timer giving current time 用于计算过期时间\n\tvacuumLen int64      // up to vacuumLen, new data can be written without overwriting old data.\n\tslotLens  [256]int32 // The actual length for every slot.   - (每个 slot 容纳的 entryPtr  数量 len)\n\tslotCap   int32      // max number of entry pointers a slot can hold. - (每个 slot 可以容纳的 entryPtr  cap)\n\tslotsData []entryPtr // shared by all 256 slots - (用来解决 hash冲突, 每个 slot 是一个 []entryPtr, 是直接寻址法)\n&#125;\n\nEntry\n// entry pointer struct points to an entry in ring buffer, \ntype entryPtr struct &#123;\n\toffset   int64  // entry offset in ring buffer\n\thash16   uint16 // entries are ordered by hash16 in a slot.\n\tkeyLen   uint16 // used to compare a key\n\treserved uint32\n&#125;\n\n// entry header struct in ring buffer, followed by key and value.\ntype entryHdr struct &#123;\n\taccessTime uint32\n\texpireAt   uint32\n\tkeyLen     uint16\n\thash16     uint16\n\tvalLen     uint32\n\tvalCap     uint32\n\tdeleted    bool\n\tslotId     uint8\n\treserved   uint16\n&#125;\n\nentryPtr: slot 中存储的数据结构entryHdr: ringBuffer 中存储的 entry 的  Header 结构\n每个slot 中存储的 entryPtr. entryPtr.offset 指向 entry 在  ringBuffer 中的偏移量.\nringBuffer 中 entry的数据结构\nringBufferringBuffer 固定大小, 当超过 容量时, 新数据会覆盖老数据. 数据 存储在 data[begin] -&gt; data[end] 之间.\n// Ring buffer has a fixed size, when data exceeds the\n// size, old data will be overwritten by new data.\n// It only contains the data in the stream from begin to end\ntype RingBuf struct &#123;\n\tbegin int64 // beginning offset of the data stream.\n\tend   int64 // ending offset of the data stream.\n\tdata  []byte\n\tindex int //range from '0' to 'len(rb.data)-1'\n&#125;\n\n\n\n2. 常用操作:# go doc freecache Cache\n\npackage freecache &#x2F;&#x2F; import &quot;github.com&#x2F;coocood&#x2F;freecache&quot;\n\ntype Cache struct &#123;\n        &#x2F;&#x2F; Has unexported fields.\n&#125;\n    Cache is a freecache instance.\n\nfunc NewCache(size int) (cache *Cache)\nfunc NewCacheCustomTimer(size int, timer Timer) (cache *Cache)\nfunc (cache *Cache) AverageAccessTime() int64\nfunc (cache *Cache) Clear()\nfunc (cache *Cache) Del(key []byte) (affected bool)\nfunc (cache *Cache) DelInt(key int64) (affected bool)\nfunc (cache *Cache) EntryCount() (entryCount int64)\nfunc (cache *Cache) EvacuateCount() (count int64)\nfunc (cache *Cache) ExpiredCount() (count int64)\nfunc (cache *Cache) Get(key []byte) (value []byte, err error)\nfunc (cache *Cache) GetFn(key []byte, fn func([]byte) error) (err error)\nfunc (cache *Cache) GetInt(key int64) (value []byte, err error)\nfunc (cache *Cache) GetIntWithExpiration(key int64) (value []byte, expireAt uint32, err error)\nfunc (cache *Cache) GetOrSet(key, value []byte, expireSeconds int) (retValue []byte, err error)\nfunc (cache *Cache) GetWithBuf(key, buf []byte) (value []byte, err error)\nfunc (cache *Cache) GetWithExpiration(key []byte) (value []byte, expireAt uint32, err error)\nfunc (cache *Cache) HitCount() (count int64)\nfunc (cache *Cache) HitRate() float64\nfunc (cache *Cache) LookupCount() int64\nfunc (cache *Cache) MissCount() (count int64)\nfunc (cache *Cache) NewIterator() *Iterator\nfunc (cache *Cache) OverwriteCount() (overwriteCount int64)\nfunc (cache *Cache) Peek(key []byte) (value []byte, err error)\nfunc (cache *Cache) PeekFn(key []byte, fn func([]byte) error) (err error)\nfunc (cache *Cache) ResetStatistics()\nfunc (cache *Cache) Set(key, value []byte, expireSeconds int) (err error)\nfunc (cache *Cache) SetAndGet(key, value []byte, expireSeconds int) (retValue []byte, found bool, err error)\nfunc (cache *Cache) SetInt(key int64, value []byte, expireSeconds int) (err error)\nfunc (cache *Cache) TTL(key []byte) (timeLeft uint32, err error)\nfunc (cache *Cache) Touch(key []byte, expireSeconds int) (err error)\nfunc (cache *Cache) TouchedCount() (touchedCount int64)\n\n\n1. Set// Set sets a key, value and expiration for a cache entry and stores it in the cache.\n// If the key is larger than 65535 or value is larger than 1/1024 of the cache size,\n// the entry will not be written to the cache. expireSeconds &lt;= 0 means no expire,\n// but it can be evicted when cache is full.\nfunc (cache *Cache) Set(key, value []byte, expireSeconds int) (err error) &#123;\n\thashVal := hashFunc(key)\n\tsegID := hashVal &amp; segmentAndOpVal // 通过 位运算 计算取余操作\n\tcache.locks[segID].Lock()\n\terr = cache.segments[segID].set(key, value, hashVal, expireSeconds)\n\tcache.locks[segID].Unlock()\n\treturn\n&#125;\n\n# 取余操作. 对于 2的幂次方取余 可以通过位运算的方式进行处理:\nx % 256 &#x3D; x &amp; (2^8 -1)\nx % 512 &#x3D; x &amp; (2^9 -1)\n\n拿到 segment 后, \nfunc (seg *segment) set(key, value []byte, hashVal uint64, expireSeconds int) (err error) &#123;\n\t// param check\n\t...\n\t\n\tnow := seg.timer.Now()\n\texpireAt := uint32(0)\n\tif expireSeconds > 0 &#123;\n\t\texpireAt = now + uint32(expireSeconds)\n\t&#125;\n\n\t// uint64     32     16      8       8\n\t// hashValue          hash16 slotId\n\tslotId := uint8(hashVal >> 8)\n\thash16 := uint16(hashVal >> 16)\n\n\t// slot 中每个元素是按照  hash16 升序排序的, 因此查询操作可以利用二分查找\n\t//从 segment 中查找数据\n\tslot := seg.getSlot(slotId)\n\tidx, match := seg.lookup(slot, hash16, key) // idx 要插入的位置,  match 是否找到  对应的 entry\n\n\tvar hdrBuf [ENTRY_HDR_SIZE]byte\n\thdr := (*entryHdr)(unsafe.Pointer(&amp;hdrBuf[0]))\n\t// 进行替换操作\n\tif match &#123;\n\t\tmatchedPtr := &amp;slot[idx]\n\t\tseg.rb.ReadAt(hdrBuf[:], matchedPtr.offset)\n\t\thdr.slotId = slotId\n\t\thdr.hash16 = hash16\n\t\thdr.keyLen = uint16(len(key))\n\t\toriginAccessTime := hdr.accessTime\n\t\thdr.accessTime = now\n\t\thdr.expireAt = expireAt\n\t\thdr.valLen = uint32(len(value))\n\t\tif hdr.valCap >= hdr.valLen &#123;\n\t\t\t//in place overwrite\n\t\t\tatomic.AddInt64(&amp;seg.totalTime, int64(hdr.accessTime)-int64(originAccessTime))\n\t\t\tseg.rb.WriteAt(hdrBuf[:], matchedPtr.offset)\n\t\t\tseg.rb.WriteAt(value, matchedPtr.offset+ENTRY_HDR_SIZE+int64(hdr.keyLen))\n\t\t\tatomic.AddInt64(&amp;seg.overwrites, 1)\n\t\t\treturn\n\t\t&#125;\n\t\t// avoid unnecessary memory copy.\n\t\tseg.delEntryPtr(slotId, slot, idx)\n\t\tmatch = false\n\t\t// increase capacity and limit entry len.\n\t\t// 进行扩容\n\t\tfor hdr.valCap &lt; hdr.valLen &#123;\n\t\t\thdr.valCap *= 2\n\t\t&#125;\n\t\tif hdr.valCap > uint32(maxKeyValLen-len(key)) &#123;\n\t\t\thdr.valCap = uint32(maxKeyValLen - len(key))\n\t\t&#125;\n\t&#125; else &#123;\n\t\thdr.slotId = slotId\n\t\thdr.hash16 = hash16\n\t\thdr.keyLen = uint16(len(key))\n\t\thdr.accessTime = now\n\t\thdr.expireAt = expireAt\n\t\thdr.valLen = uint32(len(value))\n\t\thdr.valCap = uint32(len(value))\n\t\tif hdr.valCap == 0 &#123; // avoid infinite loop when increasing capacity.\n\t\t\thdr.valCap = 1\n\t\t&#125;\n\t&#125;\n\n\tentryLen := ENTRY_HDR_SIZE + int64(len(key)) + int64(hdr.valCap)\n\tslotModified := seg.evacuate(entryLen, slotId, now)\n\tif slotModified &#123;\n\t\t// the slot has been modified during evacuation, we need to looked up for the 'idx' again.\n\t\t// otherwise there would be index out of bound error.\n\t\tslot = seg.getSlot(slotId)\n\t\tidx, match = seg.lookup(slot, hash16, key)\n\t\t// assert(match == false)\n\t&#125;\n\tnewOff := seg.rb.End()\n\t// 将 偏移量(data在 ringbuffer 中的偏移量)写入  slot\n\tseg.insertEntryPtr(slotId, hash16, newOff, idx, hdr.keyLen)\n\t// 写入 ringBuffer\n\t...\n\treturn\n&#125;\n\n\n\n通过 hash(key) 找到对应的 segment\n通过 hash(key) 找到对应的 slot\nslotId :&#x3D; uint8(hashVal &gt;&gt; 8)\nhash16 :&#x3D; uint16(hashVal &gt;&gt; 16)\n\n\n找到  kv 在 slot 中要插入的 位置.   idx\n\n\n如果对应的 key 存在,就进行替换. (如果 该位置的容量 &lt; 要插入的kv, 就将该位置标记为 deleted, 往后面append)\n如果 对应的key不存在,就在 slot 后面进行 append.(如果 空间不足就扩容)\n\n总结:set 操作为什么高效?\n\n通过  hash(key) 计算  bucket 使用 位运算操作\n通过 二分查找 的方式 在 slot中查询 entry\nkey 不存在的场景: \n如果 ringBuffer容量充足, 就直接在 环尾部 append entry. 时间复杂度 是 O(1)\n如果 ringBuffer容量不足,需要将一些 key 移除掉. freeCache 通过一定的措施，保证移除key的操作时间复杂度为 O(1). entry追加操作的时间复杂度也是O(1)\n\n\nkey存在的场景(match) 找到entry索引:\n如果原来预留的entry容量充足.那么直接更新原来的entryHdr 和 value. 时间复杂度是 O(1)\n如果原来预留的entry容量不足: freecache 为了避免底层移动数组数据. 不直接对原来的entry进行扩容,而是将原来的entry标记为删除(懒删除).然后在环形缓冲区默认append 新的entry. 时间复杂度是 O(1).\n\n\n\n2. Get/ Get returns the value or not found error.\nfunc (cache *Cache) Get(key []byte) (value []byte, err error) &#123;\n\thashVal := hashFunc(key)\n\tsegID := hashVal &amp; segmentAndOpVal\n\tcache.locks[segID].Lock()\n\tvalue, _, err = cache.segments[segID].get(key, nil, hashVal, false)\n\tcache.locks[segID].Unlock()\n\treturn\n&#125;\n\n\n\nfunc (seg *segment) get(key, buf []byte, hashVal uint64, peek bool) (value []byte, expireAt uint32, err error) &#123;\n\thdr, ptr, err := seg.locate(key, hashVal, peek)\n\tif err != nil &#123;\n\t\treturn\n\t&#125;\n\texpireAt = hdr.expireAt\n\tif cap(buf) >= int(hdr.valLen) &#123;\n\t\tvalue = buf[:hdr.valLen]\n\t&#125; else &#123;\n\t\tvalue = make([]byte, hdr.valLen)\n\t&#125;\n\n\tseg.rb.ReadAt(value, ptr.offset+ENTRY_HDR_SIZE+int64(hdr.keyLen))\n\tif !peek &#123;\n\t\tatomic.AddInt64(&amp;seg.hitCount, 1)\n\t&#125;\n\treturn\n&#125;\n\n\n找到  segment, 然后 找到 对应的 slot\nseg.locate() 找到 对应的 entryPtr,以及 对应的 entryHdr\n\n要读取的数据在 ringBuffer中的偏移量是   ptr.offset + ENTRY_HDR_SIZR + keyLen\n3. 过期 与删除3.1. key 过期对于过期的数据,freecache会让它继续存储在RingBuf中,RingBuf从一开始初始化之后,就固定不变了. 是否删掉数据,对RingBuf的实际占用空间不会产生影响.当get到一个过期缓存时，freecache会删掉缓存的entry索引(但是不会将缓存从RingBuf中移除), 然后对外报ErrNotFound错误. 当RingBuf的容量不足时,会从环头开始遍历,如果key已经过期，这时才会将它删除掉. 如果一个key已经过期时,在它被freecache删除之前,如果又重新set进来（过期不会主动删除entry索引，理论上有被重新set的可能），过期的entry容量充足的情况下，则会重新复用这个entry.freecache这种过期机制,一方面减少了维护过期数据的工作,另一方面,freecache底层存储是采用数组来实现,要求缓存数据必须连续,缓存过期的剔除会带来空间碎片,挪动数组来维持缓存数据的连续性不是一个很好的选择.\n3.2 key 删除freecache有一下两种情况会进行删除key操作:\n\n外部主动调用del接口删除key.\nset缓存时，发现key已经存在，但是为entry预留的cap不足时，会选择将旧的数据删掉，然后再环尾追加新的数据.\n\nfreecache的删除机制也是懒删除,删除缓存时，只会删掉entry索引,但是缓存还是会继续保留在RingBuf中,只是被标记为删除,等到RingBuf容量不足需要置换缓存时,才会对标记为删除的缓存数据做最后的删除工作. freecache删除一个key,需要搜索entry索引和标记缓存数据.\n4. RingBuffer&#x2F;&#x2F; go doc RingBuf\npackage freecache &#x2F;&#x2F; import &quot;.&quot;\n\ntype RingBuf struct &#123;\n        &#x2F;&#x2F; Has unexported fields.\n&#125;\n    Ring buffer has a fixed size, when data exceeds the size, old data will be\n    overwritten by new data. It only contains the data in the stream from begin\n    to end\n\nfunc NewRingBuf(size int, begin int64) (rb RingBuf)\nfunc (rb *RingBuf) Begin() int64\nfunc (rb *RingBuf) Dump() []byte\nfunc (rb *RingBuf) End() int64\nfunc (rb *RingBuf) EqualAt(p []byte, off int64) bool\nfunc (rb *RingBuf) Evacuate(off int64, length int) (newOff int64)\nfunc (rb *RingBuf) ReadAt(p []byte, off int64) (n int, err error)\nfunc (rb *RingBuf) Reset(begin int64)\nfunc (rb *RingBuf) Resize(newSize int)\nfunc (rb *RingBuf) Size() int64\nfunc (rb *RingBuf) Skip(length int64)\nfunc (rb *RingBuf) Slice(off, length int64) ([]byte, error)\nfunc (rb *RingBuf) String() string\nfunc (rb *RingBuf) Write(p []byte) (n int, err error)\nfunc (rb *RingBuf) WriteAt(p []byte, off int64) (n int, err error)\n\n\n\n实现一个 ringBuffer\n\nfreeCache zeroGC 的Go Cache添加注释的代码\n","slug":"freecache源码解析","date":"2022-10-10T15:59:17.000Z","categories_index":"","tags_index":"golang,cache","author_index":"majm"},{"id":"411297e7dedff7a6e68a4f8255b55a82","title":"bigcache源码解析","content":"[TOC]\nBigcache 的特点:并发支持,快速, 过期大量条目而不影响性能.bigcache将 缓存条目放在了堆上,节省了GC. 为了实现这一点. 需要对字节切片进行操作. 因此涉及到缓存条目的序列化与反序列化.\nbigcache, freecache 和 map 的基准测试\n\n\n\n内存使用情况可能会遇到,系统内存指数增长. 属于预期内行为. Go 运行时 以 跨度(span)为单位分配内存,并在不需要他们是将状态修改为 free 来通知操作系统.在操作系统需要重新调整地址用途之前. 跨度将保留为进程资源的一部分.\n怎么做到的高性能?BigCache依赖于 go1.5中做出的优化.issue9477: 对于key value 中没有指针的map,GC将忽略其内容.因此 bigCache 中使用 map[uint64]uint32, key 为 hash(key). value 是 item的 偏移量.\nitem 保存在字节切片中,目的是为了 再次忽略  GC. 字节切片大小可以增长到 MB 而不影响性能, 因为 GC只能看到指向他们的 单个 指针. \n如何解决 hash 冲突(Hash Collisions)?Bigcache 不解决 hash 冲突. 当一个新的item 与老 item  hash(key)相同. 新 item 会覆盖老item.\nBigcache Vs freecche两种缓存都提供了相同的功能. 但是他们是以不同的方式 减少 GC开销. bigCache 一依赖 map[uint64]uint32, freecache 实现了自己的基于切片的映射 来减少指针数量.\nBigcache 相对于  freecache 的优势之一是: 不需要提前知道  缓存大小,因为 Bigcache 已满时,可以为新item 重新分配额外的内存. 而不是像 freecache 那样覆盖现有的.但是 Bigcache 也提供了参数 HardMaxCacheSize 设置缓存最大大小.\n源码解析1. 一些概念1. shard分片,  用于 减少锁粒度 ,增加并发度.  cache 默认 有 1024 个分片. (需要时  2^n,  快速进行 hash计算)shards 初始化以后是 不可以扩容的.\n2. CleanWindow删除过期entry 的  时间间隔(interval).默认配置为 1s. 如果设置为  &lt; 1s, 可能会适得其反.\n3. lifeWindowentry 的过期时间. \n\n\n\n\n\n\n\n\n\nbigcache 的一个feature: 不支持为 特定的entry 单独设置  过期时间. \n2. 数据结构\n1. cache\n// BigCache is fast, concurrent, evicting cache created to keep big number of entries without impact on performance.\n// It keeps entries on heap but omits GC for them. To achieve that, operations take place on byte arrays,\n// therefore entries (de)serialization in front of the cache will be needed in most use cases.\ntype BigCache struct &#123;\n\tshards     []*cacheShard // shard分片 减小锁粒度,长度为 2^N\n\tlifeWindow uint64\n\tclock      clock // 时钟,计算过期时间 会用到\n\thash       Hasher // hash 算法 分 shard\n\tconfig     Config\n\tshardMask  uint64 // 2^N-1\n\tclose      chan struct&#123;&#125;\n&#125;\n\n\n\n\n2. shard\ntype cacheShard struct &#123;\n\thashmap     map[uint64]uint32 //存储索引 key: hashKey  value: value存入  byteQueue的 offset\n\tentries     queue.BytesQueue  // 存储实际的数据 的 环形字节数组\n\tlock        sync.RWMutex      // 锁\n\tentryBuffer []byte            //\n\tonRemove    onRemoveCallback  // 回调函数, 有多种实现方式\n\n\tisVerbose    bool\n\tstatsEnabled bool\n\tlogger       Logger\n\tclock        clock\n\tlifeWindow   uint64\n\n\thashmapStats map[uint64]uint32 // 记录 key的 requestCount\n\tstats        Stats             // shard 的 缓存 统计状态\n\tcleanEnabled bool              // 是否开启 清理\n&#125;\n\n\n\n3. entry\n&#x2F;&#x2F; EntryInfo holds informations about entry in the cache\ntype EntryInfo struct &#123;\n\ttimestamp uint64\n\thash      uint64\n\tkey       string\n\tvalue     []byte\n\terr       error\n&#125;\n\ntimestamp: 8byte.Hash:      8byte.keyLen:    2byte.key:       Nbyte.value:     Nbyte.&#x2F;&#x2F; headerSize(timestamp + hash + keyLen)  &#x3D; 18byte\n将 kv 包装成 entry.\n// header                | kv\n// timestamp|hash|keySize|key|value\nfunc wrapEntry(timestamp uint64, hash uint64, key string, entry []byte, buffer *[]byte) []byte &#123;\n\tkeyLength := len(key)\n\tblobLength := len(entry) + headersSizeInBytes + keyLength\n\n\t// 如果 blob 长度 > buffer,重新申请一个  buffer\n\tif blobLength > len(*buffer) &#123;\n\t\t*buffer = make([]byte, blobLength)\n\t&#125;\n\tblob := *buffer\n\n\tbinary.LittleEndian.PutUint64(blob, timestamp)\n\tbinary.LittleEndian.PutUint64(blob[timestampSizeInBytes:], hash)\n\tbinary.LittleEndian.PutUint16(blob[timestampSizeInBytes+hashSizeInBytes:], uint16(keyLength))\n\tcopy(blob[headersSizeInBytes:], key)\n\tcopy(blob[headersSizeInBytes+keyLength:], entry)\n\n\treturn blob[:blobLength]\n&#125;\n\n解析 entry 为 kv 结构:\n// 读取 value:  array[headersSizeInBytes + keyLen:]\nfunc readEntry(data []byte) []byte &#123;\n\t// 读取 keyLen\n\tlength := binary.LittleEndian.Uint16(data[timestampSizeInBytes+hashSizeInBytes:])\n\n\t// copy on read\n\tdst := make([]byte, len(data)-int(headersSizeInBytes+length))\n\tcopy(dst, data[headersSizeInBytes+length:])\n\n\treturn dst\n&#125;\n\n// 读取 timestamp:  uint64(array)\nfunc readTimestampFromEntry(data []byte) uint64 &#123;\n\treturn binary.LittleEndian.Uint64(data)\n&#125;\n\n// 读取 key:  array[headerSize:headerSize + keyLen]\nfunc readKeyFromEntry(data []byte) string &#123;\n\tlength := binary.LittleEndian.Uint16(data[timestampSizeInBytes+hashSizeInBytes:])\n\n\t// copy on read\n\tdst := make([]byte, length)\n\tcopy(dst, data[headersSizeInBytes:headersSizeInBytes+length])\n\n\treturn bytesToString(dst)\n&#125;\n\n// compare key and entry.\nfunc compareKeyFromEntry(data []byte, key string) bool &#123;\n\tlength := binary.LittleEndian.Uint16(data[timestampSizeInBytes+hashSizeInBytes:])\n\n\treturn bytesToString(data[headersSizeInBytes:headersSizeInBytes+length]) == key\n&#125;\n\n//  读取 hash:  uint64(array[timestampSizeinByte:])\nfunc readHashFromEntry(data []byte) uint64 &#123;\n\treturn binary.LittleEndian.Uint64(data[timestampSizeInBytes:])\n&#125;\n\n\n4. byteQueue实际存储数据.\ntype BytesQueue struct &#123;\n\tfull         bool\n\tarray        []byte\n\tcapacity     int\n\tmaxCapacity  int\n\thead         int\n\ttail         int\n\tcount        int\n\trightMargin  int\n\theaderBuffer []byte\n\tverbose      bool\n&#125;\n\n一个  kv 结构 是一个 entry. entry 存储在 array 里面.   通过 offset 来进行访问.\n3. 常用方法3.1  缓存初始化// NewBigCache initialize new instance of BigCache\nfunc NewBigCache(config Config) (*BigCache, error) &#123;\n\treturn newBigCache(config, &amp;systemClock&#123;&#125;)\n&#125;\n\nfunc newBigCache(config Config, clock clock) (*BigCache, error) &#123;\n\t// param check\n\tif config.Hasher == nil &#123;\n\t\tconfig.Hasher = newDefaultHasher()\n\t&#125;\n\n\tcache := &amp;BigCache&#123;\n\t\tshards:     make([]*cacheShard, config.Shards),\n\t\tlifeWindow: uint64(config.LifeWindow.Seconds()),\n\t\tclock:      clock,\n\t\thash:       config.Hasher,\n\t\tconfig:     config,\n\t\tshardMask:  uint64(config.Shards - 1), // 用于 快速计算 hash 值\n\t\tclose:      make(chan struct&#123;&#125;),    // 接收 close 信号的 一个 chan, 关闭主动清理任务\n\t&#125;\n\n\t// 设置 onremove 回调函数\n\tvar onRemove func(wrappedEntry []byte, reason RemoveReason)\n\tif config.OnRemoveWithMetadata != nil &#123;\n\t\tonRemove = cache.providedOnRemoveWithMetadata\n\t&#125; else if config.OnRemove != nil &#123;\n\t\tonRemove = cache.providedOnRemove\n\t&#125; else if config.OnRemoveWithReason != nil &#123;\n\t\tonRemove = cache.providedOnRemoveWithReason\n\t&#125; else &#123;\n\t\tonRemove = cache.notProvidedOnRemove\n\t&#125;\n\n\t// 逐个初始化  shard\n\tfor i := 0; i &lt; config.Shards; i++ &#123;\n\t\tcache.shards[i] = initNewShard(config, onRemove, clock)\n\t&#125;\n\n\t// 主动清理  过期数据\n\tif config.CleanWindow > 0 &#123;\n\t\tgo func() &#123;\n\t\t\tticker := time.NewTicker(config.CleanWindow)\n\t\t\tdefer ticker.Stop()\n\t\t\tfor &#123;\n\t\t\t\tselect &#123;\n\t\t\t\tcase t := &lt;-ticker.C:\n\t\t\t\t\tcache.cleanUp(uint64(t.Unix())) // 进行过期数据清理\n\t\t\t\tcase &lt;-cache.close:\n\t\t\t\t\treturn\n\t\t\t\t&#125;\n\t\t\t&#125;\n\t\t&#125;()\n\t&#125;\n\n\treturn cache, nil\n&#125;\n\n\n\n\n\n3.2 Get// Get reads entry for the key.\n// It returns an ErrEntryNotFound when\n// no entry exists for the given key.\nfunc (c *BigCache) Get(key string) ([]byte, error) &#123;\n\thashedKey := c.hash.Sum64(key)\n\tshard := c.getShard(hashedKey) // 取余操作,    c.shards[hashedKey&amp;c.shardMask]\n\treturn shard.get(key, hashedKey) // 调用 shard.get 获取  value\n&#125;\n\nbigcache.hash 默认使用  fnv hash算法.  new 64-bit FNV-1a Hasher 算法 可以 0 内存申请.\nshard.Get\nfunc (s *cacheShard) get(key string, hashedKey uint64) ([]byte, error) &#123;\n\t// 加 读锁, 保护   hashmap\n\ts.lock.RLock()\n\twrappedEntry, err := s.getWrappedEntry(hashedKey)\n\tif err != nil &#123;\n\t\ts.lock.RUnlock()\n\t\treturn nil, err\n\t&#125;\n\t// 判断 key 是否相同. 当发生hash冲突时,如果 key不相同, 直接返回 ErrEntryNotFound\n\t// bigcache 不解决 hash Collision\n\tif entryKey := readKeyFromEntry(wrappedEntry); key != entryKey &#123;\n\t\ts.lock.RUnlock()\n\t\ts.collision()\n\t\tif s.isVerbose &#123;\n\t\t\ts.logger.Printf(\"Collision detected. Both %q and %q have the same hash %x\", key, entryKey, hashedKey)\n\t\t&#125;\n\t\t// 如果  key 不存在, 返回  `ErrEntryNotFound`\n\t\treturn nil, ErrEntryNotFound\n\t&#125;\n\t// entry: value的 字节数组\n\tentry := readEntry(wrappedEntry)\n\ts.lock.RUnlock()\n\ts.hit(hashedKey)\n\n\treturn entry, nil\n&#125;\n\n\n\n\n3.3 Set\n// Set saves entry under the key\nfunc (c *BigCache) Set(key string, entry []byte) error &#123;\n\thashedKey := c.hash.Sum64(key) // 计算 hash 值\n\tshard := c.getShard(hashedKey) // 根据  取余 计算 分片 \n\treturn shard.set(key, hashedKey, entry) //\n&#125;\n\n\nshard ：\n\nfunc (s *cacheShard) set(key string, hashedKey uint64, entry []byte) error &#123;\n\tcurrentTimestamp := uint64(s.clock.Epoch())\n\n\ts.lock.Lock()\n\n\t// hash Collision| key 已存在(并未进行更新), 将原来的 entry 软删除\n\tif previousIndex := s.hashmap[hashedKey]; previousIndex != 0 &#123;\n\t\tif previousEntry, err := s.entries.Get(int(previousIndex)); err == nil &#123;\n\t\t\tresetKeyFromEntry(previousEntry)\n\t\t\t//remove hashkey\n\t\t\tdelete(s.hashmap, hashedKey)\n\t\t&#125;\n\t&#125;\n\n    // 如果 未开启  定时 清理任务, 那么 主动调用, 将最早的数据 清理(如果过期)\n\tif !s.cleanEnabled &#123;\n\t\tif oldestEntry, err := s.entries.Peek(); err == nil &#123;\n\t\t\ts.onEvict(oldestEntry, currentTimestamp, s.removeOldestEntry)\n\t\t&#125;\n\t&#125;\n\n    // 将kv 封装成  entry. ( 从这个方法里面可以 看出 entry 的 数据结构.)\n\tw := wrapEntry(currentTimestamp, hashedKey, key, entry, &amp;s.entryBuffer)\n\n\t//  循环目的是为了 保证 一定放入 数据成功.\n\tfor &#123;\n\t\t// 放入  entrys 中  (bytesQueue)\n\t\tif index, err := s.entries.Push(w); err == nil &#123; // Push() 也可以看一下\n\t\t\ts.hashmap[hashedKey] = uint32(index)\n\t\t\ts.lock.Unlock()\n\t\t\treturn nil\n\t\t&#125;\n\t\t// 如果 放入 失败, (空间不足, 那么 就用 LRU算法, 清理出空间)\n\t\tif s.removeOldestEntry(NoSpace) != nil &#123;\n\t\t\ts.lock.Unlock()\n\t\t\treturn fmt.Errorf(\"entry is bigger than max shard size\")\n\t\t&#125;\n\t&#125;\n&#125;\n\n\n\n\n\n\n\n\n\n\n\nbigcache 为何不提供更新的操作? 其实这是显而易见的:\n每次插入元素, bigCache 会根据插入的 key 和 value 在 BytesQueue 中申请一个固定大小的空间. 因为无法保证更新的 value 值和旧的 value 长度相同(这也是数据定长存储的劣势),这样对 bigcache &gt; 来说，按照时间顺序的 head 和 tail 索引值会乱掉,所以干脆就不提供更新接口了.\nwrapEntry\n// header                | kv\n// timestamp|hash|keySize|key|value\nfunc wrapEntry(timestamp uint64, hash uint64, key string, entry []byte, buffer *[]byte) []byte &#123;\n\tkeyLength := len(key)\n\tblobLength := len(entry) + headersSizeInBytes + keyLength\n\n\t// 如果 blob 长度 > buffer,重新申请一个  buffer\n\tif blobLength > len(*buffer) &#123;\n\t\t*buffer = make([]byte, blobLength)\n\t&#125;\n\tblob := *buffer\n\n\tbinary.LittleEndian.PutUint64(blob, timestamp)\n\tbinary.LittleEndian.PutUint64(blob[timestampSizeInBytes:], hash)\n\tbinary.LittleEndian.PutUint16(blob[timestampSizeInBytes+hashSizeInBytes:], uint16(keyLength))\n\tcopy(blob[headersSizeInBytes:], key)\n\tcopy(blob[headersSizeInBytes+keyLength:], entry)\n\n\treturn blob[:blobLength]\n&#125;\n\n\n\n\n\n3.4 Delete// Delete removes the key\nfunc (c *BigCache) Delete(key string) error &#123;\n\thashedKey := c.hash.Sum64(key)\n\tshard := c.getShard(hashedKey)\n\treturn shard.del(hashedKey)\n&#125;\n\n\nshard.del()\n\n// Optimistic 乐观锁机制\n// 主动删除, 将 entry 中 hash值 置为 0， 如果 不存在,直接返回, 不用加写锁\nfunc (s *cacheShard) del(hashedKey uint64) error &#123;\n\t// Optimistic pre-check using only readlock\n\ts.lock.RLock()\n\t&#123;\n\t\titemIndex := s.hashmap[hashedKey]\n\n\t\tif itemIndex == 0 &#123;\n\t\t\ts.lock.RUnlock()\n\t\t\ts.delmiss()\n\t\t\treturn ErrEntryNotFound\n\t\t&#125;\n\n\t\tif err := s.entries.CheckGet(int(itemIndex)); err != nil &#123;\n\t\t\ts.lock.RUnlock()\n\t\t\ts.delmiss()\n\t\t\treturn err\n\t\t&#125;\n\t&#125;\n\ts.lock.RUnlock()\n\n\ts.lock.Lock()\n\t&#123;\n\t\t// After obtaining the writelock, we need to read the same again,\n\t\t// since the data delivered earlier may be stale now\n\t\titemIndex := s.hashmap[hashedKey]\n\n\t\tif itemIndex == 0 &#123;\n\t\t\ts.lock.Unlock()\n\t\t\ts.delmiss()\n\t\t\treturn ErrEntryNotFound\n\t\t&#125;\n\n\t\twrappedEntry, err := s.entries.Get(int(itemIndex))\n\t\tif err != nil &#123;\n\t\t\ts.lock.Unlock()\n\t\t\ts.delmiss()\n\t\t\treturn err\n\t\t&#125;\n\n\t\tdelete(s.hashmap, hashedKey)\n\t\ts.onRemove(wrappedEntry, Deleted)\n\t\tif s.statsEnabled &#123;\n\t\t\tdelete(s.hashmapStats, hashedKey)\n\t\t&#125;\n\t\t// 将 entry 中的 hash值 置为0,表示删除. (并不是立即回收空间)\n\t\tresetKeyFromEntry(wrappedEntry)\n\t&#125;\n\ts.lock.Unlock()\n\n\ts.delhit()\n\treturn nil\n&#125;\n\n\n\n\n\n\n4. BytesQueueBytesQueue 是一个循环数组, 存储 entry 数据. 通过 offset 来进行访问. 减少 GC 开销. (shard 中的 hashmap 存储的是  hash(key) 与 offset 的映射关系).\n\nbytesQueue 的几个特点: \n\n存储的 entry  不会是  截断的. (一部分数据在tail, 一部分数据在  头部.)\nentry 的数据格式:   如上图所示.\n\n// go doc queue BytesQueue\npackage queue // import \"github.com/allegro/bigcache/v3/queue\"\n\ntype BytesQueue struct &#123;\n        // Has unexported fields.\n&#125;\n    BytesQueue is a non-thread safe queue type of fifo based on bytes array. For\n    every push operation index of entry is returned. It can be used to read the\n    entry later\n\nfunc NewBytesQueue(capacity int, maxCapacity int, verbose bool) *BytesQueue\nfunc (q *BytesQueue) Capacity() int\nfunc (q *BytesQueue) CheckGet(index int) error\nfunc (q *BytesQueue) Get(index int) ([]byte, error)\nfunc (q *BytesQueue) Len() int\nfunc (q *BytesQueue) Peek() ([]byte, error)\nfunc (q *BytesQueue) Pop() ([]byte, error)\nfunc (q *BytesQueue) Push(data []byte) (int, error)\nfunc (q *BytesQueue) Reset()\n\n\n\n\n\nbigcache 的缺点 和使用中要注意的点:\nbigcache 不支持 为单个key 设置 过期时间, bigcache 中所有的 key 的过期时间是一样的. (如果有需求自己开发)\nbigcache set key 时 不会 更新 entry, 而是将原来的 entry 软删除, 在append 一个entry.\n无持久化功能, 只能用作单机缓存\nBytesQueue 的扩容操作可能会影响性能\n\n\n[参考]Writing a very fast cache service with millions of entries in GoGolang 高性能 LocalCache：BigCache 设计与分析Golang 中map与GC“纠缠不清”的关系源码\n","slug":"bigcache源码解析","date":"2022-10-10T15:58:44.000Z","categories_index":"","tags_index":"golang,cache,bigcache","author_index":"majm"},{"id":"abbd863cb849430f5ba6ae97c8807bd7","title":"大数据相关的一些名词","content":"\n\n\n\n\n\n\n\n\n据仓库(data warehouse) 也可以简称为 DW DH\n\n\n数据仓库中的分层:1. 数据运营层 ODS\nODS(Operation Data Store):  数据准备区,最接近数据源的一层, 也称为 贴源层. 数据仓库中 源头系统的数据通常会原封不动的存储一份. 这称为为  ODS. 是后续数据仓库加工数据的来源.\n\nODS 数据来源的方式:\n\n业务数据库\n经常会使用sqoop来抽取，例如每天定时抽取一次。\n实时方面,可以考虑用canal监听mysql的binlog，实时接入即可.\n\n\n埋点日志\n日志一般以文件的形式保存，可以选择用flume定时同步\n也可以采用 spark Streaming, flink 来做实时同步\nkafka也ok\n\n\n消息队列\nkafka, rabbitMQ\n\n\n\n\n\n2. 数据仓库层 DW\n\n\n\n\n\n\n\n\nDW 数据分层,由上至下 可以分为:   DWD, DWB, DWS\n\nDWD(data warehouse deatils):   细节数据层,是业务层与数据仓库层的隔离层, 主要是对 ODS做一些数据清洗和  规范化的操作.\n\n去除空值,脏数据,超过规范极限的…\n\n\nDWB(data warehouse base):   数据基础层, 存储的是客观数据,一般用作中间层,可以认为是大量指标的数据层.\n\n一般是由数据明细层 按照一定的业务需求,生成轻度汇总表. 明细层需要复杂清洗的数据和需要MR处理的数据也经过处理后接入到轻度汇总层.\n日志存储方式: 内表，parquet文件格式.\n日志删除方式: 长久存储.\n表schema: 一般按天创建分区,没有时间概念的按具体业务选择分区字段.\n库与表命名: 库名:dwb,表名:初步考虑格式为:dwb日期业务表名,待定.\n旧数据更新方式: 直接覆盖\n\n\nDWS(data warehouse service):  数据服务层, 基于 DWB的基础数据,整合汇总成分析某一个主题域的数据服务层. 一般是宽表. 用于提供后续的业务查询. OLAP 数据分析， 数据分发…\n\n用户行为轻度聚合\n主要是对  DWD DWB 的数据做一些轻度汇总.\n数据宽表, 按照业务划分,如流量、订单、用户等, 生成字段比较多的宽表,用于提供后续的业务查询,OLAP分析,数据分发等.\n数据生成方式: 由轻度汇总层和明细层数据计算生成.\n日志存储方式:使用impala内表，parquet文件格式\n日志删除方式:长久存储\n表schema:一般按天创建分区,没有时间概念的按具体业务选择分区字段.\n库与表命名:库名:dm,表名:初步考虑格式为：dm日期业务表名,待定.\n旧数据更新方式: 直接覆盖\n\n\n\n3. 数据服务层,应用层  ADS\nADS(Application Data Service): 应用数据服务，该层主要是提供数据产品和数据分析使用的数据，一般会存储在ES、mysql等系统中供线上系统使用。我们通过说的报表数据，或者说那种大宽表，一般就放在这里\n\nETL(Extract-Transform-Load): 用于描述将数据从来源端经过抽取、转换、加载到目的端的过程。\n\n宽表:  指字段比较多的数据库表. 通常是指业务主体相关的指标,纬度,属性关联在一起的一张数据库表.\n\n宽表由于把不同的内容都放在同一张表，宽表已经不符合三范式的模型设计规范：\n坏处:数据有大量冗余\n好处:查询性能的提高和便捷\n\n\n宽表的设计广泛应用于数据挖掘模型训练前的数据准备,通过把相关字段放在同一张表中,可以大大提供数据挖掘模型训练过程中迭代计算的消息问题.\n\n\n\n\n[参考]数据仓库分层中的ODS、DWD、DWS【漫谈数据仓库】 如何优雅地设计数据分层 ODS DW DM层级数据仓库–通用的数据仓库分层方法\n","slug":"大数据相关的一些名词","date":"2022-09-09T16:36:11.000Z","categories_index":"bigdata","tags_index":"bigdata","author_index":"majm"},{"id":"c851ed248b05eaa2eb5ed28481ee6148","title":"Go Context 使用场景","content":"context 使用场景1 超时控制实际使用中, context 经常和 select 关键字一起使用. 用于监听  context 结束 取消.\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc testTimeout() &#123;\n\ttimerCtx, cancelFunc := context.WithTimeout(context.Background(), 1*time.Second)\n\tdefer cancelFunc()\n\n\tuseContext(timerCtx)\n&#125;\n\nfunc useContext(ctx context.Context) &#123;\n\tch := make(chan struct&#123;&#125;)\n\tgo func() &#123;\n\t\tprocessLogic()\n\t\tch &lt;- struct&#123;&#125;&#123;&#125;\n\t&#125;()\n\t//process\n\tselect &#123;\n\tcase &lt;-ctx.Done():\n\t\tfmt.Println(\"上下文取消 or 超时.\")\n\tcase &lt;-ch:\n\t\tfmt.Println(\"process log  succeess.\")\n\t&#125;\n&#125;\n\nfunc processLogic() &#123;\n\ttime.Sleep(time.Second * 2)\n&#125;\n\n\n\n其中 timerContext 是可以 在 上下文链路中传递, 当上游配置 timeout， 调用 下游 服务时, 如果 超时 , 可以通过 context 级联取消下游服务的处理, 避免下游服务占用资源.(已经超时了, 还在处理业务)\n2.  Request Scope 传递共享数据比如 在 http 请求中, 传递 traceID, userID…\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n)\n\ntype requestKeyType string\n\n// 避免冲突. \nvar requestIdKey = requestKeyType(\"requestID\")\n\nfunc initHttp() &#123;\n\th := WithRequestID(Handle)\n\terr := http.ListenAndServe(\":8080\", h)\n\tif err != nil &#123;\n\t\tpanic(err)\n\t&#125;\n&#125;\n\nfunc WithRequestID(next http.HandlerFunc) http.Handler &#123;\n\treturn http.HandlerFunc(\n\t\tfunc(w http.ResponseWriter, r *http.Request) &#123;\n\t\t\t// 从header 中提取 requestID\n\t\t\trequestID := r.Header.Get(\"X-Request-ID\")\n\t\t\tvalCtx := context.WithValue(r.Context(), requestIdKey, requestID)\n\t\t\t// 构建 新的请求\n\t\t\tr = r.WithContext(valCtx)\n\t\t\t//调用 http处理函数\n\t\t\tnext.ServeHTTP(w, r)\n\t\t&#125;,\n\t)\n&#125;\n\nfunc Handle(writer http.ResponseWriter, request *http.Request) &#123;\n\trequestID, ok := request.Context().Value(requestIdKey).(string)\n\tif !ok &#123;\n\t\treturn\n\t&#125;\n\tfmt.Println(requestID)\n\twriter.Write([]byte(requestID))\n&#125;\n\n\n\n3. tracing 组件中 carrier  SpanContextcontext 注意事项- 对第三方调用要传入 context, 用于控制远程调用\n- 不要将上下文存储在结构类型中,尽可能的作为函数第一位形参传入.\n- 函数调用链必须传播上下文,实现完整链路上的控制\n- context 的继承和派生, 保证父、子级 context 的联动\n- 不传递 nil context,不确定的 context 应当使用 TODO\n- context 仅传递必要的值, 不要让可选参数揉在一起\n\n\n1.  对第三方调用要传入 context, 用于控制远程调用在 golang 中 对 context 的 使用 已经是 约定俗成的规定, 因此 使用第三方 服务的时候, 要传入 context.\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"time\"\n)\n\nfunc httpTimeout() &#123;\n\treq, err := http.NewRequest(\"GET\", \"https://google.com\", nil)\n\tif err != nil &#123;\n\t\tpanic(err)\n\t&#125;\n\n\ttimerCtx, cancelFunc := context.WithTimeout(context.Background(), 1*time.Second)\n\tdefer cancelFunc()\n\n\treq = req.WithContext(timerCtx)\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil &#123;\n\t\tfmt.Printf(\"http.DefaultClient.Do error, err = %v \\n\", err)\n\t\treturn\n\t&#125;\n\tdefer resp.Body.Close()\n&#125;\n\n\n\n这样子由于第三方开源库已经实现了根据 context 的超时控制,那么当你所传入的时间到达时，将会中断调用.若你发现第三方开源库没支持 context, 那就 看看 是否要使用,否则出问题 没有   简单的控制手段.\n2. 不要将上下文存储在结构类型中,尽可能的作为函数第一位形参传入.在 golang 中, 所有的第三方库, 开源代码. 清一色的 会将context 作为方法的第一个参数. 并且命名为  ctx.标准要求: context 作为方法的第一个参数,并且命名为 ctx\n当然也有极少数情况 会将 context 放在结构体里面,基本常见于:\n\nDDD 架构\n底层基础库\n\n每个请求都是独立的,context也就不一样,想清楚业务场景最重要.否则 遵循 go基本规范就好.\n3. Trace 函数调用链必须传播上下文,实现完整链路上的控制把 context 作为方法第一个参数,本质是为了 传播 context, 完成调用链路的跟踪和 控制.\nimport (\n\t\"context\"\n\t\n\t\"github.com/jmoiron/sqlx\"\n\t\"github.com/opentracing/opentracing-go\"\n\t\"github.com/pkg/errors\"\n)\n\ntype User struct &#123;\n&#125;\n\nfunc List(ctx context.Context, db *sqlx.DB) ([]User, error) &#123;\n\tspan, ctx := opentracing.StartSpanFromContext(ctx, \"internal.user.List\")\n\tdefer span.Finish()\n\n\tusers := []User&#123;&#125;\n\tconst q = `SELECT * FROM users`\n\n\tif err := db.SelectContext(ctx, &amp;users, q); err != nil &#123;\n\t\treturn nil, errors.Wrap(err, \"selecting users\")\n\t&#125;\n\n\treturn users, nil\n&#125;\n\n\n4. context 的继承和派生, 保证父、子级 context 的联动ctx := context.Background()\nctx1, _ := context.WithCancel(ctx)\nctx2, _ := context.WithDeadline(ctx, time.Now().Add(time.Second))\nctx3, _ := context.WithTimeout(ctx, time.Second)\nctx4 := context.WithValue(ctx, \"key\", \"value\")\nctx5 := conetext.WithValue(ctx2, \"key\", \"value\")\n\n\ncontext Value的查找是 回溯树的方式.(由下至上)cancel 一个节点, 会 cancel其所有子节点.(由上至下)\n5. 不传递 nil context,不确定的 context 应当使用 TODO在实际使用 context中,对于不知道使用什么类型的 context的时候,使用 context.TODO()  代替，直到了解清楚 context 的实际用途, 在进行替换.\n$$\n6. context 仅传递必要的值, 不要让可选参数揉在一起我们在使用 context 作为上下文时，经常有信息传递的诉求.像是在 gRPC 中就会有 metadata 的概念, 而在 gin 中就会自己封装 context 作为参数管理.\n\n[参考]分享 Go 使用 Context 的正式姿势Contex 的作用Go Concurrency Patterns: Context\n","slug":"Go-Context-使用场景","date":"2022-08-31T03:04:55.000Z","categories_index":"","tags_index":"golang,context","author_index":"majm"},{"id":"bd18eec6e0045068932a65759db44fe4","title":"Go源码-context","content":"在go服务器中,通常 每个传入的请求都会在自己的goroutine中进行处理. 请求处理程序通常会启动额外的goroutine来访问数据库 或者第三方服务.处理请求的一组goroutine通常需要访问特定于请求的值: 例如userid, request_id, token,timeout…,当请求被取消或者超时时,所有处理该请求的goroutine都应该快速退出. 以便系统可以快速回收他们正在使用的任何资源.\ncontext 是 go 1.14 引入 的一个概念. 用于解决上述问题.\n\n\ncontext 源码解析\ncontext.Context\n// Context 是协程安全的,context 的方法可以被多个协程同时调用\ntype Context interface &#123;\n\n    // \n\tDeadline() (deadline time.Time, ok bool)\n\n\t// 返回一个 channel,当 这个 context 被取消时,这个channel 会写入一个 struct\n\tDone() &lt;-chan struct&#123;&#125;\n\n\t// Done 还没有被关闭， 返回  nil\n    // 如果  Done  已经被关闭, 返回 error:\n    // - Canceled\n    // - DeadlineExceeded\n    // 一旦返回 error,这个方法之后就是幂等的\n\tErr() error\n\n\t// \n\tValue(key any) any\n&#125;\n\n\n\n\nDeadline如果 该 Context 被设置了超时，该函数返回  true &amp; 对应的超时时间， 否则 返回 false &amp; nil.\n\nDone\n\n\n返回一个只读 Channel, 但context 主动取消或者 自动超时取消时，该 context 以及 该context 的所有 子context 的 Done channel 都会被 close.级联取消所有的子过程.\n\nErr()\n\nDone() 返回的 channel被 close 之前 会返回nil.在 close 之后会返回error(表示比关闭的原因).\n// Canceled is the error returned by Context.Err when the context is canceled.\nvar Canceled = errors.New(\"context canceled\")\n// DeadlineExceeded is the error returned by Context.Err when the context's\n// deadline passes.\nvar DeadlineExceeded error = deadlineExceededError&#123;&#125;\n\n\n\nValue(key any) any\n\n返回绑定在 该 context 上 给定 key 对应的 value.  如果没有 返回 nil.\n为了防止Key冲突,最好将 key设置为 非导出类型,然后为其定义访问器.(这在许多开源项目中都有影子)\nkey可是任意可比较的类型.\n下面是一个 context 共享 User 信息的 一个例子.\npackage user\nimport \"context\"\n\n// User 是 要存储在Context中的value 的类型.\ntype User struct &#123;...&#125;\n\n// key 被定义为非导出类型 为了防止与其他包冲突\n// key is an unexported type for keys defined in this package.\n// This prevents collisions with keys defined in other packages.\ntype key int\n\n// userKey 用来关联 请求中的user信息, 绑定在 context上.他是非导出的.\n// 通过  NewContext &amp; FromContext 来设置和读取  user.User 信息， 而不是直接使用 userKey.\n// userKey is the key for user.User values in Contexts. It is\n// unexported; clients use user.NewContext and user.FromContext\n// instead of using this key directly.\nvar userKey key\n\n// 携带 value\n// NewContext returns a new Context that carries value u.\nfunc NewContext(ctx context.Context, u *User) context.Context &#123;\n    return context.WithValue(ctx, userKey, u)\n&#125;\n\n//读取 context 中的 存储的 user信息\n// FromContext returns the User value stored in ctx, if any.\nfunc FromContext(ctx context.Context) (*User, bool) &#123;\n    u, ok := ctx.Value(userKey).(*User)\n    return u, ok\n&#125;\n\n\ncontext.Context 的实现.\n1. emptyContextemtptyContext 不是一个结构体,而是一个int类型,这样每一个值 都有独立的地址. 是 Context 的一个空的实现\nvar (\n\tbackground = new(emptyCtx)\n\ttodo       = new(emptyCtx)\n)\n\ncontext.Background() 通常被用作根节点,不能被取消,也不会超时.通过 WithCancel 从 context.Background() 派生出的 Context 要注意在对应过程完结后及时 cancel, 否则会造成 Context 泄露.\n// An emptyCtx is never canceled, has no values, and has no deadline. It is not\n// struct&#123;&#125;, since vars of this type must have distinct addresses.\ntype emptyCtx int\n\nfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123;\n\treturn\n&#125;\n\nfunc (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123;\n\treturn nil\n&#125;\n\nfunc (*emptyCtx) Err() error &#123;\n\treturn nil\n&#125;\n\nfunc (*emptyCtx) Value(key any) any &#123;\n\treturn nil\n&#125;\n\nfunc (e *emptyCtx) String() string &#123;\n\tswitch e &#123;\n\tcase background:\n\t\treturn \"context.Background\"\n\tcase todo:\n\t\treturn \"context.TODO\"\n\t&#125;\n\treturn \"unknown empty Context\"\n&#125;\n\n\n\n\n2. context.cancelCtxcontext核心实现在这里,包括树形结构的构建 以及 进行级联取消.\n// A cancelCtx can be canceled. When canceled, it also cancels any children\n// that implement canceler.\ntype cancelCtx struct &#123;\n\tContext\n\n\tmu       sync.Mutex            // protects following fields 保护下面的字段\n\tdone     atomic.Value          // of chan struct&#123;&#125;, created lazily, closed by first cancel call\n\tchildren map[canceler]struct&#123;&#125; // set to nil by the first cancel call\n\terr      error                 // set to non-nil by the first cancel call\n&#125;\n\n// 递归查找 parentCtx 中第一个  cancelCtx\nfunc (c *cancelCtx) Value(key any) any &#123;\n\tif key == &amp;cancelCtxKey &#123; // \n\t\treturn c\n\t&#125;\n\treturn value(c.Context, key)\n&#125;\n\nfunc (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123;\n\td := c.done.Load()\n\tif d != nil &#123;\n\t\treturn d.(chan struct&#123;&#125;)\n\t&#125;\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\td = c.done.Load()\n\tif d == nil &#123;\n\t\td = make(chan struct&#123;&#125;)\n\t\tc.done.Store(d)\n\t&#125;\n\treturn d.(chan struct&#123;&#125;)\n&#125;\n\nfunc (c *cancelCtx) Err() error &#123;\n\tc.mu.Lock()\n\terr := c.err\n\tc.mu.Unlock()\n\treturn err\n&#125;\n\n// cancel closes c.done, cancels each of c's children, and, if\n// removeFromParent is true, removes c from its parent's children.\n// cancel  关闭 c.done, 关闭 context 及其所有子节点. 如果  removeFromParent = true, 那么将会把 context 从起 父节点移除.\nfunc (c *cancelCtx) cancel(removeFromParent bool, err error) &#123;\n\tif err == nil &#123;\n\t\tpanic(\"context: internal error: missing cancel error\")\n\t&#125;\n\t// process\n\tc.mu.Lock()\n\tif c.err != nil &#123;\n\t\tc.mu.Unlock()\n\t\treturn // already canceled\n\t&#125;\n\tc.err = err\n\td, _ := c.done.Load().(chan struct&#123;&#125;)\n\tif d == nil &#123;\n\t\tc.done.Store(closedchan)\n\t&#125; else &#123;\n\t\tclose(d)\n\t&#125;\n\t// 遍历子节点,  递归调用 子节点的 cancel()\n\tfor child := range c.children &#123;\n\t\t// NOTE: acquiring the child's lock while holding parent's lock.\n\t\tchild.cancel(false, err)\n\t&#125;\n\tc.children = nil\n\tc.mu.Unlock()\n\n\t// c.Context 保存的是其 父节点\n\tif removeFromParent &#123;\n\t\tremoveChild(c.Context, c)\n\t&#125;\n&#125;\n\n\ncancelContext.Value() 方法  遇到特殊keycancelCtxKey 时会返回自身, 其实这是 复用了  Value()的 回溯逻辑(后面回溯树构建中会用到).从而在 context树种回溯遍历时, 可以找到给定context中的第一个祖先 cancelContext实例.\nWithCancel:WithCancel() 通过 调用propagateCancel()  实现回溯树的构建.\n\n// WithCancel returns a copy of parent with a new Done channel. The returned\n// context's Done channel is closed when the returned cancel function is called\n// or when the parent context's Done channel is closed, whichever happens first.\n//\n// Canceling this context releases resources associated with it, so code should\n// call cancel as soon as the operations running in this Context complete.\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123;\n\tif parent == nil &#123;\n\t\tpanic(\"cannot create context from nil parent\")\n\t&#125;\n\tc := newCancelCtx(parent)\n\tpropagateCancel(parent, &amp;c)\n\treturn &amp;c, func() &#123; c.cancel(true, Canceled) &#125;\n&#125;\n\n\n\n\n// propagateCancel arranges for child to be canceled when parent is.\nfunc propagateCancel(parent Context, child canceler) &#123;\n\tdone := parent.Done()\n\tif done == nil &#123;\n\t\treturn // parent is never canceled\n\t&#125;\n\n\t// 如果父节点已经被取消, 级联取消当前子节点.\n\tselect &#123;\n\tcase &lt;-done:\n\t\t// parent is already canceled\n\t\tchild.cancel(false, parent.Err())\n\t\treturn\n\tdefault:\n\t&#125;\n\n\t// 否则: \n\tif p, ok := parentCancelCtx(parent); ok &#123; //  如果是 cancelCtx 类型,那就简单了， 将 curCtx 放到  parent.child 里面.\n\t\tp.mu.Lock()\n\t\tif p.err != nil &#123;\n\t\t\t// 父节点已经被取消\n\t\t\tchild.cancel(false, p.err)\n\t\t&#125; else &#123;\n\t\t\tif p.children == nil &#123;\n\t\t\t\tp.children = make(map[canceler]struct&#123;&#125;) // lazy create\n\t\t\t&#125;\n\t\t\tp.children[child] = struct&#123;&#125;&#123;&#125;\n\t\t&#125;\n\t\tp.mu.Unlock()\n\t&#125; else &#123;                                    //  如果 不是 cancelCtx类型, 就开启一个协程监听  parent 与 curCtx 是否有取消操作\n\t\tatomic.AddInt32(&amp;goroutines, +1)\n\t\tgo func() &#123;\n\t\t\tselect &#123;\n\t\t\tcase &lt;-parent.Done():\n\t\t\t\tchild.cancel(false, parent.Err())\n\t\t\tcase &lt;-child.Done():\n\t\t\t&#125;\n\t\t&#125;()\n\t&#125;\n&#125;\n\n\n\n// 当 parent 时cancelCtx时才会调用此方法.\n// 通过 调用 `parent.Value(&amp;cancelCtxKey)` 找到最里面的  cancelCtx, \n// 然后检查  parent.Done == cancelCtx.Done(). \n// 如果 不匹配, 说明 cancelCtx 被包裹在了一个 自定义实现中,提供不同的 done通道. \n// \n// \n// parentCancelCtx returns the underlying *cancelCtx for parent.\n// It does this by looking up parent.Value(&amp;cancelCtxKey) to find\n// the innermost enclosing *cancelCtx and then checking whether\n// parent.Done() matches that *cancelCtx. (If not, the *cancelCtx\n// has been wrapped in a custom implementation providing a\n// different done channel, in which case we should not bypass it.)\nfunc parentCancelCtx(parent Context) (*cancelCtx, bool) &#123;\n\tdone := parent.Done()\n\tif done == closedchan || done == nil &#123;\n\t\treturn nil, false\n\t&#125;\n\t// 传入\n\tp, ok := parent.Value(&amp;cancelCtxKey).(*cancelCtx)\n\tif !ok &#123;\n\t\treturn nil, false\n\t&#125;\n\tpdone, _ := p.done.Load().(chan struct&#123;&#125;)\n\tif pdone != done &#123;\n\t\treturn nil, false\n\t&#125;\n\treturn p, true\n&#125;\n\n3. context.timerCtx超时取消, 顾名思义,  内部应该会有一个定时执行的函数, 调用 cancel().这里包含两种取消模式: 1. 主动调用  cancel() 2. 时间到了, 执行 cancel()\n// timerCtx  携带了一个 timer 和一个 deadline.\n// timerCtx 内嵌了一个  cancelCtx  复用其  `Done()`  and `Err()`.\n// 当时间到了的时候,会调用  cacnelCtx 的 cancel() 执行取消\n// A timerCtx carries a timer and a deadline. It embeds a cancelCtx to\n// implement Done and Err. It implements cancel by stopping its timer then\n// delegating to cancelCtx.cancel.\ntype timerCtx struct &#123;\n\tcancelCtx\n\ttimer *time.Timer // Under cancelCtx.mu.\n\n\tdeadline time.Time\n&#125;\n\nfunc (c *timerCtx) Deadline() (deadline time.Time, ok bool) &#123;\n\treturn c.deadline, true\n&#125;\n\nfunc (c *timerCtx) String() string &#123;\n\treturn contextName(c.cancelCtx.Context) + \".WithDeadline(\" +\n\t\tc.deadline.String() + \" [\" +\n\t\ttime.Until(c.deadline).String() + \"])\"\n&#125;\n\nfunc (c *timerCtx) cancel(removeFromParent bool, err error) &#123;\n\tc.cancelCtx.cancel(false, err)\n\tif removeFromParent &#123;\n\t\t// Remove this timerCtx from its parent cancelCtx's children.\n\t\tremoveChild(c.cancelCtx.Context, c)\n\t&#125;\n\tc.mu.Lock()\n\tif c.timer != nil &#123;\n\t\tc.timer.Stop()\n\t\tc.timer = nil\n\t&#125;\n\tc.mu.Unlock()\n&#125;\n\n\n\n创建一个 timerCtx:\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123;\n\treturn WithDeadline(parent, time.Now().Add(timeout))\n&#125;\n\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123;\n\tif parent == nil &#123;\n\t\tpanic(\"cannot create context from nil parent\")\n\t&#125;\n\tif cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123;\n\t\t// The current deadline is already sooner than the new one.\n\t\treturn WithCancel(parent)\n\t&#125;\n\tc := &amp;timerCtx&#123;\n\t\tcancelCtx: newCancelCtx(parent),\n\t\tdeadline:  d,\n\t&#125;\n\t// 下卖弄会分析， 回溯树的构建\n\tpropagateCancel(parent, c)\n\tdur := time.Until(d)\n\n\t// 如果已经超时了, 直接取消\n\tif dur &lt;= 0 &#123;\n\t\tc.cancel(true, DeadlineExceeded) // deadline has already passed\n\t\treturn c, func() &#123; c.cancel(false, Canceled) &#125;\n\t&#125;\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tif c.err == nil &#123;\n\t\t// 添加一个延时任务\n\t\tc.timer = time.AfterFunc(dur, func() &#123;\n\t\t\tc.cancel(true, DeadlineExceeded)\n\t\t&#125;)\n\t&#125;\n\treturn c, func() &#123; c.cancel(true, Canceled) &#125;\n&#125;\n\n4. valueCtx创建:\n\n// WithValue returns a copy of parent in which the value associated with key is\n// val.\n//\n// Use context Values only for request-scoped data that transits processes and\n// APIs, not for passing optional parameters to functions.\n//\n// The provided key must be comparable and should not be of type\n// string or any other built-in type to avoid collisions between\n// packages using context. Users of WithValue should define their own\n// types for keys. To avoid allocating when assigning to an\n// interface&#123;&#125;, context keys often have concrete type\n// struct&#123;&#125;. Alternatively, exported context key variables' static\n// type should be a pointer or interface.\nfunc WithValue(parent Context, key, val any) Context &#123;\n\tif parent == nil &#123;\n\t\tpanic(\"cannot create context from nil parent\")\n\t&#125;\n\tif key == nil &#123;\n\t\tpanic(\"nil key\")\n\t&#125;\n\tif !reflectlite.TypeOf(key).Comparable() &#123;\n\t\tpanic(\"key is not comparable\")\n\t&#125;\n\treturn &amp;valueCtx&#123;parent, key, val&#125;\n&#125;\n\n// A valueCtx carries a key-value pair. It implements Value for that key and\n// delegates all other calls to the embedded Context.\ntype valueCtx struct &#123;\n\tContext\n\tkey, val any\n&#125;\n\n\n\n\n5.1.  构建 context 树树的构建 级联取消的不分 基础代码在 cancelCtx 中, timerCtx和 valuectx 都会引用 cancelCtx 这部分代码.\nWithCancel() 创建了 一个 Donechannel 和 拷贝了parentCtx.当  parentCtx 被取消 或者 当前context 的 cancel() 被调用, 当前 context.Done() 的channel将会被 close.\n\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123;\n\tif parent == nil &#123;\n\t\tpanic(\"cannot create context from nil parent\")\n\t&#125;\n\tc := newCancelCtx(parent)\n\tpropagateCancel(parent, &amp;c)\n\treturn &amp;c, func() &#123; c.cancel(true, Canceled) &#125;\n&#125;\n\n\n\n子 context 持有 父 context 的引用.\ncontext 持有 其 所有子节点(子context) 的引用.\n\npropagateCancel(): 保证当parentCtx 被取消时,遍历取消 childCtx, 构建一个回溯树.\n\n监听 parentContext.Done(), 收到取消信号时,级联取消子节点\n\n// propagateCancel arranges for child to be canceled when parent is.\nfunc propagateCancel(parent Context, child canceler) &#123;\n\t// parent.Done() 返回nil， 说明 parentContext 根本无法取消\n\t// 1. 比如 context.Background() || context.TODO()\n\tdone := parent.Done()\n\tif done == nil &#123;\n\t\treturn // parent is never canceled\n\t&#125;\n\n\t// 2. 判断 parentContext 已经取消 \n\tselect &#123;\n\tcase &lt;-done:\n\t\t// parent is already canceled\n\t\tchild.cancel(false, parent.Err())\n\t\treturn\n\tdefault:\n\t&#125;\n\n\t// parentCancelCtx  用于获取底层可取消的 Context(cancelContext)\n\t// 如果 parent Context 本身就是 *cancelCtx 或者是标准库中基于 cancelCtx 衍生的 Context 会返回 true\n\t// 如果 parent Context 已经取消/或者根本无法取消 会返回 false\n\t// 如果 parent Context 无法转换为一个 *cancelCtx 也会返回 false\n\t// 如果 parent Context 是一个自定义深度包装的 cancelCtx(自己定义了 done channel) 则也会返回 false\n\t// \n\t// ok 为 true 说明 parent Context 为 标准库的 cancelCtx 或者至少可以完全转换为 *cancelCtx\n\tif p, ok := parentCancelCtx(parent); ok &#123;\n\t\tp.mu.Lock() // 加锁  double check\n\t\t// 所以并发加锁情况下如果 parent Context 的 err 不为空说明已经被取消了\n\t\tif p.err != nil &#123;\n\t\t\t// parent has already been canceled\n\t\t\tchild.cancel(false, p.err)\n\t\t&#125; else &#123;\n\t\t\t// 如果 parent Context没有被取消, 就将 自身 context 加入到 parentContext.children 中,建立关联\n\t\t\t// 当 parentContext被取消时, 会遍历  parent.children, 一次调用  child.cancel() \n\t\t\t// 所以 -> p.children 中所有的 context 都可以转化为  cancelCtx 节点.\n\t\t\tif p.children == nil &#123;\n\t\t\t\tp.children = make(map[canceler]struct&#123;&#125;)\n\t\t\t&#125;\n\t\t\tp.children[child] = struct&#123;&#125;&#123;&#125;\n\t\t&#125;\n\t\tp.mu.Unlock()\n\t&#125; else &#123;\n\t\t// ok 为false 说明 parent Context 已经取消 || 根本无法取消 || 无法转换为一个 \t`cancelContext` || 是一个自定义的深度包装的 `cancelCtx`\n\t\tatomic.AddInt32(&amp;goroutines, +1)\n\t\t// 由于代码一开始已经判断了 parentContext 已经取消  和  根本无法取消 的两种情况.\n\t\t// 所以这里  &lt;- parent.Done() 并不会产生 panic\n\t\t//\n\t\t// 后两种情况下 无法通过  parentContext.child(map) 建立关联, 只能通过 一个 goroutine 完成 级联取消操作.\n\t\tgo func() &#123;\n\t\t\tselect &#123;\n\t\t\tcase &lt;-parent.Done():\n\t\t\t\tchild.cancel(false, parent.Err())\n\t\t\tcase &lt;-child.Done():\n\t\t\t&#125;\n\t\t&#125;()\n\t&#125;\n&#125;\n\n\n\n\nparentCancelCtx():  parentCancelCtx  用于获取底层可取消的 Context(cancelContext)\n\n如果 parent Context 本身就是 *cancelCtx 或者是标准库中基于 cancelCtx 衍生的 Context 会返回 true\n如果 parent Context 已经取消&#x2F;或者根本无法取消 会返回 false\n如果 parent Context 无法转换为一个 *cancelCtx 也会返回 false\n如果 parent Context 是一个自定义深度包装的 cancelCtx(自己定义了 done channel) 则也会返回 false\n\n// parentCancelCtx returns the underlying *cancelCtx for parent.\n// It does this by looking up parent.Value(&amp;cancelCtxKey) to find\n// the innermost enclosing *cancelCtx and then checking whether\n// parent.Done() matches that *cancelCtx. (If not, the *cancelCtx\n// has been wrapped in a custom implementation providing a\n// different done channel, in which case we should not bypass it.)\nfunc parentCancelCtx(parent Context) (*cancelCtx, bool) &#123;\n\tdone := parent.Done()\n\t// 1.\n\t// parentContext.Done()   == nil 说明不是一个 cancelContext\n\t// parentContext.Done()   == closedchan(一个可复用的表示关闭), 说明 parentContext  已经被关闭了.\n\tif done == closedchan || done == nil &#123;\n\t\treturn nil, false\n\t&#125;\n\n\t// 2.\n\t// parentContex 无法转换为一个   cancelCtx\n\tp, ok := parent.Value(&amp;cancelCtxKey).(*cancelCtx)\n\tif !ok &#123;\n\t\treturn nil, false\n\t&#125;\n\n\t// 3. \n\t// 经过上面的判断后，说明 parent context 可以被转换为 *cancelCtx，这时存在多种情况:\n\t//   - parent context 就是 *cancelCtx\n\t//   - parent context 是标准库中的 timerCtx\n\t//   - parent context 是个自己自定义包装的 cancelCtx\n\t//\n\t// 针对这 3 种情况需要进行判断，判断方法就是: \n\t//   判断 parent context 通过 Done() 方法获取的 done channel 与 Value 查找到的 context 的 done channel 是否一致\n\t// \n\t// 一致情况说明 parent context 为 cancelCtx 或 timerCtx 或 自定义的 cancelCtx 且未重写 Done()，\n\t// 这种情况下可以认为拿到了底层的 *cancelCtx\n\t// \n\t// 不一致情况说明 parent context 是一个自定义的 cancelCtx 且重写了 Done(), 并且并未返回标准 `*cancelCtx` 的\n\t// 的 done channel，这种情况需要单独处理，故返回 nil, false\n\tpdone, _ := p.done.Load().(chan struct&#123;&#125;)\n\tif pdone != done &#123;\n\t\treturn nil, false\n\t&#125;\n\treturn p, true\n&#125;\n\n\n\n5.2 级联取消 cancel级联取消的关键函数是 cancelCtx.cancel(),  在 当前 cancelCtx 取消时,需要级联取消  以该context为根节点的 context树中所有context,并将 cancelCtx 从 其父节点摘除,以便让 GC 回收该 cancelCtx 子树的所有资源.\n// cancel closes c.done, cancels each of c's children, and, if\n// removeFromParent is true, removes c from its parent's children.\nfunc (c *cancelCtx) cancel(removeFromParent bool, err error) &#123;\n\n\t// err == nil,那么 直接 panic\n\t// 这么做的目的是因为 `cancel()`是个私有方法，标准库内任何调用 `cancel()`\n    // 的方法保证了一定会传入 err, 如果没传那就是非正常调用,所以可以直接 panic\n\tif err == nil &#123;\n\t\tpanic(\"context: internal error: missing cancel error\")\n\t&#125;\n\tc.mu.Lock()\n\t// 已经被取消了, 防止重复调用 cancel()\n\tif c.err != nil &#123;\n\t\tc.mu.Unlock()\n\t\treturn // already canceled\n\t&#125;\n\tc.err = err\n\td, _ := c.done.Load().(chan struct&#123;&#125;)\n\t// 判断 c.done 是否为 nil，因为 context.WithCancel 创建 cancelContext 时, c.done是延迟初始化的, 所以可能为nil\n\t// 如果 c.done == nil, 将其赋值为 可 复用的  closechan.\n\tif d == nil &#123;\n\t\tc.done.Store(closedchan)\n\t&#125; else &#123;\n\t\tclose(d)\n\t&#125;\n\n\t// 如果当前 Context 下面还有关联的 child Context，且这些 child Context 都是\n\t// 可以转换成 *cancelCtx 的 Context(见上面的 propagateCancel()分析).\n\t// 那么直接遍历 childre map，并且调用 child Context 的 cancel 即可\n\t// 如果关联的 child Context 不能转换成 *cancelCtx，那么由 propagateCancel 方法\n\t// 中已经创建了单独的 Goroutine 来关闭这些 child Context\n\tfor child := range c.children &#123;\n\t\t// NOTE: acquiring the child's lock while holding parent's lock.\n\t\tchild.cancel(false, err) // 递归调用 子context cancel\n\t&#125;\n\tc.children = nil\n\tc.mu.Unlock()\n\n\tif removeFromParent &#123;\n\t\tremoveChild(c.Context, c) //从 parent 中找出 curContext\n\t&#125;\n&#125;\n\n// removeChild removes a context from its parent.\nfunc removeChild(parent Context, child canceler) &#123;\n\tp, ok := parentCancelCtx(parent)\n\tif !ok &#123;\n\t\treturn\n\t&#125;\n\tp.mu.Lock()\n\tif p.children != nil &#123;\n\t\tdelete(p.children, child)\n\t&#125;\n\tp.mu.Unlock()\n&#125;\n\nfunc parentCancelCtx(parent Context) (*cancelCtx, bool) &#123;\n\tdone := parent.Done()\n\tif done == closedchan || done == nil &#123;\n\t\treturn nil, false\n\t&#125;\n\tp, ok := parent.Value(&amp;cancelCtxKey).(*cancelCtx)\n\tif !ok &#123;\n\t\treturn nil, false\n\t&#125;\n\tpdone, _ := p.done.Load().(chan struct&#123;&#125;)\n\tif pdone != done &#123;\n\t\treturn nil, false\n\t&#125;\n\treturn p, true\n&#125;\n\n\n\n\nGolang Context 源码分析\n","slug":"Go源码-context","date":"2022-08-30T15:39:07.000Z","categories_index":"","tags_index":"golang,context,源码剖析","author_index":"majm"},{"id":"9a85a1a2b7a6a9bc3209cb287c73c69a","title":"微服务 Trace","content":"Spection  Trace 语义Trace代表一个调用链.\n通常， 一个 Trace 可以被理解为一系列span 组成的有向无环图(DAG), span 之间的边称为  Reference.\nSpanSpan 表示一个跨进程的 RPC 或者进程内部的一个过程.\n每个span 可以包含一些状态:operate_namestart_timestampeend_timestampTags: 一系列 kv 集合Logs: 一系列 kv 集合,并且携带时间戳SpanContext:Reference: 通过 SpanContext 关联其他 Span\nSpanContextSpanContext  封装了一个可以用来指向特定 Span 的状态,用于在进程间(内)传递. 通过在进程间传递,在分布式环境中构建一个DAG图.\nspan 必须去提供方法访问 SpanContext,SpanContext 代表跨越进程边界,传递到下级Span的状态.(包含  trace_id span_id sampled 元组).\nSpanContext 在跨越进程边界,和在追踪图中创建边界的时候会使用.\nLogs 每个Span可以进行多次Logs操作,每一次Logs操作, 都需要一个带时间戳的时间名称, 以及可选的任意大小的存储结构.Standard LogKeys\nTags每个 Span 可以有多个键值对(key:value)形式的Tags, Tags是没有时间戳的,支持简单的对Span进行注解和补充.\nStandard Tags\nBaggageBaggage 是存储在 SpanContext 中的一个键值对(SpanContext)集合. 它会在一条追踪链路上的所有span内全局传输. 在这种情况下, Baggage会随着Trace一同传播.(Baggage可理解为随着trace运行过程传送的行李).\nBaggage 拥有强大功能,也会有很大的消耗.  由于Baggage的全局传输,如果包含的数量量太大，或者元素太多，它将降低系统的吞吐量或增加RPC的延迟.\nReferenceReference 有两种类型:\n\nChildOf\nFollowsFrom\n\n\nOpenTracing语义标准The OpenTracing Semantic SpecificationThe OpenTracing Semantic Specification-github\n","slug":"微服务-Trace","date":"2022-08-18T04:46:07.000Z","categories_index":"","tags_index":"微服务,trace","author_index":"majm"},{"id":"4d9104954e68f25499a2e47d5b935f32","title":"微服务:API Gateway","content":"什么是 API网关API网关是一个服务器,是系统的唯一入口.  从面向对象设计的角度看，它与外观模式类似.\nAPI网关封装了系统内部架构,为每个客户端提供一个定制的API.它可能还具有其它职责,如身份验证、监控、负载均衡、缓存、协议转换、限流熔断、静态响应处理.\nAPI网关方式的核心要点是: 所有的客户端和消费端都通过统一的网关接入微服务,在网关层处理所有的非业务功能. 通常，网关也是提供REST/HTTP的访问API.\n网关应该具有那些能力微服务网关作为微服务后端服务的统一入口, 它可以统筹管理后端服务,主要分为数据平面和控制平面:\n数据平面主要功能是接入用户的HTTP请求和微服务被拆分后的聚合.使用微服务网关统一对外暴露后端服务的API和契约,路由和过滤功能正是网关的核心能力模块.另外,微服务网关可以实现拦截机制和专注跨横切面的功能,包括协议转换、安全认证、熔断限流、灰度发布、日志管理、流量监控等.\n控制平面主要功能是对后端服务做统一的管控和配置管理.例如,可以控制网关的弹性伸缩; 可以统一下发配置; 可以对网关服务添加标签; 可以在微服务网关上通过配置Swagger功能统一将后端服务的API契约暴露给使用方, 完成文档服务, 提高工作效率和降低沟通成本.\n\n限流\n熔断\n安全\n缓存\n重试\n负载均衡\n反向路由\n认证,鉴权\n日志收集\n监控\nIP列表:黑名单,白名单\n流量染色\n协议转换\nAPI管理\n\n下图 是 Kong 官方  的一个简单架构图.\n\n常见的开源网关对比\n\n\n功能\nApache APISIX\nKong\nTyk\n\n\n\n项目归属\nApache\nKong Inc\n\n\n\n技术架构\nNginx + etcd\nNginx + postgres\nGolang + Redis\n\n\n部署模式\n单机&amp;集群\n单机&amp;集群\n单机&amp;集群\n\n\n单核Qps(开启限流和 prometheus)\n18,000\n1700\n\n\n\n平均延时\n0.2ms\n2ms\n\n\n\n配置生效时间\n时间通知, 低于 1ms\n定时轮询 5s\n\n\n\n支持配置回滚\n[x]\n[]\n\n\n\n热插件更新\n[x]\n[]\n\n\n\n用户自定义负载均衡算法，路由\n[x]\n[]\n[]\n\n\n控制台\n[x]\n[]\n[]\n\n\n","slug":"微服务-API-Gateway","date":"2022-08-17T02:52:25.000Z","categories_index":"","tags_index":"微服务,gateway","author_index":"majm"},{"id":"237d42f01cd872e0a7556a026d085cc6","title":"awesome-blog","content":"golang极客兔兔跟煎鱼学GoO神的博客曹大的博客\nJava小马哥的技术博客田小波的技术博客\nArchitechcleancoders解道凤凰架构\nLinuxFRIMIN鸟哥的首页Vamei\n算法谭新宇LABULADONG 的算法网站结构之法算法之道kuangbin - 博客园acm_cxlove某岛ACMer 博客瀑布流伟阳的博客\n大厂博客美团技术团队阿里中间件团队博客有赞技术团队Thoughtworks洞见小米信息部技术团队伴鱼技术团队\n其他茶歇驿站木鸟杂记陈树义的博客左耳朵耗子的博客\nGolang 书籍Go语言圣经（中文版）Go语言精进之路Go 语言原本Go语言高级编程(Advanced Go Programming)语言设计与实现\nGo 语言问题集(Go Questions)\n","slug":"awesome-blog","date":"2022-08-16T12:45:48.000Z","categories_index":"","tags_index":"blog","author_index":"majm"},{"id":"bc5ccb2e868ae0ec4cf759c000e9d341","title":"golang-sync.Pool解析","content":"sync.Pool是sync包下的一个组件,可以作为临时取还对象的一个 池子.\n作用: 对于很多需要重复分配、回收内存的地方,sync.Pool 是一个很好的选择.频繁地分配、回收内存会给 GC 带来一定的负担,严重的时候会引起 CPU 的毛刺,而 sync.Pool 可以将暂时不用的对象缓存起来m待下次需要的时候直接使用,不用再次经过内存分配,复用对象的内存,减轻 GC 的压力,提升系统的性能.\n使用场景:\n\n当多个 goroutine 都需要创建同⼀个对象的时候，如果 goroutine 数过多,导致对象的创建数⽬剧增,进⽽导致 GC 压⼒增大.形成”并发⼤－占⽤内存⼤－GC 缓慢－处理并发能⼒降低－并发更⼤”这样的恶性循环.\n关键思想就是对象的复用,避免重复创建.销毁.\n\nPool原理详解type Pool struct &#123;\n\tnoCopy noCopy\n\n\tlocal     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal\n\tlocalSize uintptr        // size of the local array\n\n\tvictim     unsafe.Pointer // local from previous cycle\n\tvictimSize uintptr        // size of victims array\n\n\t// New optionally specifies a function to generate\n\t// a value when Get would otherwise return nil.\n\t// It may not be changed concurrently with calls to Get.\n\tNew func() any\n&#125;\n\n\n\n\nnoCopy:\nlocal:   每个P的本地队列,实际类型为 [P]poolLocal\nlocalSize: \nvicticm:\nvicticmSize: \nNew:      自定义创建对象的回调函数,当pool中没有都可用对象时会调用\n\n1. noCopynocopy:因为Pool不希望被复制,所以结构体里面有一个noCopy字段, 使用 go vet 工具可以检查用户是否复制了 Pool.\n用户只需要实现这样不需要消耗内存的,仅用于静态分析的结构, 保证对象在第一次使用后不会发生复制.\n// noCopy may be embedded into structs which must not be copied\n// after the first use.\n// noCopy 可以被嵌入结构体来保证其第一次使用后不会在被复制.\n//\n// See https://golang.org/issues/8005#issuecomment-190753527\n// for details.\ntype noCopy struct&#123;&#125;\n\n// Lock is a no-op used by -copylocks checker from `go vet`.\n// Lock 是一个空操作用来给 `go ve` 的 -copylocks 静态分析\nfunc (*noCopy) Lock()   &#123;&#125;\nfunc (*noCopy) Unlock() &#123;&#125;\n\n\n2. locallocal字段指向  [P]poolLocal 数组(切片)的指针, localSize 则表示 这个数组的大小. 访问时 P 的 id 对应 [P]poolLocal 下标索引, 这样的设计减少了 多个goroutine 的竞争,提升了性能.\n2.1 poolLocaltype poolLocal struct &#123;\n\tpoolLocalInternal\n\n\t// 将 poolLocal 补齐至两个缓存行的倍数，防止 false sharing,\n\t// 每个缓存行具有 64 bytes，即 512 bit$$\n\t// 目前我们的处理器一般拥有 32 * 1024 / 64 = 512 条缓存行\n\t// 伪共享，仅占位用,防止在 cache line 上分配多个 poolLocalInternal\n\t// \n\t// Prevents false sharing on widespread platforms with$$\n\t// 128 mod (cache line size) = 0 .\n\tpad [128 - unsafe.Sizeof(poolLocalInternal&#123;&#125;)%128]byte\n&#125;\n\n\n\n\n2.2 poolLocalInternal\n// Local per-P Pool appendix.\ntype poolLocalInternal struct &#123;\n\tprivate any       // Can be used only by the respective P.  仅能被各自的 P 获取\n\tshared  poolChain // Local P can pushHead/popHead; any P can popTail. 本地P可以从头部取, 其他 P 从尾部取\n&#125;\n\n\n\n\n\n2.3 poolChain\n// poolChain is a dynamically-sized version of poolDequeue.\n//\n// This is implemented as a doubly-linked list queue of poolDequeues\n// where each dequeue is double the size of the previous one. Once a\n// dequeue fills up, this allocates a new one and only ever pushes to\n// the latest dequeue. Pops happen from the other end of the list and\n// once a dequeue is exhausted, it gets removed from the list.\ntype poolChain struct &#123;\n\t// head is the poolDequeue to push to. This is only accessed\n\t// by the producer, so doesn't need to be synchronized.\n\thead *poolChainElt\n\n\t// tail is the poolDequeue to popTail from. This is accessed\n\t// by consumers, so reads and writes must be atomic.\n\ttail *poolChainElt\n&#125;\n\n\n\ntype poolChainElt struct &#123;\n\tpoolDequeue\n\n\t// next and prev link to the adjacent poolChainElts in this\n\t// poolChain.\n\t//\n\t// next is written atomically by the producer and read\n\t// atomically by the consumer. It only transitions from nil to\n\t// non-nil.\n\t//\n\t// prev is written atomically by the consumer and read\n\t// atomically by the producer. It only transitions from\n\t// non-nil to nil.\n\tnext, prev *poolChainElt\n&#125;\n\n// \n// poolDequeue is a lock-free fixed-size single-producer,\n// multi-consumer queue. The single producer can both push and pop\n// from the head, and consumers can pop from the tail.\n//\n// It has the added feature that it nils out unused slots to avoid\n// unnecessary retention of objects. This is important for sync.Pool,\n// but not typically a property considered in the literature.\ntype poolDequeue struct &#123;\n\t// headTail 包含一个 32 位的 head 和一个 32 位的 tail 指针. 这两个值都和 len(vals)-1 取模过.\n\t// tail 是队列中最老的数据,head 指向下一个将要填充的 slot\n    // slots 的有效范围是 [tail, head),由 consumers 持有.\n\t// \n\t// headTail packs together a 32-bit head index and a 32-bit\n\t// tail index. Both are indexes into vals modulo len(vals)-1.\n\t//\n\t// tail = index of oldest data in queue\n\t// head = index of next slot to fill\n\t//\n\t// Slots in the range [tail, head) are owned by consumers.\n\t// A consumer continues to own a slot outside this range until\n\t// it nils the slot, at which point ownership passes to the\n\t// producer.\n\t//\n\t// The head index is stored in the most-significant bits so\n\t// that we can atomically add to it and the overflow is\n\t// harmless.\n\theadTail uint64\n\n\t// \n\t// vals 是一个存储 interface&#123;&#125; 的环形队列,它的 size 必须是 2 的幂\n\t// 如果 slot 为空,则 vals[i].typ 为空;否则，非空.\n\t// 一个 slot 在这时宣告无效: tail 不指向它了，vals[i].typ 为 nil\n\t// 由 consumer 设置成 nil，由 producer 读\n\t// \n\t// vals is a ring buffer of interface&#123;&#125; values stored in this\n\t// dequeue. The size of this must be a power of 2.\n\t//\n\t// vals[i].typ is nil if the slot is empty and non-nil\n\t// otherwise. A slot is still in use until *both* the tail\n\t// index has moved beyond it and typ has been set to nil. This\n\t// is set to nil atomically by the consumer and read\n\t// atomically by the producer.\n\tvals []eface\n&#125;\n\n\n\n\n\n\n\n\n\n\n\n\n\npoolDequeue 被设计成单生产者，多消费者固定长度&amp;&amp;无锁的 双端队列.   producer 可以从head插入和删除.  consumer可以从尾部pop 数据.\n\n\n\n\n\n\n\n\n\nheadTail 指向队头和队尾, 通过位运算, 将 head  &amp; tail 存入  headTail中.\n\n\n\n\n\n\n\n\n\n\n\n我们看到 Pool 并没有直接使用 poolDequeue,原因是它的大小是固定的,而 Pool 的大小是没有限制的.因此，在 poolDequeue 之上包装了一下,变成了一个 poolChainElt 的双向链表,可以动态增长.\n3. victim一轮 GC 完成后,victim 和 victimSize 会分别接管  local  和 localSize,victim 的机制用于减少GC后冷启动导致的性能抖动. 让分配对象更加平滑.\n\n\n\n\n\n\n\n\n\nvictim Cache 本来是计算机架构里面的一个概念,是让CPU硬件处理缓存的一种技术, sync.Pool引入的意图在于 降低GC压力的同时增加缓存命中率.\n4. New当Pool中没有对象可供提供时,会调用 New 生成一个新对象.\n\n\n\n\n\n2. 源码详解2.1. Get// Get selects an arbitrary item from the Pool, removes it from the\n// Pool, and returns it to the caller.\n// Get may choose to ignore the pool and treat it as empty.\n// Callers should not assume any relation between values passed to Put and\n// the values returned by Get.\n//\n// If Get would otherwise return nil and p.New is non-nil, Get returns\n// the result of calling p.New.\nfunc (p *Pool) Get() any &#123;\n\tif race.Enabled &#123;\n\t\trace.Disable()\n\t&#125;\n\t// 将当前的 goroutine 和 P绑定,禁止被强占,返回当前P对应的 localPool &amp; pid\n\tl, pid := p.pin()\n\tx := l.private\n\tl.private = nil\n\tif x == nil &#123;\n\t\t// Try to pop the head of the local shard. We prefer\n\t\t// the head over the tail for temporal locality of\n\t\t// reuse.\n\t\tx, _ = l.shared.popHead()\n\t\tif x == nil &#123;\n\t\t\t// 尝试从 qita P 的 shared 双端队列尾部头一个对象出来.\n\t\t\tx = p.getSlow(pid)\n\t\t&#125;\n\t&#125;\n\t// pool 操作完成之后, 接触非抢占\n\truntime_procUnpin()\n\tif race.Enabled &#123;\n\t\trace.Enable()\n\t\tif x != nil &#123;\n\t\t\trace.Acquire(poolRaceAddr(x))\n\t\t&#125;\n\t&#125;\n\n\t// 如果最后还是没有获取到缓存对象,那就直接调用预先设置好的回调函数 `New` 创建一个对象.\n\tif x == nil &amp;&amp; p.New != nil &#123;\n\t\tx = p.New()\n\t&#125;\n\treturn x\n&#125;\n\n\n\n2.1.1 pin// pin pins the current goroutine to P, disables preemption and\n// returns poolLocal pool for the P and the P's id.\n// Caller must call runtime_procUnpin() when done with the pool.\nfunc (p *Pool) pin() (*poolLocal, int) &#123;\n\tpid := runtime_procPin()\n\t// In pinSlow we store to local and then to localSize, here we load in opposite order.\n\t// Since we've disabled preemption, GC cannot happen in between.\n\t// Thus here we must observe local at least as large localSize.\n\t// We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness).\n\ts := runtime_LoadAcquintptr(&amp;p.localSize) // load-acquire\n\tl := p.local                              // load-consume\n\t// 因为可能存在动态的 P（运行时调整 P 的个数）\n\tif uintptr(pid) &lt; s &#123;\n\t\treturn indexLocal(l, pid), pid\n\t&#125;\n\treturn p.pinSlow()\n&#125;\n\n调用方必须在完成取值后,调用 runtime.proc_Unpin() 来取消抢占.\n\n\n\n\n\n\n\n\n\npin 的作用就是将当前 groutine 和 P 绑定在一起，禁止抢占. 并且返回对应的 poolLocal 以及 P 的 id。\n如果 G 被抢占，则 G 的状态从 running 变成 runnable,会被放回 P 的 localq 或 globaq，等待下一次调度.下次再执行时，就不一定是和现在的 P 相结合了. 因为之后会用到 pid,如果被抢占了,有可能接下来使用的 pid 与所绑定的 P 并非同一个.\n\nfunc (p *Pool) pinSlow() (*poolLocal, int) &#123;\n\t// Retry under the mutex.\n\t// Can not lock the mutex while pinned.\n\truntime_procUnpin()\n\tallPoolsMu.Lock()\n\tdefer allPoolsMu.Unlock()\n\tpid := runtime_procPin()\n\t// poolCleanup won't be called while we are pinned.\n\ts := p.localSize\n\tl := p.local\n\tif uintptr(pid) &lt; s &#123;\n\t\treturn indexLocal(l, pid), pid\n\t&#125;\n\tif p.local == nil &#123;\n\t\tallPools = append(allPools, p)\n\t&#125;\n\t// If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one.\n\tsize := runtime.GOMAXPROCS(0)\n\tlocal := make([]poolLocal, size)\n\tatomic.StorePointer(&amp;p.local, unsafe.Pointer(&amp;local[0])) // store-release\n\truntime_StoreReluintptr(&amp;p.localSize, uintptr(size))     // store-release\n\treturn &amp;local[pid], pid\n&#125;\n\n因为有一把大锁 allPoolsMu, 所以函数名带有 slow. 锁粒度越大,竞争越多,就越慢.  不过想要上锁的话,先要解除绑定.  原因是锁越大,被阻塞的概率越大,如果还占着 P, 那就浪费资源.\n2.1.2 popHead\nfunc (c *poolChain) pushHead(val any) &#123;\n\td := c.head\n\tif d == nil &#123;\n\t\t// Initialize the chain.\n\t\tconst initSize = 8 // Must be a power of 2\n\t\td = new(poolChainElt)\n\t\td.vals = make([]eface, initSize)\n\t\tc.head = d\n\t\tstorePoolChainElt(&amp;c.tail, d)\n\t&#125;\n\n\tif d.pushHead(val) &#123;\n\t\treturn\n\t&#125;\n\n\t// The current dequeue is full. Allocate a new one of twice\n\t// the size.\n\tnewSize := len(d.vals) * 2\n\tif newSize >= dequeueLimit &#123;\n\t\t// Can't make it any bigger.\n\t\tnewSize = dequeueLimit\n\t&#125;\n\n\td2 := &amp;poolChainElt&#123;prev: d&#125;\n\td2.vals = make([]eface, newSize)\n\tc.head = d2\n\tstorePoolChainElt(&amp;d.next, d2)\n\td2.pushHead(val)\n&#125;\n\nfunc (c *poolChain) popHead() (any, bool) &#123;\n\td := c.head\n\tfor d != nil &#123;\n\t\t// 调用 dequeue 的 popHead\n\t\tif val, ok := d.popHead(); ok &#123;\n\t\t\treturn val, ok\n\t\t&#125;\n\t\t// There may still be unconsumed elements in the\n\t\t// previous dequeue, so try backing up.\n\t\td = loadPoolChainElt(&amp;d.prev)\n\t&#125;\n\treturn nil, false\n&#125;\n\n\npopHead 只会被  producer调用,首先拿到头结点: ,如果头结点不为空,尝试调用 头结点(poolDequeue)的 popHead().\n\n// 自旋锁的模式,避免加锁.\n// \n// popHead removes and returns the element at the head of the queue.\n// It returns false if the queue is empty. It must only be called by a\n// single producer.\nfunc (d *poolDequeue) popHead() (any, bool) &#123;\n\tvar slot *eface\n\tfor &#123;\n\t\tptrs := atomic.LoadUint64(&amp;d.headTail)\n\t\thead, tail := d.unpack(ptrs)\n\t\tif tail == head &#123;\n\t\t\t// Queue is empty.\n\t\t\treturn nil, false\n\t\t&#125;\n\n\t\t// head 是队头的前一个位置,所以要后移一位.\n\t\t// 在读出 slot 的 value 之前就将 head值 -1,取消对这个 slot 的控制.\n\t\t// Confirm tail and decrement head. We do this before\n\t\t// reading the value to take back ownership of this\n\t\t// slot.\n\t\thead--\n\t\tptrs2 := d.pack(head, tail)\n\t\tif atomic.CompareAndSwapUint64(&amp;d.headTail, ptrs, ptrs2) &#123;\n\t\t\t// We successfully took back slot.\n\t\t\tslot = &amp;d.vals[head&amp;uint32(len(d.vals)-1)]\n\t\t\tbreak\n\t\t&#125;\n\t&#125;\n\n\tval := *(*any)(unsafe.Pointer(slot))\n\tif val == dequeueNil(nil) &#123;\n\t\tval = nil\n\t&#125;\n\t// Zero the slot. Unlike popTail, this isn't racing with\n\t// pushHead, so we don't need to be careful here.\n\t*slot = eface&#123;&#125;\n\treturn val, true\n&#125;\n\n\n通过 自旋锁的模式(for 循环 + CAS)  避免加锁.\n2.1.3 getSlow如果在 shared里面没有获得缓存对象,则继续调用 Pool.getSlow, 尝试从其他 P 的 poolLocal 中偷取.\nfunc (p *Pool) getSlow(pid int) any &#123;\n\t// See the comment in pin regarding ordering of the loads.\n\tsize := runtime_LoadAcquintptr(&amp;p.localSize) // load-acquire\n\tlocals := p.local                            // load-consume\n\t// 尝试从其他P中偷取 对象.\n\t// Try to steal one element from other procs.\n\tfor i := 0; i &lt; int(size); i++ &#123;\n\t\tl := indexLocal(locals, (pid+i+1)%int(size))\n\t\tif x, _ := l.shared.popTail(); x != nil &#123;\n\t\t\treturn x\n\t\t&#125;\n\t&#125;\n\n\t// 尝试从victim cache中取对象。这发生在尝试从其他 P 的 poolLocal 偷去失败后，\n\t// 因为这样可以使 victim 中的对象更容易被回收.\n\t// \n\t// Try the victim cache. We do this after attempting to steal\n\t// from all primary caches because we want objects in the\n\t// victim cache to age out if at all possible.\n\tsize = atomic.LoadUintptr(&amp;p.victimSize)\n\tif uintptr(pid) >= size &#123;\n\t\treturn nil\n\t&#125;\n\tlocals = p.victim\n\tl := indexLocal(locals, pid)\n\tif x := l.private; x != nil &#123;\n\t\tl.private = nil\n\t\treturn x\n\t&#125;\n\tfor i := 0; i &lt; int(size); i++ &#123;\n\t\tl := indexLocal(locals, (pid+i)%int(size))\n\t\tif x, _ := l.shared.popTail(); x != nil &#123;\n\t\t\treturn x\n\t\t&#125;\n\t&#125;\n\n\t// 清空 victimCache,下次就不用从这里面找了.\n\t// Mark the victim cache as empty for future gets don't bother\n\t// with it.\n\tatomic.StoreUintptr(&amp;p.victimSize, 0)\n\n\treturn nil\n&#125;\n\n\n从索引为 pid + 1 的 poolLocal 开始, 尝试调用shared.popTail 获取缓存对象. 如果没有拿到,从victim中查找. 和 从 poolLocal 的逻辑类似.\n最后 如果还没有找到,就把 victimSize 值 0. 防止后来的人再从 victim中找.\n在 Get 函数的最后，经过这一番操作还是没找到缓存的对象，就调用 New 函数创建一个新的对象.\n\n2.1.4 popTailfunc (c *poolChain) popTail() (any, bool) &#123;\n\td := loadPoolChainElt(&amp;c.tail)\n\tif d == nil &#123;\n\t\treturn nil, false\n\t&#125;\n\n\tfor &#123;\n\t\t// It's important that we load the next pointer\n\t\t// *before* popping the tail. In general, d may be\n\t\t// transiently empty, but if next is non-nil before\n\t\t// the pop and the pop fails, then d is permanently\n\t\t// empty, which is the only condition under which it's\n\t\t// safe to drop d from the chain.\n\t\td2 := loadPoolChainElt(&amp;d.next)\n\n\t\tif val, ok := d.popTail(); ok &#123;\n\t\t\treturn val, ok\n\t\t&#125;\n\n\t\tif d2 == nil &#123;\n\t\t\t// This is the only dequeue. It's empty right\n\t\t\t// now, but could be pushed to in the future.\n\t\t\treturn nil, false\n\t\t&#125;\n\n\t\t// The tail of the chain has been drained, so move on\n\t\t// to the next dequeue. Try to drop it from the chain\n\t\t// so the next pop doesn't have to look at the empty\n\t\t// dequeue again.\n\t\tif atomic.CompareAndSwapPointer((*unsafe.Pointer)(unsafe.Pointer(&amp;c.tail)), unsafe.Pointer(d), unsafe.Pointer(d2)) &#123;\n\t\t\t// We won the race. Clear the prev pointer so\n\t\t\t// the garbage collector can collect the empty\n\t\t\t// dequeue and so popHead doesn't back up\n\t\t\t// further than necessary.\n\t\t\t// 甩掉尾结点.\n\t\t\tstorePoolChainElt(&amp;d2.prev, nil)\n\t\t&#125;\n\t\td = d2\n\t&#125;\n&#125;\n\n\n// popTail removes and returns the element at the tail of the queue.\n// It returns false if the queue is empty. It may be called by any\n// number of consumers.\nfunc (d *poolDequeue) popTail() (any, bool) &#123;\n\tvar slot *eface\n\tfor &#123;\n\t\tptrs := atomic.LoadUint64(&amp;d.headTail)\n\t\thead, tail := d.unpack(ptrs)\n\t\tif tail == head &#123;\n\t\t\t// Queue is empty.\n\t\t\treturn nil, false\n\t\t&#125;\n\n\t\t// Confirm head and tail (for our speculative check\n\t\t// above) and increment tail. If this succeeds, then\n\t\t// we own the slot at tail.\n\t\tptrs2 := d.pack(head, tail+1)\n\t\tif atomic.CompareAndSwapUint64(&amp;d.headTail, ptrs, ptrs2) &#123;\n\t\t\t// Success.\n\t\t\tslot = &amp;d.vals[tail&amp;uint32(len(d.vals)-1)]\n\t\t\tbreak\n\t\t&#125;\n\t&#125;\n\n\t// We now own slot.\n\tval := *(*any)(unsafe.Pointer(slot))\n\tif val == dequeueNil(nil) &#123;\n\t\tval = nil\n\t&#125;\n\n\t// Tell pushHead that we're done with this slot. Zeroing the\n\t// slot is also important so we don't leave behind references\n\t// that could keep this object live longer than necessary.\n\t//\n\t// We write to val first and then publish that we're done with\n\t// this slot by atomically writing to typ.\n\tslot.val = nil\n\tatomic.StorePointer(&amp;slot.typ, nil)\n\t// At this point pushHead owns the slot.\n\n\treturn val, true\n&#125;\n\n\n2.2. Put// Put adds x to the pool.\nfunc (p *Pool) Put(x any) &#123;\n\tif x == nil &#123;\n\t\treturn\n\t&#125;\n\tif race.Enabled &#123;\n\t\tif fastrandn(4) == 0 &#123;\n\t\t\t// Randomly drop x on floor.\n\t\t\treturn\n\t\t&#125;\n\t\trace.ReleaseMerge(poolRaceAddr(x))\n\t\trace.Disable()\n\t&#125;\n\tl, _ := p.pin()\n\tif l.private == nil &#123;\n\t\tl.private = x\n\t\tx = nil\n\t&#125;\n\tif x != nil &#123;\n\t\tl.shared.pushHead(x)\n\t&#125;\n\truntime_procUnpin()\n\tif race.Enabled &#123;\n\t\trace.Enable()\n\t&#125;\n&#125;\n\n\n\n\n先绑定 g 和 P.  然后尝试将 x 赋值给 private字段.\n如果失败. 就调用 pushHead() 尝试将其放入 shared字段 维护的双端队列中.\n\n\n2.2.1 pushHeadfunc (c *poolChain) pushHead(val any) &#123;\n\td := c.head\n\tif d == nil &#123;\n\t\t// Initialize the chain.\n\t\tconst initSize = 8 // Must be a power of 2\n\t\td = new(poolChainElt)\n\t\td.vals = make([]eface, initSize)\n\t\tc.head = d\n\t\tstorePoolChainElt(&amp;c.tail, d)\n\t&#125;\n\n\tif d.pushHead(val) &#123;\n\t\treturn\n\t&#125;\n\n\t// 当前 poolDequeue 满了. 分配一个 当前 poolDequeue 2倍的一个 poolDequeue\n\t// The current dequeue is full. Allocate a new one of twice\n\t// the size.\n\tnewSize := len(d.vals) * 2\n\tif newSize >= dequeueLimit &#123;\n\t\t// Can't make it any bigger.\n\t\tnewSize = dequeueLimit\n\t&#125;\n\n\t// 收尾相连. 构成链表\n\td2 := &amp;poolChainElt&#123;prev: d&#125;\n\td2.vals = make([]eface, newSize)\n\tc.head = d2\n\tstorePoolChainElt(&amp;d.next, d2)\n\td2.pushHead(val)\n&#125;\n\n\n// // 将 val 添加到双端队列头部。如果队列已满，则返回 false。此函数只能被一个生产者调用\n//\n// pushHead adds val at the head of the queue. It returns false if the\n// queue is full. It must only be called by a single producer.\nfunc (d *poolDequeue) pushHead(val any) bool &#123;\n\tptrs := atomic.LoadUint64(&amp;d.headTail)\n\thead, tail := d.unpack(ptrs)\n\n\t//队列满了\n\tif (tail+uint32(len(d.vals)))&amp;(1&lt;&lt;dequeueBits-1) == head &#123;\n\t\t// Queue is full.\n\t\treturn false\n\t&#125;\n\tslot := &amp;d.vals[head&amp;uint32(len(d.vals)-1)]\n\n\t// Check if the head slot has been released by popTail.\n\ttyp := atomic.LoadPointer(&amp;slot.typ)\n\tif typ != nil &#123;\n\t\t// Another goroutine is still cleaning up the tail, so\n\t\t// the queue is actually still full.\n\t\treturn false\n\t&#125;\n\n\t// The head slot is free, so we own it.\n\tif val == nil &#123;\n\t\tval = dequeueNil(nil)\n\t&#125;\n\t*(*any)(unsafe.Pointer(slot)) = val\n\n\t// Increment head. This passes ownership of slot to popTail\n\t// and acts as a store barrier for writing the slot.\n\tatomic.AddUint64(&amp;d.headTail, 1&lt;&lt;dequeueBits)\n\treturn true\n&#125;\n\n\n\n\n3. pack &amp; unpack3. GC\n[参考]深度解密 Go 语言之 sync.Pool 请问sync.Pool有什么缺点?几个 Go 系统可能遇到的锁问题\n","slug":"golang-sync-Pool解析","date":"2022-08-11T17:15:26.000Z","categories_index":"","tags_index":"golang","author_index":"majm"},{"id":"7f644a5a0ef8dce45a5c7a8966cb4d95","title":"clickhouse-原理","content":"\n\n\n\n\n\n\n\n\nClickhouse 是一个 用于联机分析(OLAP)的 列式存储数据库管理系统(DBMS).\n\n\n常见的列式数据库有: Vertica、 Paraccel (Actian Matrix，Amazon Redshift)、 Sybase IQ、 Exasol、 Infobright、 InfiniDB、 MonetDB (VectorWise， Actian Vector)、 LucidDB、 SAP HANA、 Google Dremel、 Google PowerDrill、 Druid、 kdb+.\nOLAP 场景的关键特征\n绝大多数是读请求\n数据以相当大的批次(&gt; 1000行)更新，而不是单行更新;或者根本没有更新。\n已添加到数据库的数据不能修改。\n对于读取，从数据库中提取相当多的行，但只提取列的一小部分。\n宽表，即每个表包含着大量的列\n查询相对较少(通常每台服务器每秒查询数百次或更少)\n对于简单查询，允许延迟大约50毫秒\n列中的数据相对较小：数字和短字符串(例如，每个URL 60个字节)\n处理单个查询时需要高吞吐量(每台服务器每秒可达数十亿行)\n事务不是必须的\n对数据一致性要求低\n每个查询有一个大表。除了他以外，其他的都很小。\n查询结果明显小于源数据。换句话说，数据经过过滤或聚合，因此结果适合于单个服务器的RAM中\n\n列式数据库更适合OLAP场景的原因列式数据库更适合于OLAP场景(对于大多数查询而言，处理速度至少提高了100倍).\n\n\n为什么会出现这种情况?\n1. IO\n针对分析类查询, 通常只需要读取表的一小部分列.在列式数据库中你可以只读取你需要的数据.例如，如果只需要读取100列中的5列，这将帮助你最少减少20倍的I&#x2F;O消耗.\n由于数据总是打包成批量读取的，所以压缩是非常容易的.同时数据按列分别存储这也更容易压缩.这进一步降低了I&#x2F;O的体积.\n由于I&#x2F;O的降低,这将帮助更多的数据被系统缓存.\n例如: 查询统计每个广告平台的记录数量需要读取广告平台ID这一列,它在未压缩的情况下需要1个字节进行存储.如果大部分流量不是来自广告平台，那么这一列至少可以以十倍的压缩率被压缩.当采用快速压缩算法,它的解压速度最少在十亿字节(未压缩数据)每秒.换句话说,这个查询可以在单个服务器上以每秒大约几十亿行的速度进行处理.这实际上是当前实现的速度。\n\n2.  CPU\n\n\n\n\n\n\n\n\n由于执行一个查询需要处理大量的行,因此在整个向量上执行所有操作将比在每一行上执行所有操作更加高效.同时这将有助于实现一个几乎没有调用成本的查询引擎.如果你不这样做,使用任何一个机械硬盘.查询引擎都不可避免的停止CPU进行等待.所以,在数据按列存储并且按列执行是很有意义的.\n有两种方法可以做到这一点: \n\n向量引擎: 所有的操作都是为向量而不是为单个值编写的.这意味着多个操作之间的不再需要频繁的调用,并且调用的成本基本可以忽略不计.操作代码包含一个优化的内部循环.\n\n代码生成: 生成一段代码,包含查询中的所有操作.\n\n\n\n[参考]什么是clickhouse\n","slug":"clickhouse-原理","date":"2022-08-11T17:00:53.000Z","categories_index":"","tags_index":"clickhouse","author_index":"majm"},{"id":"d96ad83bba94948fc2ba2a5f3d6fbcb0","title":"go build 实现包切换","content":"参考 Gin 的实现\ngin 在  internal/json包中实现了多个 json 包的序列化能力, 默认使用官方encoding/json包. 如何保证这些包不会冲突呢?\n这里用到了  go build -tags 的能力.\n[json.go](https://github.com/gin-gonic/gin/blob/master/internal/json/json.go)\n// Copyright 2017 Bo-Yi Wu. All rights reserved.\n// Use of this source code is governed by a MIT style\n// license that can be found in the LICENSE file.\n\n//go:build !jsoniter &amp;&amp; !go_json &amp;&amp; !(sonic &amp;&amp; avx &amp;&amp; (linux || windows || darwin) &amp;&amp; amd64)\n// +build !jsoniter\n// +build !go_json\n// +build !sonic !avx !linux,!windows,!darwin !amd64\n\npackage json\n\nimport \"encoding/json\"\n\nvar (\n\t// Marshal is exported by gin/json package.\n\tMarshal = json.Marshal\n\t// Unmarshal is exported by gin/json package.\n\tUnmarshal = json.Unmarshal\n\t// MarshalIndent is exported by gin/json package.\n\tMarshalIndent = json.MarshalIndent\n\t// NewDecoder is exported by gin/json package.\n\tNewDecoder = json.NewDecoder\n\t// NewEncoder is exported by gin/json package.\n\tNewEncoder = json.NewEncoder\n)\n\n\n[jsoniter.go](https://github.com/gin-gonic/gin/blob/master/internal/json/jsoniter.go)\n// Copyright 2017 Bo-Yi Wu. All rights reserved.\n// Use of this source code is governed by a MIT style\n// license that can be found in the LICENSE file.\n\n//go:build jsoniter\n// +build jsoniter\n\npackage json\n\nimport jsoniter \"github.com/json-iterator/go\"\n\nvar (\n\tjson = jsoniter.ConfigCompatibleWithStandardLibrary\n\t// Marshal is exported by gin/json package.\n\tMarshal = json.Marshal\n\t// Unmarshal is exported by gin/json package.\n\tUnmarshal = json.Unmarshal\n\t// MarshalIndent is exported by gin/json package.\n\tMarshalIndent = json.MarshalIndent\n\t// NewDecoder is exported by gin/json package.\n\tNewDecoder = json.NewDecoder\n\t// NewEncoder is exported by gin/json package.\n\tNewEncoder = json.NewEncoder\n)\n\n\n切换 不同的 json实现采用  jsoniter包\ngo build -tags&#x3D;jsoniter .\n\n\n\n条件编译通过在代码中增加注释//+build xxx时,编译时传递对应的tags值,就会编译不同的文件.\n\n构建约束以一行+build开始的注释.在+build之后列出了一些条件,在这些条件成立时,该文件应包含在编译的包中;\n约束可以出现在任何源文件中,不限于go文件;\n+build必须出现在package语句之前,+build注释之后应要有一个空行.\n\n参考-Compile and install the application-Compile_packages_and_dependencies-Go条件编译\n","slug":"go-build-实现包切换","date":"2022-08-03T04:18:02.000Z","categories_index":"","tags_index":"go,go build","author_index":"majm"},{"id":"2797f253c04e63756fe2c781cd7fcc62","title":"洋葱架构","content":"\n\n\n领域是一个知识范畴,他指的是我们的软件要模拟的业务知识。 领域驱动设计的核心是 领域模型,它对一个领域的流程和规则有着深刻的理解,洋葱架构实现了这一概念,并极大地改善了代码的品质,降低了复杂性,并且支持不断地发展企业系统.\n\n详解”洋葱架构”Onion Architecture\n","slug":"洋葱架构","date":"2022-07-23T06:23:04.000Z","categories_index":"","tags_index":"架构","author_index":"majm"},{"id":"911037a657c82ed3571b8e922dfd713c","title":"六边形架构","content":"分层架构是一种架构风格,本质是避免耦合,使边界清晰.六边形架构 遵循了分层架构的所有约束与特性，其实使用 端口与适配器这个名字更加合适.因为六边形架构的 边数没有意义.\n六边形架构能够充分地区分 领域模型与 输入输出设备之间的界限.\n\n\n\n\n1. 六边形架构(端口与适配器)\n一种具有对称性特征的架构风格\n在这种架构中不同的客户通过”平等”的方式与系统交互\n新客户的加入,只需要添加一个新的适配器将客户输入转化成能被系统 API 所理解的参数就行了\n系统输出(图形界面、持久化和消息等)都有一个新建的适配器负责完成相应的转化功能.\n\n2. 六边形架构的概念实体 Entity领域对象的一个 Snapshot.  他不知道自身的存储位置.\n存储器 Repositories是获取实体及创建和更改实体的 interface.它们保存一系列方法,用来与数据源通信并返回单个实体或实体列表\n交互器 Interactors是用来编排和执行域动作(domain action),的类——可以考虑服务对象或用例对象.它们实现复杂的业务规则和针对特定域动作的验证逻辑.\n数据源 Datasource是针对不同 Repository 实现的适配器(Adaptor). 数据源可能是 SQL 数据库的适配器弹性搜索适配器,REST API,CSV 文件, 或者 Hash表 之类的简单适配器.   数据源实现在 Repository 上定义的方法, 并存储获取和推送数据的实现.\n层: 领域层领域模型包含了所有的应用逻辑与规则.\n领域层中不会直接引用技术实现(细节),例如 HTTP 上下文或数据库调用,这样就能够确保在技术方面的改动不会影响到领域层面.\n层:  端口层负责接收与用例相关的所有请求,这些请求负责在领域层中协调工作\n端口层在端口内部作为领域层的边界,在端口外部则扮演了外部实体的角色.\n层: 适配器层这一层的技术实现负责以某种格式接收输入,及产生输出.\n在适配器层不存在领域逻辑,它的唯一职责就是在外部世界与领域层之间进行技术性的转换.\n3. 六边形架构的优点\n可以轻易的开发用于测试的适配器。\n应用程序和领域模型可以在没有客户和存储机制的条件下进行设计开发\n任何测试客户都可以在用户解密还未完成之前进行开发\n选择持久化机制之前，可以在测试中采用内存资源库来模拟持久化\n如此可以在核心领域上进行持续开发,不需要考虑那些支撑性的技术组件\n\n4.  六边形架构的核心思想关注点分离\n重心放在领域业务逻辑上, 因为领域的业务逻辑相对更加稳定,体现应用的核心价值,应当优先详尽的设计与测试.\n外部的输入驱动逻辑和输出给外部的被驱动逻辑存在可变性,可替换性,同时可以依赖多种不同的具体技术实现,可以在后一个阶段考虑.\n实际研发过程中还存在输出的外部系统还没有设计与开发好的情况,此时在节奏上也不匹配,可能只有对方的设计文档,甚至更严重的情况下设计文档都没\n输出的外部系统存在多种不同类型的可能,例如在有些情况下你对接的是 OpenStack,有些情况下对接的是 VMware 。\n\n外部可替换内部不关心外部如何使用端口， 外部使用者是可替换的这个原则一开始设计的时候就需要遵守。适配器可以分为2类，“驱动者适配器”和“被驱动者适配器”，也可以称为“输入型适配器”和“输出型适配器”。输出型适配器从表面上看似乎是内部在使用外部，与外部可替换的原则有冲突，这个问题实际上需要通过“依赖倒置”解决。\n依赖倒置Adapter  + Repository\n可测试性\n内六边形中的应用程序应当可以在不依赖外部的情况下自行测试.\n通过 接口可以 方便的 进行 mock.\n\n\n[参考]六边形架构的理解探索六边形架构深入理解六边形架构Netflix 的六边形架构实践\n","slug":"六边形架构","date":"2022-07-23T02:47:02.000Z","categories_index":"","tags_index":"架构","author_index":"majm"},{"id":"0fbff2d6e80a66fc76d63bc97dc872bd","title":"位运算-基础","content":"\n\n\n异或操作x ^ 0  &#x3D; x\nx ^ 1s &#x3D; ~x  &#x2F;&#x2F; 1s  &#x3D; ~0\nx ^ ~x &#x3D; 1s\nx ^ x  &#x3D; 0\nc &#x3D; a ^ b  &#x3D;&gt; a ^ c &#x3D; b,  b ^ c &#x3D; a    &#x2F;&#x2F; 交换两个数\na ^ b ^ c &#x3D; a ^ (b ^ c) &#x3D; (a ^ b) ^ c  &#x2F;&#x2F; associate\n\n\n\n指定位置的 位运算\n将 x 最右边的 n位清零  :   x &amp; (~0 &lt;&lt; n)\n获取 x 的第n位的值(1|0):   (x &gt;&gt; n) &amp; 1\n获取 x 的第n位的幂值   :    x &amp;(1 &lt;&lt; n)\n仅将第 n 位置 1       :    x | (1&lt;&lt; n)\n仅将第 n 位置 0       :    x &amp; ~(1&lt;&lt; n)\n仅将第 n 位取反       :    x ^ (1&lt;&lt; n)\n将x最高位至第n(含)位清零:    x&amp;((1&lt;&lt;n) - 1)\n获取x  最右边的 1     :     x &amp; -x (lowbit操作)\n\n\na      &#x3D; 00110100\n~a     &#x3D; 11001011\n-a     &#x3D; 11001100\na &amp; -a &#x3D; 00000100\n\n常用操作\n判断奇偶\n\n\nx % 2 &#x3D;&#x3D; 0  &#x3D;&gt;   (x &amp; 1) &#x3D;&#x3D; 0\nx % 2 &#x3D;&#x3D; 1  &#x3D;&gt;   (x &amp; 1) &#x3D;&#x3D; 1\n\n\nx &gt;&gt; 1 &#x3D;&#x3D; x &#x2F; 2mid &#x3D; (left + right) &#x2F; 2   &#x3D;&#x3D; mid &#x3D; (left + right) &gt;&gt; 1 \n\nx &#x3D; x &amp;(x-1)  清零最低位的1\n\nx &amp; -x       得到最低位的 1 \n\nx &amp; ~x  &#x3D;&#x3D; 0\n\n\n应用\nbloomFilter\n\n\n","slug":"位运算-基础","date":"2022-07-19T15:29:47.000Z","categories_index":"","tags_index":"算法,位运算","author_index":"majm"},{"id":"5ed57e13aea17add1dca2c51e84aa68f","title":"《架构整洁之道》-读书笔记:7-11章","content":"《架构整洁之道》-读书笔记:7-11章架构整洁之道: 第 7-11 章 主要讲的是 设计原则, SOLID,SOLID 的主要作用是告诉我们如何将数据和函数组织称为类,以及如何将这些类链接起来组合成一个程序.\n软件构建中层模块主要目标如下:\n\n使软件可容忍被改动.\n是软件更容易被理解.\n构建在多个系统中复用的组件.\n\nSOLID 原则应该紧贴于代码实现之上,这些原则主要是帮助我们定义软件架构中组件和模块的.\n\nSRP  Single Resposibility Principle每个软件应该有且仅有一个被修改的理由.\nOCP  Open Close Principle如果软件系统想要更容易被改变,那么设计就必须允许新增代码来修改系统行为,而非只能靠修改原来的代码.\nLSP  Liskov Substitution Principle利用可替换的组件构建软件系统,那么这些组件就必须遵循同一个约定,以便让谢谢组件可以相互替换.\nISP  Interface Segregation Principle在设计中避免不必要的依赖.\nDIP  Depencency Inverse Principle高层策略性的代码不应该依赖实现底层细节的代码,恰恰相反,那些实现底层细节的代码应该依赖高层策略性的代码.\n\n\n\n\nSRP 单一职责原则最重要的一个原则, 其他原则也基本是上都与这个原则有关.《架构整洁之道》这本书中的例子讲的很好\n任何一个软件模块都应该有且仅有一个被修改的原因.\n任何一个软件模块都应该只对某一类行为者负责.\n多人为了不同的目的修改了同一份源代码,这很容易造成问题的产生. 而避免这种问题产生的方法就是将服务不同行为者的代码进行切分.\nOCP 开闭原则设计良好的计算机软件应该易于扩展, 同时抗拒修改.\n如果A组件不想被B组件上发生的修改所影响, 那么就应该让B组件依赖于A组件.\n软件系统不应该依赖其不直接使用的组件\nOCP是我们进行系统架构设计的主导原则,其主要目标是让系统易于扩展,同时限制其每次被修改所影响的范围.实现方式是通过将系统划分为一系列组件,并且将这些组件间的依赖关系按层次结构进行组织,使得高阶组件不会因低阶组件被修改而受到影响.\nLSP  里氏替换原则果对于每个类型是S的对象o1都存在一个类型为T的对象o2,能使操作T类型的程序P在用o2替换o1时行为保持不变,我们就可以将S称为T的子类型.(指导类的设计)\nLSP可以且应该被应用于软件架构层面,因为一旦违背了可替换性,该系统架构就不得不为此增添大量复杂的应对机制.\nISP 接口隔离原则任何层次的软件设计如果依赖了它并不需要的东西.就会带来意料之外的麻烦.\n目的是为了解耦,不依赖其不需要的系统,避免牵一发而动全身.\n\n\nDIP  依赖反转原则如果想要设计一个灵活的系统,在源代码层次的依赖关系中就应该多引用抽象类型,而非具体实现.\n在应用DIP时,我们也不必考虑稳定的操作系统或者平台设施,因为这些系统接口很少会有变动.我们主要应该关注的是软件系统内部那些会经常变动的(volatile)具体实现模块,这些模块是不停开发的,也就会经常出现变更.\n稳定的抽象层应在代码中多使用抽象接口，尽量避免使用那些多变的具体实现类. (抽象工厂)不要在具体实现类上创建衍生类.不要覆盖（override）包含具体实现的函数.在这里,控制依赖关系的唯一办法,就是创建一个抽象函数,然后再为该函数提供多种具体实现. (不要引入源代码层级的依赖)应避免在代码中写入与任何具体实现相关的名字,或者是其他容易变动的事物的名字.\n🏭工厂模式如果要创建出一个稳定的抽象层, 要对那些容易变的对象的创建过程做一些特殊处理. (因为基本在所有的编程语言中,对象的创建都免不了源代码层级上依赖对象的具体实现.)一般场景下,使用抽象工厂模式解决源代码层级依赖的问题.\n中间那条曲线代表了软件架构中抽象层与具体实现层之间的边界,这里,所有跨越这条边界的源代码级别的依赖关系都应该是单向的. 也即具体实现依赖于抽象.\n\n[参考]极客时间-设计模式之美架构整洁之道-阿里云盘\n","slug":"《架构整洁之道》-读书笔记-7-11章","date":"2022-07-09T06:01:58.000Z","categories_index":"","tags_index":"读书笔记,架构整洁之道","author_index":"majm"},{"id":"8f865e6ecd68910430d22fc2c9ae4d28","title":"Intelij-快捷键","content":"常用快捷键\nCtrl + Command + G :  选中所有相同的的内容\n\nCtrl + G :            选中下一个相同的内容\n\n\n\n","slug":"Intelij-快捷键","date":"2022-07-07T03:20:28.000Z","categories_index":"","tags_index":"Intelij,快捷键","author_index":"majm"},{"id":"f618fdcc06390449a60431b1cd6a19c6","title":"算法-线段树","content":"线段树是经常用来维护区间信息的数据结构,线段树可以在 O(logN) 的时间复杂度内实现单点修改,区间修改,区间查询(区间求和,区间最大值,区间最小值) 等操作.\n线段树的数据结构\n线段树是一种近似的完全二叉树,每个节点代表一个区间,节点的权值. 根节点是整个区间.每个节点的左孩子是该节点所代表的的区间的左半部分,右孩子是右半部分.\n线段树采用 类似堆的 数组  来存储数据.\n属性\n每个区间的长度是区间内整数的个数;\n叶子节点长度为1,不能再分;\n若一个结点对应的区间是[left,right], mid = (left + right) / 2 则其子区间对应的节点分别是[left,mid]和[mid+1,right];\n线段树的高度是;log2(right- left + 1)\n线段树把区间上的任意一条线段都分成不超过 2log2N\n\n线段树的定义code​\nvar (\n\trootIndex = 1\n)\n\n// index = 1 开始编号\ntype Segment struct &#123;\n\tleft  int // 区间起始点\n\tright int // 区间 结束点\n\tcount int // 统计值\n&#125;\n\ntype SegmentTree struct &#123;\n\tm        int\n\tsegments []*Segment\n&#125;\n\nfunc NewSegmentTree(m int) *SegmentTree &#123;\n\treturn &amp;SegmentTree&#123;\n\t\tm:        m,\n\t\tsegments: make([]*Segment, 4*m),\n\t&#125;\n&#125;\n\nfunc (st *SegmentTree) buildSegmentTreeInternal(left, right, i int) &#123;\n\n\tst.segments[i] = &amp;Segment&#123;\n\t\tleft:  left,\n\t\tright: right,\n\t\tcount: 0,\n\t&#125;\n\tif left == right &#123;\n\t\treturn\n\t&#125;\n\tmid := left + (right-left)/2\n\tst.buildSegmentTreeInternal(left, mid, i*2)\n\tst.buildSegmentTreeInternal(mid+1, right, i*2+1)\n&#125;\n\nfunc (st *SegmentTree) insert(data int) &#123;\n\tleft, right := 1, st.m\n\ti := rootIndex\n\tfor left &lt; right &#123;\n\t\tmid := left + (right - left) + 1\n\t\tst.segments[i].count++\n\t\tif data &lt;= mid &#123;\n\t\t\tright = mid\n\t\t\ti = 2 * i\n\t\t&#125; else &#123;\n\t\t\tleft = mid + 1\n\t\t\ti = 2*i + 1\n\t\t&#125;\n\t&#125;\n\tst.segments[i].count++\n&#125;\n\nfunc (st *SegmentTree) delete(data int) &#123;\n\tleft, right := 1, st.m\n\ti := rootIndex\n\n\tfor left &lt; right &#123;\n\t\tst.segments[i].count--\n\t\tmid := left + (right-left)/2\n\t\tif data &lt;= mid &#123;\n\t\t\tright = mid\n\t\t\ti = 2 * i\n\t\t&#125; else &#123;\n\t\t\tleft = mid + 1\n\t\t\ti = 2*i + 1\n\t\t&#125;\n\t&#125;\n\tst.segments[i].count--\n&#125;\n\n// query\nfunc (st *SegmentTree) count(left, right int) int &#123;\n\treturn st.countInternal(left, right, rootIndex)\n&#125;\n\nfunc (st *SegmentTree) countInternal(left int, right int, index int) int &#123;\n\t// terminate\n\tseg := st.segments[index]\n\tif seg.left == left &amp;&amp; seg.right == right &#123;\n\t\treturn seg.count\n\t&#125;\n\n\tmid := seg.left + (seg.right-seg.left)>>1\n\tif mid >= right &#123;\n\t\t//区间在左子节点\n\t\treturn st.countInternal(left, right, 2*index)\n\t&#125; else if mid &lt; left &#123;\n\t\t// 区间在右子节点\n\t\treturn st.countInternal(left, right, 2*index+1)\n\t&#125; else &#123;\n\t\treturn st.countInternal(left, mid, 2*index) +\n\t\t\tst.countInternal(mid+1, right, 2*index+1)\n\t&#125;\n\n&#125;\n\nfunc (st *SegmentTree) getKth(left, right, k int) int &#123;\n\treturn st.getKthInternal(left, right, rootIndex, k)\n&#125;\n\nfunc (st *SegmentTree) getKthInternal(left int, right int, index int, k int) int &#123;\n\tseg := st.segments[index]\n\tif left == seg.left &amp;&amp; right == seg.right &#123;\n\t\tif k == -1 &#123;\n\t\t\t//第 Kth 大值不存在\n\t\t\treturn -1\n\t\t&#125; else &#123;\n\t\t\treturn seg.left\n\t\t&#125;\n\t&#125;\n\trightSeg := st.segments[2*index+1]\n\tmid := left + (right-left)/2\n\tif rightSeg.count > k &#123;\n\t\treturn st.getKthInternal(mid+1, right, 2*index+1, k)\n\t&#125; else &#123;\n\t\treturn st.getKthInternal(left, mid, 2*index, k-rightSeg.count)\n\t&#125;\n&#125;\n\n\n\n\n\n\n\n[参考]线段树知乎-线段树\n","slug":"算法-线段树","date":"2022-06-25T02:07:37.000Z","categories_index":"","tags_index":"algorithm,线段树,区间","author_index":"majm"},{"id":"c648812ee90e87a774c05f7906322d9f","title":"grpc-DNSResolver","content":"\n\n\n\n\nCoderesolver/resolver.go\npackage resolver\n\nimport (\n\t\"context\"\n\t\"net\"\n\t\"net/url\"\n\n\t\"google.golang.org/grpc/attributes\"\n\t\"google.golang.org/grpc/credentials\"\n\t\"google.golang.org/grpc/internal/pretty\"\n\t\"google.golang.org/grpc/serviceconfig\"\n)\n\nvar (\n\t// m is a map from scheme to resolver builder.\n\tm = make(map[string]Builder)\n\t// defaultScheme is the default scheme to use.\n\tdefaultScheme = \"passthrough\"\n)\n\n// TODO(bar) install dns resolver in init()&#123;&#125;.\n\n// Register registers the resolver builder to the resolver map. b.Scheme will be\n// used as the scheme registered with this builder.\n//\n// NOTE: this function must only be called during initialization time (i.e. in\n// an init() function), and is not thread-safe. If multiple Resolvers are\n// registered with the same name, the one registered last will take effect.\n// 注册scheme -> ResolverBuilder 的映射关系. 可以注册自定义的  Resolver\nfunc Register(b Builder) &#123;\n\tm[b.Scheme()] = b\n&#125;\n\n// Get returns the resolver builder registered with the given scheme.\n//\n// If no builder is register with the scheme, nil will be returned.\n// 根据 schema 获取 对应的 resolver 构建器\nfunc Get(scheme string) Builder &#123;\n\tif b, ok := m[scheme]; ok &#123;\n\t\treturn b\n\t&#125;\n\treturn nil\n&#125;\n\n// SetDefaultScheme sets the default scheme that will be used. The default\n// default scheme is \"passthrough\".\n//\n// NOTE: this function must only be called during initialization time (i.e. in\n// an init() function), and is not thread-safe. The scheme set last overrides\n// previously set values.\n// 设置默认的  schema,grpc 默认的构建器 是  passthrough\nfunc SetDefaultScheme(scheme string) &#123;\n\tdefaultScheme = scheme\n&#125;\n\n// GetDefaultScheme gets the default scheme that will be used.\nfunc GetDefaultScheme() string &#123;\n\treturn defaultScheme\n&#125;\n\n// AddressType indicates the address type returned by name resolution.\n//\n// Deprecated: use Attributes in Address instead.\ntype AddressType uint8\n\nconst (\n\t// Backend indicates the address is for a backend server.\n\t//\n\t// Deprecated: use Attributes in Address instead.\n\tBackend AddressType = iota\n\t// GRPCLB indicates the address is for a grpclb load balancer.\n\t//\n\t// Deprecated: to select the GRPCLB load balancing policy, use a service\n\t// config with a corresponding loadBalancingConfig.  To supply balancer\n\t// addresses to the GRPCLB load balancing policy, set State.Attributes\n\t// using balancer/grpclb/state.Set.\n\tGRPCLB\n)\n\n// Address represents a server the client connects to.\n// 表示客户端需要访问的服务器地址\n//\n// Experimental\n//\n// Notice: This type is EXPERIMENTAL and may be changed or removed in a\n// later release.\ntype Address struct &#123;\n\t// Addr is the server address on which a connection will be established.\n    // 用于构建  connection 的服务器地址\n\tAddr string\n\n\t// ServerName is the name of this address.\n\t// If non-empty, the ServerName is used as the transport certification authority for\n\t// the address, instead of the hostname from the Dial target string. In most cases,\n\t// this should not be set.\n\t//\n\t// If Type is GRPCLB, ServerName should be the name of the remote load\n\t// balancer, not the name of the backend.\n\t//\n\t// WARNING: ServerName must only be populated with trusted values. It\n\t// is insecure to populate it with data from untrusted inputs since untrusted\n\t// values could be used to bypass the authority checks performed by TLS.\n\tServerName string\n\n\t// Attributes contains arbitrary data about this address intended for\n\t// consumption by the SubConn.\n\tAttributes *attributes.Attributes\n\n\t// BalancerAttributes contains arbitrary data about this address intended\n\t// for consumption by the LB policy.  These attribes do not affect SubConn\n\t// creation, connection establishment, handshaking, etc.\n\tBalancerAttributes *attributes.Attributes\n\n\t// Type is the type of this address.\n\t//\n\t// Deprecated: use Attributes instead.\n\tType AddressType\n\n\t// Metadata is the information associated with Addr, which may be used\n\t// to make load balancing decision.\n\t//\n\t// Deprecated: use Attributes instead.\n\tMetadata interface&#123;&#125;\n&#125;\n\n// Equal returns whether a and o are identical.  Metadata is compared directly,\n// not with any recursive introspection.\nfunc (a Address) Equal(o Address) bool &#123;\n\treturn a.Addr == o.Addr &amp;&amp; a.ServerName == o.ServerName &amp;&amp;\n\t\ta.Attributes.Equal(o.Attributes) &amp;&amp;\n\t\ta.BalancerAttributes.Equal(o.BalancerAttributes) &amp;&amp;\n\t\ta.Type == o.Type &amp;&amp; a.Metadata == o.Metadata\n&#125;\n\n// String returns JSON formatted string representation of the address.\nfunc (a Address) String() string &#123;\n\treturn pretty.ToJSON(a)\n&#125;\n\n// BuildOptions includes additional information for the builder to create\n// the resolver.\ntype BuildOptions struct &#123;\n\t// DisableServiceConfig indicates whether a resolver implementation should\n\t// fetch service config data.\n\tDisableServiceConfig bool\n\t// DialCreds is the transport credentials used by the ClientConn for\n\t// communicating with the target gRPC service (set via\n\t// WithTransportCredentials). In cases where a name resolution service\n\t// requires the same credentials, the resolver may use this field. In most\n\t// cases though, it is not appropriate, and this field may be ignored.\n\tDialCreds credentials.TransportCredentials\n\t// CredsBundle is the credentials bundle used by the ClientConn for\n\t// communicating with the target gRPC service (set via\n\t// WithCredentialsBundle). In cases where a name resolution service\n\t// requires the same credentials, the resolver may use this field. In most\n\t// cases though, it is not appropriate, and this field may be ignored.\n\tCredsBundle credentials.Bundle\n\t// Dialer is the custom dialer used by the ClientConn for dialling the\n\t// target gRPC service (set via WithDialer). In cases where a name\n\t// resolution service requires the same dialer, the resolver may use this\n\t// field. In most cases though, it is not appropriate, and this field may\n\t// be ignored.\n\tDialer func(context.Context, string) (net.Conn, error)\n&#125;\n\n// State contains the current Resolver state relevant to the ClientConn.\ntype State struct &#123;\n\t// Addresses is the latest set of resolved addresses for the target.\n\tAddresses []Address\n\n\t// ServiceConfig contains the result from parsing the latest service\n\t// config.  If it is nil, it indicates no service config is present or the\n\t// resolver does not provide service configs.\n\tServiceConfig *serviceconfig.ParseResult\n\n\t// Attributes contains arbitrary data about the resolver intended for\n\t// consumption by the load balancing policy.\n\tAttributes *attributes.Attributes\n&#125;\n\n// ClientConn contains the callbacks for resolver to notify any updates\n// to the gRPC ClientConn.\n//\n// This interface is to be implemented by gRPC. Users should not need a\n// brand new implementation of this interface. For the situations like\n// testing, the new implementation should embed this interface. This allows\n// gRPC to add new methods to this interface.\ntype ClientConn interface &#123;\n\t// UpdateState updates the state of the ClientConn appropriately.\n\tUpdateState(State) error\n\t// ReportError notifies the ClientConn that the Resolver encountered an\n\t// error.  The ClientConn will notify the load balancer and begin calling\n\t// ResolveNow on the Resolver with exponential backoff.\n\tReportError(error)\n\t// NewAddress is called by resolver to notify ClientConn a new list\n\t// of resolved addresses.\n\t// The address list should be the complete list of resolved addresses.\n\t//\n\t// Deprecated: Use UpdateState instead.\n\tNewAddress(addresses []Address)\n\t// NewServiceConfig is called by resolver to notify ClientConn a new\n\t// service config. The service config should be provided as a json string.\n\t//\n\t// Deprecated: Use UpdateState instead.\n\tNewServiceConfig(serviceConfig string)\n\t// ParseServiceConfig parses the provided service config and returns an\n\t// object that provides the parsed config.\n\tParseServiceConfig(serviceConfigJSON string) *serviceconfig.ParseResult\n&#125;\n\n// Target represents a target for gRPC, as specified in:\n// https://github.com/grpc/grpc/blob/master/doc/naming.md.\n// It is parsed from the target string that gets passed into Dial or DialContext\n// by the user. And gRPC passes it to the resolver and the balancer.\n//\n// If the target follows the naming spec, and the parsed scheme is registered\n// with gRPC, we will parse the target string according to the spec. If the\n// target does not contain a scheme or if the parsed scheme is not registered\n// (i.e. no corresponding resolver available to resolve the endpoint), we will\n// apply the default scheme, and will attempt to reparse it.\n//\n// Examples:\n//\n// - \"dns://some_authority/foo.bar\"\n//   Target&#123;Scheme: \"dns\", Authority: \"some_authority\", Endpoint: \"foo.bar\"&#125;\n// - \"foo.bar\"\n//   Target&#123;Scheme: resolver.GetDefaultScheme(), Endpoint: \"foo.bar\"&#125;\n// - \"unknown_scheme://authority/endpoint\"\n//   Target&#123;Scheme: resolver.GetDefaultScheme(), Endpoint: \"unknown_scheme://authority/endpoint\"&#125;\ntype Target struct &#123;\n\t// Deprecated: use URL.Scheme instead.\n\tScheme string\n\t// Deprecated: use URL.Host instead.\n\tAuthority string\n\t// Deprecated: use URL.Path or URL.Opaque instead. The latter is set when\n\t// the former is empty.\n\tEndpoint string\n\t// URL contains the parsed dial target with an optional default scheme added\n\t// to it if the original dial target contained no scheme or contained an\n\t// unregistered scheme. Any query params specified in the original dial\n\t// target can be accessed from here.\n\tURL url.URL\n&#125;\n\n// Builder creates a resolver that will be used to watch name resolution updates.\n// 自定义一个 resolver 必须实现这个接口\ntype Builder interface &#123;\n\t// Build creates a new resolver for the given target.\n\t//\n\t// gRPC dial calls Build synchronously, and fails if the returned error is\n\t// not nil.\n\tBuild(target Target, cc ClientConn, opts BuildOptions) (Resolver, error)\n\t// Scheme returns the scheme supported by this resolver.\n\t// Scheme is defined at https://github.com/grpc/grpc/blob/master/doc/naming.md.\n    // 指定构建的是那种 Scheme 类型的解析器，就是客户端调用的 scheme 名字\n\tScheme() string\n&#125;\n\n// ResolveNowOptions includes additional information for ResolveNow.\n// execute ResolveNow 的 一些附属信息\ntype ResolveNowOptions struct&#123;&#125;\n\n// Resolver watches for the updates on the specified target.\n// Updates include address updates and service config updates.\n// 要实现自定义的解析器,必须实现 Resolver 接口(解析器监听target 上的更新, 更新内容包括 已resolved的 地址列表 和 服务配置)\ntype Resolver interface &#123;\n\t// ResolveNow will be called by gRPC to try to resolve the target name\n\t// again. It's just a hint, resolver can ignore this if it's not necessary.\n\t//\n\t// It could be called multiple times concurrently.\n\tResolveNow(ResolveNowOptions)  // 通过channel的方式 唤醒select ，立即解析\n\t// Close closes the resolver.\n\tClose()\n&#125;\n\n// UnregisterForTesting removes the resolver builder with the given scheme from the\n// resolver map.\n// This function is for testing only.\nfunc UnregisterForTesting(scheme string) &#123;\n\tdelete(m, scheme)\n&#125;\n\n\n","slug":"grpc-DNSResolver","date":"2022-06-21T02:58:26.000Z","categories_index":"","tags_index":"DNSResolver,grpc","author_index":"majm"},{"id":"2c7dd58c559020b938dd674699ae2dad","title":"docker-compose etcd","content":"codedocker-compose.yml\n\n\nversion: &#39;3&#39;\n\nnetworks:\n  etcd-net:\n    driver: bridge # 网桥模式\n\nvolumes:\n  etcd1_data:       # 挂在到 本地数据卷 名\n    driver: local\n  etcd2_data:\n    driver: local\n  etcd3_data:\n    driver: local\n\nservices:\n  etcd1:\n    image: docker.io&#x2F;bitnami&#x2F;etcd:3\n    container_name: etcd1\n    restart: always\n    networks:\n      - etcd-net\n    ports:\n      - &quot;20000:2379&quot;\n      - &quot;20001:2380&quot;\n    environment:\n      - ALLOW_NONE_AUTHENTICATION&#x3D;yes\n      - ETCD_NAME&#x3D;etcd1\n      - ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;http:&#x2F;&#x2F;etcd1:2380\n      - ETCD_LISTEN_PEER_URLS&#x3D;http:&#x2F;&#x2F;0.0.0.0:2380\n      - ETCD_LISTEN_CLIENT_URLS&#x3D;http:&#x2F;&#x2F;0.0.0.0:2379\n      - ETCD_ADVERTISE_CLIENT_URLS&#x3D;http:&#x2F;&#x2F;etcd1:2379\n      - ETCD_INITIAL_CLUSTER_TOKEN&#x3D;etcd-cluster\n      - ETCD_INITIAL_CLUSTER&#x3D;etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380,etcd3&#x3D;http:&#x2F;&#x2F;etcd3:2380\n      - ETCD_INITIAL_CLUSTER_STATE&#x3D;new\n    volumes:\n      - etcd1_data:&#x2F;bitnami&#x2F;etcd\n  etcd2:\n    image: docker.io&#x2F;bitnami&#x2F;etcd:3\n    container_name: etcd2\n    restart: always\n    networks:\n      - etcd-net\n    ports:\n      - &quot;20002:2379&quot;\n      - &quot;20003:2380&quot;\n    environment:\n      - ALLOW_NONE_AUTHENTICATION&#x3D;yes\n      - ETCD_NAME&#x3D;etcd2\n      - ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;http:&#x2F;&#x2F;etcd2:2380\n      - ETCD_LISTEN_PEER_URLS&#x3D;http:&#x2F;&#x2F;0.0.0.0:2380\n      - ETCD_LISTEN_CLIENT_URLS&#x3D;http:&#x2F;&#x2F;0.0.0.0:2379\n      - ETCD_ADVERTISE_CLIENT_URLS&#x3D;http:&#x2F;&#x2F;etcd2:2379\n      - ETCD_INITIAL_CLUSTER_TOKEN&#x3D;etcd-cluster\n      - ETCD_INITIAL_CLUSTER&#x3D;etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380,etcd3&#x3D;http:&#x2F;&#x2F;etcd3:2380\n      - ETCD_INITIAL_CLUSTER_STATE&#x3D;new\n    volumes:\n      - etcd2_data:&#x2F;bitnami&#x2F;etcd\n  etcd3:\n    image: docker.io&#x2F;bitnami&#x2F;etcd:3\n    container_name: etcd3\n    restart: always\n    networks:\n      - etcd-net\n    ports:\n      - &quot;20004:2379&quot;\n      - &quot;20005:2380&quot;\n    environment:\n      - ALLOW_NONE_AUTHENTICATION&#x3D;yes\n      - ETCD_NAME&#x3D;etcd3\n      - ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;http:&#x2F;&#x2F;etcd3:2380\n      - ETCD_LISTEN_PEER_URLS&#x3D;http:&#x2F;&#x2F;0.0.0.0:2380\n      - ETCD_LISTEN_CLIENT_URLS&#x3D;http:&#x2F;&#x2F;0.0.0.0:2379\n      - ETCD_ADVERTISE_CLIENT_URLS&#x3D;http:&#x2F;&#x2F;etcd3:2379\n      - ETCD_INITIAL_CLUSTER_TOKEN&#x3D;etcd-cluster\n      - ETCD_INITIAL_CLUSTER&#x3D;etcd1&#x3D;http:&#x2F;&#x2F;etcd1:2380,etcd2&#x3D;http:&#x2F;&#x2F;etcd2:2380,etcd3&#x3D;http:&#x2F;&#x2F;etcd3:2380\n      - ETCD_INITIAL_CLUSTER_STATE&#x3D;new\n    volumes:\n      - etcd3_data:&#x2F;bitnami&#x2F;etcd\n\n\n运行docker-compose up -d\n\n查看运行状态docker ps\n\ndocket inspect etcd1\n\n\n\n\n\n\n[参考]bitnami-docker-etcddocker-compose 部署etcd集群\n","slug":"docker-compose-etcd","date":"2022-06-20T08:53:05.000Z","categories_index":"","tags_index":"docker,docker-compose,etcd","author_index":"majm"},{"id":"bcbdd392335684c9104bdd4f64660df8","title":"golang ChecksumMismath Problem Resolve","content":"","slug":"golang-ChecksumMismath-Problem-Resolve","date":"2022-03-04T10:31:53.000Z","categories_index":"","tags_index":"","author_index":"majm"},{"id":"ffad35a1622d678553fcb007d75f9511","title":"hexo中插入图片","content":"在 hexo 中使用 图片, 有如下几种方式:\n1. 在 资源目录下 创建图片\nhexo 配置文件 _config.yml\n\npost_asset_folder: true  # 创建新文章时，会生成相同名字的文件夹，也就是文章资源文件夹\n\n当执行命令 hexo new &quot;title&quot; 会创建一个 与文章名相同的目录, 这个目录也称为 文章资源文件.在资源文件下创建 一张图片 image.png,在文章中 按理说 ![image](image.png)这样引用就可以了,但是 现在好像不能用了. 需要引入其他的插件\nnpm install hexo-renderer-marked\n\n安装后,在 _config.yml 文件写入如下配置:\npost_asset_folder: true  # 创建新文章时，会生成相同名字的文件夹，也就是文章资源文件夹\nmarked:\n  prependRoot: true\n  postAsset: true\n\n之后就可以在使用![](image.png)的方式愉快的插入图片了.\n2. 使用图床3. picGo +  github + JsDeliver  构建免费图床","slug":"hexo中插入图片","date":"2022-03-03T15:52:29.000Z","categories_index":"hexo","tags_index":"blog,image","author_index":"majm"},{"id":"33a93209a96a0749f2f19c4e853409bf","title":"升级hexo-cli的版本","content":"最近升级 node版本后,执行  hexo d 就会报错:\nNFO  Copying files from public folder...\nFATAL &#123;\n  err: TypeError [ERR_INVALID_ARG_TYPE]: The &quot;mode&quot; argument must be integer. Received an instance of Object\n\n之后查看其他文档 和 官方文档, 说明要升级  hexo-cli 的版本\n\n操作步骤&#x2F;&#x2F;以下指令均在Hexo目录下操作，先定位到Hexo目录\n&#x2F;&#x2F;查看当前版本，判断是否需要升级\nhexo version\n\n&#x2F;&#x2F;全局升级hexo-cli\nnpm i hexo-cli -g\n\n&#x2F;&#x2F;再次查看版本，看hexo-cli是否升级成功,第一次未更新成功\nhexo version\n\n&#x2F;&#x2F;安装npm-check，若已安装可以跳过\nnpm install -g npm-check\n\n&#x2F;&#x2F;检查系统插件是否需要升级\nnpm-check\n\n&#x2F;&#x2F;安装npm-upgrade，若已安装可以跳过\nnpm install -g npm-upgrade\n\n&#x2F;&#x2F;更新package.json   -- 这里会提示 更新 hexo版本\nnpm-upgrade\n\n&#x2F;&#x2F;更新全局插件\nnpm update -g\n\n&#x2F;&#x2F;更新系统插件\n&gt; npm update --save\n\n&#x2F;&#x2F;再次查看版本，判断是否升级成功\n&gt; hexo version\n\n\n\n\n\n\n\n\n参考Hexo版本升级指南官方文档\n","slug":"升级hexo-cli的版本","date":"2022-03-03T15:26:10.000Z","categories_index":"hexo","tags_index":"blog,hexo","author_index":"majm"},{"id":"0ad4121ef489a5f287d594c8cbbc513d","title":"简单计算器实现-逆波兰表达式","content":"简单计算器的实现-逆波兰表达式\n\n\n\n\n\n\n\n\n一般也就是分为两步\n\n将中缀表达式 解析为  后缀(前缀)表达式\neval 计算后缀表达式解析 出 结果\n\n\n\n\n\n中缀表达式\n\n一般的算数表达式, 操作符以中缀形式出现在操作数之间\n\n前缀表达式\n\n前缀表达式是一种没有括号的算术表达式,与中缀表达式不同的是，其将运算符写在前面，操作数写在后面.为纪念其发明者波兰数学家Jan Lukasiewicz，前缀表达式也称为波兰式.\n\n后缀表达式\n\n后缀表达式指的是不包含括号,运算符放在两个运算对象的后面,所有的计算按运算符出现的顺序,严格从左向右进行(不再考虑运算符的优先规则). 也称为 逆波兰表达式\n中缀表达式: 1-(2+3)前缀表达式: 1 2 3 + -后缀表达式: - 1 + 2 3\n中缀表达式 转 前缀表达式((a+(b*c))+(((d*e)+f)*g)\n\n前缀表达式\n++a*bc*+*efg\n\n同样是使用栈的方式解析, 前缀表达式的解析 和 后缀表达式的解析 方式相反, 从右向左\n\n解析 中缀表达式\n\n从右至左解析中缀表达式\n\n遇到数字 直接输出\n遇到操作符\n\n2.1  ‘)’直接入栈2.2  ‘(‘ 将符号栈中元素移除并输出, 直到遇到右括号)只移除,不输出2.3 运算符: 将符号栈中的元素移除出栈并输出, 直到遇到比当前符号优先级更高的符号或者).          将当前符号入栈3. 扫描完后, 将栈中剩余符号依次输出\nfor example下面以a+b*c+(d*e+f)*g为例子来看看转换过程:面在描述栈的情况是直接用文字描述了,由左到右为栈底到栈顶.空表示栈空\n1. 从后向左遍历表达式: g\n\n输出:  g \n符号栈:\n\n2. 从后向左遍历表达式: *\n\n输出:  g \n符号栈: *\n\n3. 从后向左遍历表达式: )\n\n输出:  g \n符号栈: )*\n\n4. 从后向左遍历表达式: f\n\n输出:  fg \n符号栈: )*\n\n5. 从后向左遍历表达式: +\n\n输出:  fg \n符号栈: +)*\n\n6. 从后向左遍历表达式: e\n\n输出:  efg \n符号栈: +)*\n\n7. 从后向左遍历表达式: *\n\n输出:  efg \n符号栈: *+)*\n\n8. 从后向左遍历表达式: d\n\n输出:  defg \n符号栈: *+)*\n\n9. 从后向左遍历表达式: (\n\n输出:  +*defg \n符号栈: *\n\n10. 从后向左遍历表达式: +\n\n输出:  *+*defg \n符号栈: +\n\n11. 从后向左遍历表达式: c\n\n输出:  c*+*defg \n符号栈: +\n\n12. 从后向左遍历表达式: *\n\n输出:  c*+*defg \n符号栈: *+\n\n\n13. 从后向左遍历表达式: b\n\n输出:  bc*+*defg \n符号栈: *+\n\n14. 从后向左遍历表达式: +\n\n输出:  *bc*+*defg \n符号栈: ++\n\n15. 从后向左遍历表达式: a\n\n输出:  a*bc*+*defg \n符号栈: ++\n\n16. 将符号栈中剩余的 符号压入 结果集\n\n输出:  ++a*bc*+*defg \n符号栈: \n\n\n\n解析 前缀表达式\n\n\n/**\n * 基本计算器3 &lt;/br>\n *\n * @author majunmin\n * @description\n * @datetime 2021-09-25 19:47\n * @since\n */\npublic class LeetCode_0772 implements Solution &#123;\n\n\n    @Override\n    public int calculate(String s) &#123;\n        List&lt;String> pe = parsePE(s);\n        int res = evalPE(pe);\n        return res;\n    &#125;\n\n    private List&lt;String> parsePE(String s) &#123;\n        List&lt;String> list = new LinkedList&lt;>();\n        Deque&lt;String> opStack = new LinkedList&lt;>();\n        final char[] chars = s.toCharArray();\n        int num = -1;\n        for (int i = chars.length - 1; i >= 0; i--) &#123;\n            char c = chars[i];\n            if (c == ' ') &#123;\n                continue;\n            &#125;\n            if (c >= '0' &amp;&amp; c &lt;= '9') &#123;\n                if (num == -1) &#123;\n                    num = c - '0';\n                &#125; else &#123;\n                    num = num + (c - '0') * 10;\n                &#125;\n            &#125; else &#123;\n                if (num != -1) &#123;\n                    list.add(0, String.valueOf(num));\n                    num = -1;\n                &#125;\n                if (c == ')') &#123;\n                    opStack.push(\")\");\n                &#125; else if (c == '(') &#123;\n                    while (!Objects.equals(opStack.peek(), \")\")) &#123;\n                        list.add(0, opStack.pop());\n                    &#125;\n                    opStack.pop();\n                &#125; else &#123;\n                    // 运算符\n                    String op = String.valueOf(c);\n                    while (!opStack.isEmpty()) &#123;\n                        if (Objects.equals(opStack.peek(), \")\")) &#123;\n                            break;\n                        &#125;\n                        if (getPriority(op) >= getPriority(opStack.peek())) &#123;\n                            break;\n                        &#125;\n                        list.add(0, opStack.pop());\n                    &#125;\n                    opStack.push(op);\n                &#125;\n            &#125;\n        &#125;\n        if (num != -1) &#123;\n            list.add(0, String.valueOf(num));\n        &#125;\n        while (!opStack.isEmpty()) &#123;\n            list.add(0, opStack.pop());\n        &#125;\n\n        return list;\n    &#125;\n\n    /**\n     * 解析 波兰表达式\n     * ++a*bc**+*efg\n     *\n     * @param pe\n     * @return\n     */\n    private int evalPE(List&lt;String> pe) &#123;\n        Deque&lt;String> stack = new LinkedList&lt;>();\n        // 从右向左遍历\n        for (int i = pe.size() - 1; i >= 0; i--) &#123;\n            String curStr = pe.get(i);\n            if (curStr.charAt(0) >= '0' &amp;&amp; curStr.charAt(0) &lt;= '9') &#123;\n                stack.push(curStr);\n            &#125; else &#123;\n                int num = 0;\n                int num1 = parseInt(stack.pop());\n                int num2 = parseInt(stack.pop());\n                switch (curStr) &#123;\n                    case \"+\":\n                        num = num1 + num2;\n                        break;\n                    case \"-\":\n                        num = num1 - num2;\n                        break;\n                    case \"*\":\n                        num = num1 * num2;\n                        break;\n                    case \"/\":\n                        num = num1 / num2;\n                        break;\n                    default:\n                        throw new IllegalArgumentException(\"Unexcept error.\");\n                &#125;\n                stack.push(String.valueOf(num));\n            &#125;\n        &#125;\n        return parseInt(stack.pop());\n    &#125;\n\n    /**\n     * 将中最表达式转化为  逆波兰表达式\n     * 1. 遇到数字直接 放入 list\n     * 2. 遇到 符号\n     * 2.1  `(` 直接放入\n     * 2.2  `)` 将栈中 所有的字符 pop 放入到结果集\n     * 2.3  `符号`\n     * 2.3.1 符号优先级 &lt;= 栈顶元素优先级,直接放入\n     * 2.3.2 符号优先级 > 栈顶元素优先级,将栈中元素pop 并放入结果集, 直到遇到 `(` 或者 栈 为空\n     *\n     * @param s\n     * @return\n     */\n    private List&lt;String> parseRPE(String s) &#123;\n        List&lt;String> rpe = new ArrayList&lt;>();\n        Deque&lt;String> stack = new LinkedList&lt;>();\n        int num = -1;\n        for (char c : s.toCharArray()) &#123;\n            if (c == ' ') &#123;\n                continue;\n            &#125;\n            // 是一个数字\n            if (c >= '0' &amp;&amp; c &lt;= '9') &#123;\n                if (num == -1) &#123;\n                    num = c - '0';\n                &#125; else &#123;\n                    num = num * 10 + (c - '0');\n                &#125;\n            &#125; else &#123;\n                //判断数字\n                if (num != -1) &#123;\n                    rpe.add(String.valueOf(num));\n                    num = -1;\n                &#125;\n\n                if (c == '(') &#123;\n                    stack.push(String.valueOf(c));\n                &#125; else if (c == ')') &#123;\n                    while (!stack.isEmpty()) &#123;\n                        if (!\"(\".equals(stack.peek())) &#123;\n                            rpe.add(stack.pop());\n                        &#125; else &#123;\n                            stack.pop();\n                            break;\n                        &#125;\n                    &#125;\n                &#125; else &#123;\n                    // + - * /\n                    while (!stack.isEmpty()) &#123;\n                        if (\"(\".equals(stack.peek())) &#123;\n                            break;\n                        &#125;\n                        if (getPriority(String.valueOf(c)) > getPriority(stack.peek())) &#123;\n                            break;\n                        &#125;\n                        rpe.add(stack.pop());\n                    &#125;\n                    stack.push(String.valueOf(c));\n                &#125;\n            &#125;\n        &#125;\n        if (num != -1) &#123;\n            rpe.add(String.valueOf(num));\n        &#125;\n        while (!stack.isEmpty()) &#123;\n            rpe.add(stack.pop());\n        &#125;\n        return rpe;\n    &#125;\n\n    private int getPriority(String op) &#123;\n        switch (op) &#123;\n            case \"+\":\n            case \"-\":\n                return 1;\n            case \"*\":\n            case \"/\":\n                return 2;\n            default:\n                throw new IllegalArgumentException(\"Unexpected value: \" + op);\n        &#125;\n    &#125;\n&#125;\n\n\n\n\n\n\n\n中缀表达式 转 后缀表达式((a+(b*c))+(((d*e)+f)*g)\n\n后缀表达式\nabc*+de*f+g*+\n\n\n\n使用栈的方式解析,解析步骤:\n从左到右扫描中缀表达式, \n\n遇到数字直接输出\n遇到运算符\n\n2.1 ‘(‘ 直接入栈2.2 ‘)’ 将符号栈中的元素移除出栈并输出, 直到 (, ( 只出栈,不输出2.3 +-*/: 将符号栈中的元素移除出栈并输出, 直到遇到比当前符号优先级更低的符号或者’(‘.          将当前符号入栈3. 扫描完后, 将栈中剩余符号依次输出\nfor example:下面以a+b*c+(d*e+f)*g为例子来讲讲计算机的转换过程下.面在描述栈的情况是直接用文字描述了,由左到右为栈底到栈顶.空表示栈空\n\n1. 由左向右遍历表达式,首先遇到a,直接将其输出.\n\n此时输出为：a\n栈的情况为：空\n\n2. 继续遍历,遇到+,将其放入栈中.\n\n此时输出为：a\n栈的情况为：+\n\n3. 继续遍历,遇到b,直接将其输出.\n\n此时输出为：ab\n栈的情况为：+\n\n4. 继续遍历，遇到*，因为*的优先级大于栈顶的+，所以将*放入栈内。\n\n此时输出为：ab\n栈的情况为：+*\n\n5. 继续遍历,遇到c,直接将其输出.\n\n此时输出为：abc\n栈的情况为：+*\n\n6. 继续遍历,遇到+,因为+的优先级低于栈顶的*, 故将*弹出; 然后新的栈顶元素的+与这个+优先级相同, 故也要弹出现在栈顶的+;然后栈空了,将现在这个+放入栈中\n\n此时输出为：abc*+\n栈的情况为：+\n\n7. 继续遍历,遇到(,直接将其放入栈中,不遇到)不会将(弹出\n\n此时输出为：abc*+\n栈的情况为：+(\n\n8. 继续遍历,遇到d,直接将其输出.\n\n此时输出为：abc*+d\n栈的情况为：+(\n\n9. 继续遍历,遇到*,因为栈顶为(,不遇到)不将(弹出,故直接将*放入栈中\n\n此时输出为：abc*+d\n栈的情况为：+(*\n\n10. 继续遍历，遇到e，直接将其输出。\n\n此时输出为：abc*+de\n栈的情况为：+(*\n\n11. 继续遍历，遇到+，因为+比栈顶*的优先级低，故将*弹出；新的栈顶元素为(,不遇到)不弹出(,故将+放入栈中。\n\n此时输出为：abc*+de*\n栈的情况为：+(+\n\n12. 继续遍历，遇到f，直接将其输出。\n\n此时输出为：abc*+de*f\n\n栈的情况为：+(+\n\n13. 继续遍历，遇到),直接将栈中元素依次弹出并输出直到遇到(为止,  注意：(弹出但不输出\n\n此时输出为：abc*+de*f+\n栈的情况为：+\n\n14. 继续遍历，遇到*，因为*的优先级大于栈顶元素+的优先级，故直接将*入栈。\n\n此时输出为：abc*+de*f+\n栈的情况为：+*\n\n15. 继续遍历，遇到g，直接将其输出。\n\n此时输出为：abc*+de*f+g\n栈的情况为：+*\n\n16. 继续遍历，为空，遍历结束。将栈内元素依次弹出。\n\n此时输出为：abc*+de*f+g*+\n栈的情况为：空\n\n至此，中缀表达式转后缀已经全部完成,结果为abc*+de*f+g*+\n解析 会解析后缀表达就很简单了\nleetCode 772：\n/**\n * 基本计算器3 &lt;/br>\n *\n * @author majunmin\n * @description\n * @datetime 2021-09-25 19:47\n * @since\n */\npublic class LeetCode_0772 implements Solution &#123;\n\n\n    @Override\n    public int calculate(String s) &#123;\n        List&lt;String> rpe = getRPE(s);\n        int result = eval(rpe);\n        return result;\n    &#125;\n\n\n    /**\n     * rpe 表达式仅包含 &#123;@text 数字 +-/*&#125;\n     *\n     * @param rpe\n     * @return\n     */\n    private int eval(List&lt;String> rpe) &#123;\n\n        Deque&lt;String> stack = new LinkedList&lt;>();\n\n        for (String item : rpe) &#123;\n            if (item.charAt(0) >= '0' &amp;&amp; item.charAt(0) &lt;= '9') &#123;\n                stack.push(item);\n            &#125; else &#123;\n                int num1 = parseInt(stack.pop());\n                int num2 = parseInt(stack.pop());\n                int result;\n                if (!validOperator(item)) &#123;\n                    throw new IllegalArgumentException(\"\");\n                &#125;\n                switch (item) &#123;\n                    case \"+\":\n                        result = num2 + num1;\n                        break;\n                    case \"-\":\n                        result = num2 - num1;\n                        break;\n                    case \"*\":\n                        result = num2 * num1;\n                        break;\n                    default:\n                        result = num2 / num1;\n                        break;\n                &#125;\n                stack.push(String.valueOf(result));\n            &#125;\n        &#125;\n        return Integer.parseInt(stack.pop());\n    &#125;\n\n    private boolean validOperator(String operator) &#123;\n        return \"+\".equals(operator) || \"-\".equals(operator)\n                || \"*\".equals(operator) || \"/\".equals(operator);\n    &#125;\n\n    private int parseInt(String item) &#123;\n        return Integer.parseInt(item);\n    &#125;\n\n\n    /**\n     * 将中最表达式转化为  逆波兰表达式\n     * 1. 遇到数字直接 放入 list\n     * 2. 遇到 符号\n     * 2.1  `(` 直接放入\n     * 2.2  `)` 将栈中 所有的字符 pop 放入到结果集\n     * 2.3  `符号`\n     * 2.3.1 符号优先级 &lt;= 栈顶元素优先级,直接放入\n     * 2.3.2 符号优先级 > 栈顶元素优先级,将栈中元素pop 并放入结果集, 直到遇到 `(` 或者 栈 为空\n     *\n     * @param s\n     * @return\n     */\n    private List&lt;String> getRPE(String s) &#123;\n        List&lt;String> rpe = new ArrayList&lt;>();\n        Deque&lt;String> stack = new LinkedList&lt;>();\n        int num = -1;\n        for (char c : s.toCharArray()) &#123;\n            if (c == ' ') &#123;\n                continue;\n            &#125;\n            // 是一个数字\n            if (c >= '0' &amp;&amp; c &lt;= '9') &#123;\n                if (num == -1) &#123;\n                    num = c - '0';\n                &#125; else &#123;\n                    num = num * 10 + (c - '0');\n                &#125;\n            &#125; else &#123;\n                //判断数字\n                if (num != -1) &#123;\n                    rpe.add(String.valueOf(num));\n                    num = -1;\n                &#125;\n\n                if (c == '(') &#123;\n                    stack.push(String.valueOf(c));\n                &#125; else if (c == ')') &#123;\n                    while (!stack.isEmpty()) &#123;\n                        if (!\"(\".equals(stack.peek())) &#123;\n                            rpe.add(stack.pop());\n                        &#125; else &#123;\n                            stack.pop();\n                            break;\n                        &#125;\n                    &#125;\n                &#125; else &#123;\n                    // + - * /\n                    while (!stack.isEmpty()) &#123;\n                        if (\"(\".equals(stack.peek())) &#123;\n                            break;\n                        &#125;\n                        if (getPriority(String.valueOf(c)) > getPriority(stack.peek())) &#123;\n                            break;\n                        &#125;\n                        rpe.add(stack.pop());\n                    &#125;\n                    stack.push(String.valueOf(c));\n                &#125;\n            &#125;\n        &#125;\n        if (num != -1) &#123;\n            rpe.add(String.valueOf(num));\n        &#125;\n        while (!stack.isEmpty()) &#123;\n            rpe.add(stack.pop());\n        &#125;\n        return rpe;\n    &#125;\n\n    private int getPriority(String op) &#123;\n        switch (op) &#123;\n            case \"+\":\n            case \"-\":\n                return 1;\n            case \"*\":\n            case \"/\":\n                return 2;\n            default:\n                throw new IllegalArgumentException(\"Unexpected value: \" + op);\n        &#125;\n    &#125;\n\n    public static void main(String[] args) &#123;\n        Solution leetCode = new LeetCode_0772();\n        System.out.println(leetCode.calculate(\"6 - 4/2\"));\n        System.out.println(leetCode.calculate(\"(2 + 6*3 +5 - (3*14/7+2) *5)+3\"));\n    &#125;\n\n&#125;\n\n\n\n\n代码实现\n\n数据结构——中缀转后缀表达式彻底用图解教会你——中缀表达式转后缀和前缀\n","slug":"简单计算器实现-逆波兰表达式","date":"2021-09-25T17:16:01.000Z","categories_index":"Algorithm","tags_index":"算法,Algorithm,逆波兰表达式","author_index":"majm"},{"id":"53e5f1b621546948c5c24222a62321d5","title":"Maven dependency Scope","content":"官网-scope描述\n\n\nMaven 的作用域分为6种\n\n\n\n\n\n\n\n\noptional(可选的)\n\ncompile\n\n  默认的scope，表示 dependency 都可以在整个生命周期(编译 运行 测试)中使用. 而且这些dependencies  可以传递依赖\n\nprovided\n\n跟compile相似，但是表明了dependency 由JDK或者容器提供，例如Servlet API和一些Java EE APIs。这个scope 只能作用在编译和测试时，同时没有传递性。使用这个时，不会将包打入本项目中，只是依赖过来.使用默认或其他时，会将依赖的项目打成jar包，放入本项目的Lib里\n\n\n\n\n\n\n\n\n\nservlet-api，因为servlet-api，tomcat等web服务器已经存在了，如果再打包会冲突\n\nruntime\n\n表示dependency不作用在编译时，但会作用在运行和测试时\n\ntest\n\n表示dependency作用在测试时，不作用在运行时。\n\nsystem (不推荐)\n\n跟provided 相似，但是在系统中要以外部JAR包的形式提供，maven不会在repository查找它,与 systemPath 配合使用\n&lt;project>\n...\n&lt;dependencies>\n　　&lt;dependency>\n　　　&lt;groupId>javax.sql&lt;/groupId>\n　　　&lt;artifactId>jdbc-stdext&lt;/artifactId>\n　　　&lt;version>2.0&lt;/version>\n　　　&lt;scope>system&lt;/scope>\n　　　&lt;systemPath>$&#123;java.home&#125;/lib/rt.jar&lt;/systemPath>\n　　&lt;/dependency>\n&lt;/dependencies>\n...\n&lt;/project>\n\n\nimport (Maven 2.0.9 之后新增)\n\n它只使用在中，表示从其它的pom中导入dependency的配置，\n&lt;project>\n  &lt;modelVersion>4.0.0&lt;/modelVersion>\n  &lt;groupId>maven&lt;/groupId>\n  &lt;artifactId>Z&lt;/artifactId>\n  &lt;packaging>pom&lt;/packaging>\n  &lt;name>Z&lt;/name>\n  &lt;version>1.0&lt;/version>\n \n  &lt;dependencyManagement>\n    &lt;dependencies>\n      &lt;dependency>\n        &lt;groupId>maven&lt;/groupId>\n        &lt;artifactId>X&lt;/artifactId>\n        &lt;version>1.0&lt;/version>\n        &lt;type>pom&lt;/type>\n        &lt;scope>import&lt;/scope>\n      &lt;/dependency>\n      &lt;dependency>\n        &lt;groupId>maven&lt;/groupId>\n        &lt;artifactId>Y&lt;/artifactId>\n        &lt;version>1.0&lt;/version>\n        &lt;type>pom&lt;/type>\n        &lt;scope>import&lt;/scope>\n      &lt;/dependency>\n    &lt;/dependencies>\n  &lt;/dependencyManagement>\n&lt;/project>","slug":"Maven-dependency-Scope","date":"2020-09-14T07:21:10.000Z","categories_index":"maven","tags_index":"maven","author_index":"majm"},{"id":"b042f3febe72fcf77aed1d68cd1e61be","title":"JVM-jstat命令解析","content":"\n\n\n\n\n\n\n\n\nJDK8jstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下: \n\n\njstat [-命令选项] [vmid] [间隔时间&#x2F;毫秒] [查询次数]\n\n类加载统计jstat -class [pid]\n\nLoaded  Bytes  Unloaded  Bytes     Time\n 10701 20086.0        0     0.0       5.62\n\nLoaded: 加载class的数量\nBytes: 所占用空间大小\nUnloaded: 未加载数量\nBytes: 未加载占用空间\nTime: 时间\n\n编译统计jstat -compiler [pid]\n\nCompiled Failed Invalid   Time   FailedType FailedMethod\n    5642      6       0     1.51          1 com&#x2F;sun&#x2F;beans&#x2F;TypeResolver prepare\n\nCompiled: 编译数量。\nFailed: 失败数量\nInvalid: 不可用数量\nTime: 时间\nFailedType: 失败类型\nFailedMethod: 失败的方法\nCompiled: 编译数量。\nFailed: 失败数量\nInvalid: 不可用数量\nTime: 时间\nFailedType: 失败类型\nFailedMethod: 失败的方法\n\n垃圾回收统计jstat -gc [pid]\n\n S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT\n157248.0 157248.0  0.0   42754.5 1258368.0 1110221.2 2621440.0     0.0     38528.0 36701.5 5248.0 4838.0      1    0.041   0      0.000    0.041\n\nS0C: 第一个幸存区的大小\nS1C: 第二个幸存区的大小\nS0U: 第一个幸存区的使用大小\nS1U: 第二个幸存区的使用大小\nEC: Eden 的大小\nEU: Eden 的使用大小\nOC: 老年代大小\nOU: 老年代使用大小\nMC: 方法区大小\nMU: 方法区使用大小\nCCSC:压缩类空间大小\nCCSU:压缩类空间使用大小\nYGC: 年轻代垃圾回收次数\nYGCT: 年轻代垃圾回收消耗时间\nFGC: 老年代垃圾回收次数\nFGCT: 老年代垃圾回收消耗时间\nGCT: 垃圾回收消耗总时间\n\n堆内存统计jstat -gccapacity [pid]\n\n NGCMN    NGCMX     NGC     S0C   S1C       EC      OGCMN      OGCMX       OGC         OC       MCMN     MCMX      MC     CCSMN    CCSMX     CCSC    YGC    FGC\n1572864.0 1572864.0 1572864.0 157248.0 157248.0 1258368.0  2621440.0  2621440.0  2621440.0  2621440.0      0.0 1083392.0  38528.0      0.0 1048576.0   5248.0      1     0\n\n\nNGCMN: 新生代最小容量\nNGCMX: 新生代最大容量\nNGC: 当前新生代容量\nS0C: 第一个幸存区大小\nS1C: 第二个幸存区的大小\nEC: Eden区的大小\nOGCMN: 老年代最小容量\nOGCMX: 老年代最大容量\nOGC: 当前老年代大小\nOC:当前老年代大小\nMCMN:最小元数据容量\nMCMX: 最大元数据容量\nMC: 当前元数据空间大小\nCCSMN: 最小压缩类空间大小\nCCSMX: 最大压缩类空间大小\nCCSC: 当前压缩类空间大小\nYGC: 年轻代gc次数\nFGC: 老年代GC次数\n\n新生代垃圾回收统计jstat -gcnew [pid]\n\n S0C    S1C    S0U    S1U   TT MTT  DSS      EC       EU     YGC     YGCT\n157248.0 157248.0    0.0 42754.5  6   6 78624.0 1258368.0 1143777.8      1    0.041\n\n新生代内存统计jstat -gcnewcapacity [pid]\n\n  NGCMN      NGCMX       NGC      S0CMX     S0C     S1CMX     S1C       ECMX        EC      YGC   FGC\n 1572864.0  1572864.0  1572864.0 157248.0 157248.0 157248.0 157248.0  1258368.0  1258368.0     1     0\n\n老年代垃圾回收统计jstat -gcold [pid]\n\n   MC       MU      CCSC     CCSU       OC          OU       YGC    FGC    FGCT     GCT\n 38528.0  36701.5   5248.0   4838.0   2621440.0         0.0      1     0    0.000    0.041\n\n老年代内存统计jstat -gcoldcapacity [pid]\n\n   OGCMN       OGCMX        OGC         OC       YGC   FGC    FGCT     GCT\n  2621440.0   2621440.0   2621440.0   2621440.0     1     0    0.000    0.041\n\n元数据空间统计jstat -gcmetacapacity [pid]\n\n   MCMN       MCMX        MC       CCSMN      CCSMX       CCSC     YGC   FGC    FGCT     GCT\n       0.0  1083392.0    38528.0        0.0  1048576.0     5248.0     1     0    0.000    0.041\n\n\nMCMN: 最小元数据容量\nMCMX: 最大元数据容量\nMC: 当前元数据空间大小\nCCSMN: 最小压缩类空间大小\nCCSMX: 最大压缩类空间大小\nCCSC: 当前压缩类空间大小\nYGC: 年轻代垃圾回收次数\nFGC: 老年代垃圾回收次数\nFGCT: 老年代垃圾回收消耗时间\nGCT: 垃圾回收消耗总时间\n\n垃圾回收统计jstat -gcutil [pid]\n\n  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT\n  0.00  27.19  90.89   0.00  95.26  92.19      1    0.041     0    0.000    0.041\n\n\nS0: 幸存1区当前使用比例\nS1: 幸存2区当前使用比例\nE: Eden 区使用比例\nO: 老年代使用比例\nM: 元数据区使用比例\nCCS: 压缩使用比例\nYGC: 年轻代垃圾回收次数\nFGC: 老年代垃圾回收次数\nFGCT: 老年代垃圾回收消耗时间\nGCT: 垃圾回收消耗总时间\n\nJVM编译方法统计jstat -printcompilation [pid]\n\nCompiled  Size  Type Method\n    5773     18    1 com&#x2F;alibaba&#x2F;fastjson&#x2F;serializer&#x2F;SerializeWriter isEnabled\n\n\nCompiled: 最近编译方法的数量\nSize: 最近编译方法的字节码数量\nType: 最近编译方法的编译类型\nMethod: 方法名标识\n\n","slug":"JVM-jstat命令解析","date":"2019-10-16T03:23:24.000Z","categories_index":"jvm","tags_index":"jvm,jstat","author_index":"majm"},{"id":"3191f51398b532ce218b33ad1c80d29d","title":"linux下监控实时网速","content":"\n\n\n\n\n\n\n\n\nNetHogs是一个小型的’net top’工具,不像大多数工具那样拖慢每个协议或者是每个子网的速度而是按照进程进行带宽分组.NetHogs NetHogs不需要依赖载入某个特殊的内核模块. 如果发生了网络阻塞你可以启动NetHogs立即看到哪个PID造成的这种状况.这样就很容易找出哪个程序跑飞了然后突然占用你的带宽.\n\n\n命令  nethogs安装# centOS\nsudo yum install nethogs\n\n# ubtntu\nsudo apt-get install nethogs\n\n使用nethogs\n\nnethogs -d 5\n\nnethogs eth0 eth1\n\n# -d: delay for refresh rate.\n# -h: display available commands usage.\n# -p: sniff in promiscious mode (not recommended).\n# -t: trace mode.\n# -V: prints Version info. \n\n\n","slug":"linux下监控实时网速","date":"2019-08-13T09:48:52.000Z","categories_index":"linux","tags_index":"linux","author_index":"majm"},{"id":"b6fcd1b6df52f1cbb0ed1f5a0d130f42","title":"记录一次kafka消费慢解决","content":"\n\n\n\n\n\n\n\n\n最近使用kafka, 消费者速度一直跟不上，造成线上消息堆积到了 101亿，困扰了好几天，终于解决了。（其实很简单，因为 kafka消费速度本来也不慢 😂😂😂😂,其实异步+ 批量消费就满可以达到要求了）\n\n\n主要原因有两个，\n\n对 @Async 注解的不理解\n批量消费\n– 还有就是通过这次事件，也了解了点 自动提交与 手动提交的概念\n\n一般 kafka 消费慢的 解决思路有一下几种：\n\n增加分区数\n批量消费(增加拉取批次， 默认 500)\n每次拉取后，本地启线程池异步消费 (注意 kafkaConsumer 是 非线程安全的)\n如果消费多个topic的话，修改分区策略为 StickyAssignor.class(默认 RangeAssignor.class)\n\n这里使用， spring-kafka 注解形式\nkafka 配置\n@Bean\npublic KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;String, String>> listenerContainerFactory() &#123;\n    ConcurrentKafkaListenerContainerFactory&lt;String, String> factory = new ConcurrentKafkaListenerContainerFactory&lt;>();\n    factory.setConsumerFactory(consumerFactory());\n    // 飘零消费 需要设置 为 true\n    factory.setBatchListener(true);\n    // 单机消费者数量\n    factory.setConcurrency(8);\n    // 拉取超时时间\n    factory.getContainerProperties().setPollTimeout(2000);\n    return factory;\n&#125;\n\npublic ConsumerFactory&lt;String, String> consumerFactory() &#123;\n    return new DefaultKafkaConsumerFactory&lt;>(consumerConfigs());\n&#125;\n\npublic Map&lt;String, Object> consumerConfigs() &#123;\n    Map&lt;String, Object> propsMap = new HashMap&lt;>();\n    propsMap.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:2181\");\n    propsMap.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);\n    propsMap.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000);\n    // 最大拉取消息条数， 默认 500 ,可以调大此参数， 此参数过大， 也可能会出现 OOM\n    propsMap.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);\n    propsMap.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 5000);\n    propsMap.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n    propsMap.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n    propsMap.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, true);\n    return propsMap;\n&#125;\n\n消费\n@Slf4j\n@Component\npublic class Consumer &#123;\n\n    @Resource\n    private KafkaConsumeService kafkaConsumerService;\n\n\n    @KafkaListener(topics = &#123;\"$&#123;topic&#125;\", \"$&#123;topic2&#125;\"&#125;, groupId = \"$&#123;group.id&#125;\", containerFactory = \"listenerContainerFactory\")\n    public void consume(List&lt;ConsumerRecord&lt;String, String>> records) &#123;\n        kafkaConsumerService.consume(records);\n    &#125;\n&#125;\n\n@Service\npublic class ConsumeServiceImpl implements KafkaConsumeService &#123;\n\n    @Resource\n    private ADMapper AdMapper;\n\n    /**\n     * 批量消费\n     * @param records\n     */\n    @Async(\"executor\")\n    @Override\n    public void consume(List&lt;ConsumerRecord&lt;String, String>> records) &#123;\n        records.forEach(this::consume);\n    &#125;\n\n    /**\n     * 单条消费\n     * @param record\n     */\n    public void consume(ConsumerRecord&lt;String, String> record) &#123;\n        String key = record.key();\n        String value = record.value();\n        log.info(\"ConsumeServiceImpl.consume, key=&#123;&#125;, value=&#123;&#125;\", key, value);\n\n        try &#123;\n            saveInDb(value);\n        &#125; catch (Exception ex) &#123;\n            log.error(\"ConsumeServiceImpl.consume error, \", ex);\n            return;\n        &#125;\n    &#125;\n\n\n@Async  的使用\n@Configuration\n@EnableAsync\npublic class ExecutorConfig &#123;\n\n    /**\n     * Set the ThreadPoolExecutor's core pool size.\n     */\n    @Value(\"$&#123;executor.corepoolsize:8&#125;\")\n    private int corePoolSize;\n    /**\n     * Set the ThreadPoolExecutor's maximum pool size.\n     */\n    @Value(\"$&#123;executor.maxpoolsize:10&#125;\")\n    private int maxPoolSize;\n    /**\n     * Set the capacity for the ThreadPoolExecutor's BlockingQueue.\n     */\n    @Value(\"$&#123;executor.queueCapacity:500&#125;\")\n    private int queueCapacity;\n\n\n    @Bean(\"executor\")\n    public Executor insertExecutor() &#123;\n        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();\n        executor.setCorePoolSize(corePoolSize);\n        executor.setMaxPoolSize(maxPoolSize);\n        executor.setQueueCapacity(queueCapacity);\n        executor.setThreadNamePrefix(\"executor-\");\n        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());\n        executor.initialize();\n        return executor;\n    &#125;\n&#125;\n\n\n@Async 使用注意\n\n\n\n\n\n\n\n\n@Async 标注的方法，称之为异步方法；这些方法将在执行的时候，将会在独立的线程中被执行，调用者无需等待它的完成，即可继续其他的操作\n\n@EnableAsync  @EnableAsync 不能放在启动类上\n被注解的方法 需要返回值 为 void, 或者Future, 否则 @Async 无效\n@Async 注解的方法 和 其调用方法 不能放在同一个类里， 否则 @Async 注解无效\n\n生产环境上 参数可以微调\n\n每次最大拉取的条数，\n线程池数， 以及队列数目\nJVM 堆大小调整\n\n总结其实 kafka 的 消费速率很快，一般就是 一个 for 循环不停地拉取消息，然后交给线程池异步处理，一般不会产生消息堆积。消息消费情况 可 堆积情况 一般都可以看一下监控， 我这次最多堆积了 10 亿条， (原因就是对 @Async 不了解，将@Async 和其调动方法卸载了同一个类里  😢😢)\n","slug":"记录一次kafka消费慢解决","date":"2019-08-03T10:37:02.000Z","categories_index":"kafka,consumer","tags_index":"kafka","author_index":"majm"},{"id":"37aab8e3df469d14892fd29b0404f0e2","title":"redis-info命令详解","content":"\n\n\n\n\n\n\n\n\nredis info 命令详解\n\n192.168.5.244(192.168.5.244:7001)&gt;info all\n&quot;# Server\nredis_version:3.0.6\nredis_git_sha1:00000000\nredis_git_dirty:0\nredis_build_id:8e54e6b49fa2c985\nredis_mode:cluster                             #运行模式，单机或者集群\nos:Linux 3.10.0-327.el7.x86_64 x86_64\narch_bits:64\nmultiplexing_api:epoll                        #redis所使用的事件处理机制\ngcc_version:4.8.5\nprocess_id:1187                                #redis服务器进程的pid\nrun_id:3198b2ad766fe1eb467a4d27fd90b3c481f2c253  # redis服务器的随机标识符(用于sentinel和集群)\ntcp_port:7001                                #redis服务器监听端口\nuptime_in_seconds:784389                     #redis服务器启动总时间，单位是秒\nuptime_in_days:9                             #redis服务器启动总时间，单位是天\nhz:10                                        #redis内部调度（进行关闭timeout的客户端，删除过期key等等）频率，程序规定serverCron每秒运行10次。\nlru_clock:3236399                            #自增的时钟，用于LRU管理,该时钟100ms(hz&#x3D;10,因此每1000ms&#x2F;10&#x3D;100ms执行一次定时任务)更新一次\nconfig_file:&#x2F;etc&#x2F;redis&#x2F;7001&#x2F;redis.conf       #配置文件路径\n\n# Clients(已连接客户端信息)\nconnected_clients:276            # 已连接客户端的数量(不包括通过slave连接的客户端)\nclient_longest_output_list:0     # 当前连接的客户端当中，最长的输出列表，用client list命令观察omem字段最大值\nclient_biggest_input_buf:0       # 当前连接的客户端当中，最大输入缓存，用client list命令观察qbuf和qbuf-free两个字段最大值\nblocked_clients:0                # 正在等待阻塞命令(BLPOP、BRPOP、BRPOPLPUSH)的客户端的数量\n\n# Memory  (内存信息)\nused_memory:25388768             # 由redis分配器分配的内存总量，以字节为单位\nused_memory_human:24.21M         # 以人类可读的格式返回redis分配的内存总量\nused_memory_rss:32223232         # 从操作系统的角度，返回redis已分配的内存总量(俗称常驻集大小)。这个值和top命令的输出一致\nused_memory_peak:27566960        # redis的内存消耗峰值(以字节为单位) \nused_memory_peak_human:26.29M    # 以人类可读的格式返回redis的内存消耗峰值\nused_memory_lua:41984            # lua引擎所使用的内存大小(以字节为单位)\nmem_fragmentation_ratio:1.27     # used_memory_rss和used_memory之间的比率，小于1表示使用了swap，大于1表示碎片比较多\nmem_allocator:jemalloc-3.6.0     # 在编译时指定的redis所使用的内存分配器。可以是libc、jemalloc或者tcmalloc\n\n# Persistence    (rdb和aof的持久化相关信息)\nloading:0                         #服务器是否正在载入持久化文件\nrdb_changes_since_last_save:0     #离最近一次成功生成rdb文件，写入命令的个数，即有多少个写入命令没有持久化\nrdb_bgsave_in_progress:0          #服务器是否正在创建rdb文件\nrdb_last_save_time:1563456371    #离最近一次成功创建rdb文件的时间戳。当前时间戳 - rdb_last_save_time&#x3D;多少秒未成功生成rdb文件\nrdb_last_bgsave_status:ok          # 最近一次rdb持久化是否成功\nrdb_last_bgsave_time_sec:0        # 最近一次成功生成rdb文件耗时秒数\nrdb_current_bgsave_time_sec:-1   # 如果服务器正在创建rdb文件，那么这个域记录的就是当前的创建操作已经耗费的秒数\naof_enabled:1                    # 是否开启了aof\naof_rewrite_in_progress:0        # 标识aof的rewrite操作是否在进行中\naof_rewrite_scheduled:0          # rewrite任务计划，当客户端发送bgrewriteaof指令，如果当前rewrite子进程正在执行，那么将客户端请求的bgrewriteaof变为计划任务，待aof子进程结束后执行rewrite \naof_last_rewrite_time_sec:0      # 最近一次aof rewrite耗费的时长\naof_current_rewrite_time_sec:-1  # 如果rewrite操作正在进行，则记录所使用的时间，单位秒\naof_last_bgrewrite_status:ok      # 上次bgrewriteaof操作的状态\naof_last_write_status:ok         # 上次aof写入状态\naof_current_size:6006946          # aof当前尺寸\naof_base_size:5198177            # 服务器启动时或者aof重写最近一次执行之后aof文件的大小\naof_pending_rewrite:0             # 是否有aof重写操作在等待rdb文件创建完毕之后执行?\naof_buffer_length:0               # aof buffer的大小\naof_rewrite_buffer_length:0       # aof rewrite buffer的大小\naof_pending_bio_fsync:0           # 后台I&#x2F;O队列里面，等待执行的fsync调用数量\naof_delayed_fsync:0               # 被延迟的fsync调用数量\n\n# Stats        (一般统计信息)\ntotal_connections_received:111954    #新创建连接个数,如果新创建连接过多，过度地创建和销毁连接对性能有影响，说明短连接严重或连接池使用有问题，需调研代码的连接设置 \ntotal_commands_processed:410452      #redis处理的命令数\ninstantaneous_ops_per_sec:0          #redis当前的qps，redis内部较实时的每秒执行的命令数\ntotal_net_input_bytes:10401399       #redis网络入口流量字节数\ntotal_net_output_bytes:2027252713    #redis网络出口流量字节数\ninstantaneous_input_kbps:0.01        #redis网络入口kps\ninstantaneous_output_kbps:0.02       #redis网络出口kps\nrejected_connections:0               #拒绝的连接个数，redis连接个数达到maxclients限制，拒绝新连接的个数\nsync_full:0                          #主从完全同步成功次数 \nsync_partial_ok:0                    #主从部分同步成功次数\nsync_partial_err:0                   #主从部分同步失败次数\nexpired_keys:0                       #运行以来过期的key的数量\nevicted_keys:0                       #运行以来剔除(超过了maxmemory后)的key的数量\nkeyspace_hits:9682                   #命中次数\nkeyspace_misses:258                  #没命中次数\npubsub_channels:0                    #当前使用中的频道数量\npubsub_patterns:0                    #当前使用的模式的数量\nlatest_fork_usec:1253                #最近一次fork操作阻塞redis进程的耗时数，单位微秒\nmigrate_cached_sockets:0\n\n# Replication  (主从信息，slave上显示的信息)\nrole:slave                    #实例的角色，是master or slave\nmaster_host:192.168.5.244     #此节点对应的master的ip\nmaster_port:7004               #此节点对应的master的port\nmaster_link_status:up          #slave端可查看它与master之间同步状态,当复制断开后表示down\nmaster_last_io_seconds_ago:1    #主库多少秒未发送数据到从库?\nmaster_sync_in_progress:0      #从服务器是否在与主服务器进行同步\nslave_repl_offset:1875290      #slave复制偏移量\nslave_priority:100             #slave优先级\nslave_read_only:1              #从库是否设置只读\nconnected_slaves:0             #连接的slave实例个数\nmaster_repl_offset:0\nrepl_backlog_active:0          #复制积压缓冲区是否开启\nrepl_backlog_size:1048576        #复制积压缓冲大小\t\nrepl_backlog_first_byte_offset:0  #复制缓冲区里偏移量的大小\nrepl_backlog_histlen:0          #此值等于 master_repl_offset - repl_backlog_first_byte_offset,该值不会超过repl_backlog_size的大小\n\n# CPU   (CPU计算量统计信息)\t\nused_cpu_sys:314.93      # 将所有redis主进程在核心态所占用的CPU时求和累计起来\nused_cpu_user:211.47     # 将所有redis主进程在用户态所占用的CPU时求和累计起来\nused_cpu_sys_children:2.30     # 将后台进程在核心态所占用的CPU时求和累计起来\nused_cpu_user_children:15.05   # 将后台进程在用户态所占用的CPU时求和累计起来\n \n# Commandstats         (各种不同类型的命令的执行统计信息)\t\ncmdstat_get:calls&#x3D;497,usec&#x3D;2135,usec_per_call&#x3D;4.30\ncmdstat_set:calls&#x3D;52,usec&#x3D;442,usec_per_call&#x3D;8.50\ncmdstat_setnx:calls&#x3D;7,usec&#x3D;106,usec_per_call&#x3D;15.14\ncmdstat_setex:calls&#x3D;329,usec&#x3D;4964,usec_per_call&#x3D;15.09\ncmdstat_del:calls&#x3D;268,usec&#x3D;11297,usec_per_call&#x3D;42.15\ncmdstat_exists:calls&#x3D;7,usec&#x3D;22,usec_per_call&#x3D;3.14\ncmdstat_incr:calls&#x3D;50,usec&#x3D;205,usec_per_call&#x3D;4.10\ncmdstat_mget:calls&#x3D;8,usec&#x3D;28,usec_per_call&#x3D;3.50\ncmdstat_rpush:calls&#x3D;1,usec&#x3D;21,usec_per_call&#x3D;21.00\ncmdstat_lpush:calls&#x3D;15,usec&#x3D;239,usec_per_call&#x3D;15.93\ncmdstat_rpop:calls&#x3D;19,usec&#x3D;171,usec_per_call&#x3D;9.00\ncmdstat_lrange:calls&#x3D;2,usec&#x3D;7,usec_per_call&#x3D;3.50\ncmdstat_sadd:calls&#x3D;5,usec&#x3D;74,usec_per_call&#x3D;14.80\ncmdstat_zadd:calls&#x3D;24,usec&#x3D;377,usec_per_call&#x3D;15.71\ncmdstat_zrem:calls&#x3D;2,usec&#x3D;14,usec_per_call&#x3D;7.00\ncmdstat_hset:calls&#x3D;29,usec&#x3D;229,usec_per_call&#x3D;7.90\ncmdstat_hget:calls&#x3D;2,usec&#x3D;9,usec_per_call&#x3D;4.50\ncmdstat_hmset:calls&#x3D;7,usec&#x3D;15574,usec_per_call&#x3D;2224.86\ncmdstat_hincrby:calls&#x3D;21,usec&#x3D;220,usec_per_call&#x3D;10.48\ncmdstat_hdel:calls&#x3D;4,usec&#x3D;36,usec_per_call&#x3D;9.00\ncmdstat_incrby:calls&#x3D;772,usec&#x3D;2896,usec_per_call&#x3D;3.75\ncmdstat_randomkey:calls&#x3D;55,usec&#x3D;259,usec_per_call&#x3D;4.71\ncmdstat_select:calls&#x3D;1,usec&#x3D;1,usec_per_call&#x3D;1.00\ncmdstat_expire:calls&#x3D;92,usec&#x3D;354,usec_per_call&#x3D;3.85\ncmdstat_pexpire:calls&#x3D;784,usec&#x3D;1849,usec_per_call&#x3D;2.36\ncmdstat_keys:calls&#x3D;6,usec&#x3D;4763,usec_per_call&#x3D;793.83\ncmdstat_scan:calls&#x3D;3,usec&#x3D;25493,usec_per_call&#x3D;8497.67\ncmdstat_ping:calls&#x3D;378267,usec&#x3D;475783,usec_per_call&#x3D;1.26\ncmdstat_info:calls&#x3D;20,usec&#x3D;51449,usec_per_call&#x3D;2572.45\ncmdstat_ttl:calls&#x3D;771,usec&#x3D;2555,usec_per_call&#x3D;3.31\ncmdstat_cluster:calls&#x3D;9521,usec&#x3D;4896338,usec_per_call&#x3D;514.27\ncmdstat_readonly:calls&#x3D;114,usec&#x3D;219,usec_per_call&#x3D;1.92\ncmdstat_client:calls&#x3D;18455,usec&#x3D;5187940,usec_per_call&#x3D;281.11\ncmdstat_slowlog:calls&#x3D;13,usec&#x3D;233,usec_per_call&#x3D;17.92\ncmdstat_command:calls&#x3D;229,usec&#x3D;178198,usec_per_call&#x3D;778.16\n\n# Cluster   (集群相关信息)\ncluster_enabled:1                  #实例是否启用集群模式\n\n# Keyspace      (数据库相关的统计信息)\ndb0:keys&#x3D;5968,expires&#x3D;4822,avg_ttl&#x3D;2089395628   #db0的key的数量,以及带有生存期的key的数,平均存活时间\n&quot;","slug":"redis-info命令详解","date":"2019-07-22T09:44:36.000Z","categories_index":"redis","tags_index":"redis","author_index":"majm"},{"id":"409a977ec1b75954f9585ba9c4856d49","title":"Docker概念","content":"\n\n\n\n\n\n\n\n\n了解一下Docker 概念，如今容器技术在互联网行业发展的已经相当成熟，springBoot 微服务 结合 k8s 部署线上服务，安全 高效，充分利用机器资源\n\n\n✨镜像镜像是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。\n镜像使用分层存储\n✨容器容器是镜像的运行时实例 - 实际执行时镜像会在内存中变成什么。默认情况下，它完全独立于主机环境运行，仅在配置为访问主机文件和端口的情况下才执行此操作。\n容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全，占用的内存不超过任何其他可执行文件。\n镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。\n容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。\n容器可以被创建、启动、停止、删除、暂停等\n\n服务在分布式应用中，应用的不同部分称为“服务”。例如，假设有一个视频共享网站，它可能提供用于在数据库中存储应用程序数据的服务、用于在用户上传一些内容后在后台进行视频转码的服务、用于前端的服务等。\n服务实际上是“生产中的容器”。一项服务仅运行一个镜像，但它会编制镜像的运行方式 - 它应使用的端口、容器的多少个从节点应运行才能使服务的容量满足其需求等。扩展服务将更改运行该软件的容器实例数，并将多个计算资源分配给进程中的服务。\nSwarmswarm 是一组运行 Docker 并且已加入集群中的机器.执行此操作后,可以继续运行已使用的 Docker 命令,但现在它们在集群上由 swarm 管理节点执行。swarm 中的机器可以为物理或虚拟机。加入 swarm 后，可以将它们称为节点。\n✨镜像仓库  Repository镜像仓库是一组 Docker 镜像。可以通过将镜像仓库推送到镜像库服务器来对其进行共享。\n通常,一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。\n✨镜像库 Docker Registy一个镜像仓库中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。\n镜像库是一项包含镜像仓库的托管服务\nDocker Hub\n分层存储因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。\n镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。\n分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。\n链接: 概念\n","slug":"Docker概念","date":"2019-07-20T07:30:19.000Z","categories_index":"docker","tags_index":"docker","author_index":"majm"},{"id":"596309cd0250881615133cb44c237a29","title":"Linux常用命令","content":"\n\n\n\n\n\n\n\n\n记录一下 CentO7 中常用的命令\n\n\n命令：\nrpm -q package-name     #检查包是否被安装\nrpm -qa                 #列出所有安装的包\n\n\nshell 脚本参数 传参数$$$\n\n\n\n变量\n含义\n\n\n\n$0\n当前脚本的文件名\n\n\n$n\n传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。\n\n\n$#\n传递给脚本或函数的参数个数。\n\n\n$*\n传递给脚本或函数的所有参数。\n\n\n$@\n传递给脚本或函数的所有参数。被双引号(“ “)包含时，与 $* 稍有不同，下面将会讲到。\n\n\n$?\n上个命令的退出状态，或函数的返回值。\n\n\n$$\n当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。\n\n\nLinux corn定时任务\n\n\n\n代表意义\n分钟\n小时\n日期\n月份\n周\n命令\n\n\n\n数字范围\n0~59\n0~23\n1~31\n1~12\n0~7\n需要执行的命令\n\n\n# For details see man 4 crontabs\n\n# Example of job definition:\n# .---------------- minute (0 - 59)\n# | .------------- hour (0 - 23)\n# | | .---------- day of month (1 - 31)\n# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...\n# | | | | .---- day of week (0 - 6) (Sunday&#x3D;0 or 7) OR sun,mon,tue,wed,thu,fri,sat\n# | | | | |\n# * * * * * user-name command to be executed\n\n\nsedsed命令是一个面向字符流的非交互式编辑器，也就是说sed不允许用户与它进行交互操作。sed是按行来处理文本内容的。在shell中，使用sed来批量修改文本内容是非常方便的。\nsed\n选项与参数：\n-n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。\n-e ：直接在命令列模式上进行 sed 的动作编辑；\n-f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作；\n-r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法)\n-i ：直接修改读取的文件内容，而不是输出到终端。\n\nfunction：\na ：新增行， a 的后面可以是字串，而这些字串会在新的一行出现(目前的下一行)\nc ：取代行， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行\nd ：删除行，因为是删除，所以 d 后面通常不接任何参数，直接删除地址表示的行；\ni ：插入行， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；\np ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行\ns ：替换，可以直接进行替换的工作,通常这个 s 的动作可以搭配正规表示法，例如 1,20s&#x2F;old&#x2F;new&#x2F;g 一般是替换符合条件的字符串而不是整行\n\n一般function的前面会有一个地址的限制，例如 [地址]function，表示我们的动作要操作的行。下面我们通过具体的例子直观的看看sed的使用方法。\n\n&gt;&gt; 与 &gt;&gt; : 会重写文件，如果文件里面有内容会覆盖。\n&gt;   是定向输出到文件，如果文件不存在，就创建文件；如果文件存在，就将其清空。\n   一般我们备份清理日志文件的时候，就是这种方法：先备份日志，再用&#96;&gt;&#96;，将日志文件清空（文件大小变成0字节）。\n&gt;&gt; :追加文件，也就是如果文件里面有内容会把新内容追加到文件尾。\n    这个是将输出内容追加到目标文件中。如果文件不存在，就创建文件。\n\nshell 字符串“” 与 ‘’单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。\n双引号里可以有变量双引号里可以出现转义字符\nhome&#x3D;tj\necho &quot;hello, $&#123;home&#125;&quot;\necho &#39;hello, $&#123;home&#125;&#39;\n\n命令 grep\n作用​    Linux系统中grep命令是一种强大的文本搜索工具，\n它能使用正则表达式搜索文本，并把匹 配的行打印出来。\ngrep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。\n\n主要参数 -a或–text   不要忽略二进制的数据。  -A&lt;显示列数&gt;或–after-context&#x3D;&lt;显示列数&gt;   除了显示符合范本样式的那一列之外，并显示该列之后的内容。  -b或–byte-offset   在显示符合范本样式的那一列之前，标示出该列第一个字符的位编号。  -B&lt;显示列数&gt;或–before-context&#x3D;&lt;显示列数&gt;   除了显示符合范本样式的那一列之外，并显示该列之前的内容。  -c或–count   计算符合范本样式的列数。  -C&lt;显示列数&gt;或–context&#x3D;&lt;显示列数&gt;或-&lt;显示列数&gt;   除了显示符合范本样式的那一列之外，并显示该列之前后的内容。  -d&lt;进行动作&gt;或–directories&#x3D;&lt;进行动作&gt;   当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。  -e&lt;范本样式&gt;或–regexp&#x3D;&lt;范本样式&gt;   指定字符串做为查找文件内容的范本样式。  -E或–extended-regexp   将范本样式为延伸的普通表示法来使用。  -f&lt;范本文件&gt;或–file&#x3D;&lt;范本文件&gt;   指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。  -F或–fixed-regexp   将范本样式视为固定字符串的列表。  -G或–basic-regexp   将范本样式视为普通的表示法来使用。  -h或–no-filename   在显示符合范本样式的那一列之前，不标示该列所属的文件名称。  -H或–with-filename   在显示符合范本样式的那一列之前，表示该列所属的文件名称。  -i或–ignore-case   忽略字符大小写的差别。  -l或–file-with-matches   列出文件内容符合指定的范本样式的文件名称。  -L或–files-without-match   列出文件内容不符合指定的范本样式的文件名称。  -n或–line-number   在显示符合范本样式的那一列之前，标示出该列的列数编号。  -q或–quiet或–silent   不显示任何信息。  -r或–recursive   此参数的效果和指定“-d recurse”参数相同。  -s或–no-messages   不显示错误信息。  -v或–revert-match   反转查找。  -V或–version   显示版本信息。  -w或–word-regexp   只显示全字符合的列。如 “grep -w magic” 匹配 magic 不匹配magical  -x或–line-regexp   只显示全列符合的列。  -y   此参数的效果和指定“-i”参数相同。\n举例： 查找 &#x2F;etc&#x2F;profile文件 去掉 空行，去掉注释行(以#开头)grep -v ‘^$’ &#x2F;etc&#x2F;profile |grep -v ‘^#’\nawk\nawk是行处理器: 相比较屏幕处理的优点，在处理庞大文件时不会出现内存溢出或是处理缓慢的问题，通常用来格式化文本信息\nawk处理过程: 依次对每一行进行处理，然后输出\nawk:（将一行分为多个字段做处理）（重点）\nawk [-F  field-separator]  &#39;commands&#39;  input-file(s)\n\n其中，commands 是真正awk命令，*[-F域分隔符]*是可选的。default : 空格 * input-file(s) *是待处理的文件。在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。\nlast -n 5 | awk  &#39;&#123;print $1&#125;&#39; # 去除最后5行  打印第一个字段(域)\n\n$0           表示整个当前行\n$1           每行第一个字段\nNF          字段数量变量\nNR          每行的记录号，多文件记录递增\nFNR        与NR类似，不过多文件记录不递增，每个文件都从1开始\n\\t            制表符\n\\n           换行符\nFS          BEGIN时定义分隔符\nRS       输入的记录分隔符， 默认为换行符(即文本是按一行一行输入)\n~            匹配，与&#x3D;&#x3D;相比不是精确比较\n!~           不匹配，不精确比较\n&#x3D;&#x3D;         等于，必须全部相等，精确比较\n!&#x3D;           不等于，精确比较\n&amp;&amp;　     逻辑与\n||             逻辑或\n+            匹配时表示1个或1个以上\n&#x2F;[0-9][0-9]+&#x2F;   两个或两个以上数字\n&#x2F;[0-9][0-9]*&#x2F;    一个或一个以上数字\nFILENAME 文件名\nOFS      输出字段分隔符， 默认也是空格，可以改为制表符等\nORS        输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕\n-F&#39;[:#&#x2F;]&#39;   定义三个分隔符\n\ncurl 命令#常见参数\n    -A&#x2F;--user-agent &lt;string&gt; 设置用户代理发送给服务器，即告诉服务器浏览器为什么\n    -basic 使用HTTP基本验证\n    --tcp-nodelay 使用TCP_NODELAY选项\n    -e&#x2F;--referer &lt;URL&gt; 来源网址，跳转过来的网址\n    --cacert &lt;file&gt; 指定CA证书 (SSL)\n    --compressed 要求返回是压缩的形势，如果文件本身为一个压缩文件，则可以下载至本地\n    -H&#x2F;--header &lt;line&gt;自定义头信息传递给服务器\n    -I&#x2F;--head 只显示响应报文首部信息\n    --limit-rate &lt;rate&gt; 设置传输速度\n    -u&#x2F;--user &lt;user[:password]&gt;设置服务器的用户和密码\n    -0&#x2F;--http1.0 使用HTTP 1.0\n    -o&#x2F;--output\t把输出写到该文件中(必须指定文件绝对路径)\n    -s&#x2F;--silent\t静默模式。不输出任何东西\n\n举例：\n#取URL返回状态码：\ncurl -s -m 10 -o &#x2F;dev&#x2F;null -w %&#123;http_code&#125; https:&#x2F;&#x2F;www.baidu.com\n\n#检查一批URL的HTTP状态：\ncat url.txt|while read line; do curl -I $line -m 5 --connect-timeout 5 -o &#x2F;dev&#x2F;null -s -w &quot;$line &quot;%&#123;http_code&#125;&quot;\\n&quot;; done&gt;ok.txt\n\n\nlinux中 &#x2F;dev&#x2F;null命令&#x2F;dev&#x2F;null ：代表空设备文件0 :表示键盘输入(stdin) \n\n\n\n\n\n\n\n\n\n：代表重定向到哪里，例如：echo “123” &gt; &#x2F;home&#x2F;123.txt1  ：表示标准输出（stdout），系统默认值是1，所以”&gt;&#x2F;dev&#x2F;null”等同于”1&gt;&#x2F;dev&#x2F;null”2  ：表示标准错误(stderr)&amp;  ：表示等同于的意思，2&gt;&amp;1，表示2的输出重定向等同于1\n#1、禁止标准输出\n\n[root@zhoucentos log]# cat filename\nwo ai wo jia\n[root@zhoucentos log]# cat filename &gt;&#x2F;dev&#x2F;null\n\n#2、禁止标准错误\n\n[root@zhoucentos log]# rm filename1 \nrm: 无法删除&quot;filename1&quot;: 没有那个文件或目录\n[root@zhoucentos log]# rm filename1 2&gt;&#x2F;dev&#x2F;null\n\n#3、禁止标准输出和标准错误\n\n[root@zhoucentos log]# rm filename1\nrm: 无法删除&quot;filename1&quot;: 没有那个文件或目录\n[root@zhoucentos log]# rm filename1 &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1\n\n#4、清除文件的内容\n\n[root@zhoucentos log]# cat filename\nwo ai wo jia\n[root@zhoucentos log]# cat &#x2F;dev&#x2F;null &gt; filename\n[root@zhoucentos log]# cat filename\n\ncommand &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp; &#x3D;&#x3D; command 1&gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;\n\n#1)command:表示shell命令或者为一个可执行程序\n#2)&gt;:表示重定向到哪里\n#3)&#x2F;dev&#x2F;null:表示Linux的空设备文件\n#4)2:表示标准错误输出\n#5)&amp;1:&amp;表示等同于的意思,2&gt;&amp;1,表示2的输出重定向等于于1\n#6)&amp;:表示后台执行,即这条指令执行在后台运行\n\n#1&gt;&#x2F;dev&#x2F;null:表示标准输出重定向到空设备文件,也就是不输出任何信息到终端,不显示任何信息。 \n#2&gt;&amp;1:表示标准错误输出重定向等同于标准输出,因为之前标准输出已经重定向到了空设备文件,所以标准错误输出也重定向到空设备文件。\n\n#这条命令的意思就是在后台执行这个程序,并将错误输出2重定向到标准输出1,然后将标准输出1全部放到&#x2F;dev&#x2F;null文件,也就是清空. \n#所以可以看出” &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 “常用来避免shell命令或者程序等运行中有内容输出。\n\nif 判断\n条件测试的表达式：\n\n    [ expression ]  # 括号两端必须要有空格\n    [[ expression ]] # 括号两端必须要有空格\n    test expression\n组合测试条件：\n\n-a  # : and\n-o  # : or\n!   # :  非\n\n\n整数比较：\n\n-eq # 测试两个整数是否相等\n-ne # 测试两个整数是否不等\n-gt # 测试一个数是否大于另一个数\n-lt # 测试一个数是否小于另一个数\n-ge # 大于或等于\n-le # 小于或等于\n# 命令间的逻辑关系\n\n&amp;&amp;  # 逻辑与：\n        # 第一个条件为假 第二个条件不用在判断，最总结果已经有\n        # 第一个条件为真，第二个条件必须得判断\n\n|| # 逻辑或\n\n\n字符串比较\n\n&#x3D;&#x3D; # 等于  两边要有空格\n!&#x3D; # 不等\n&gt;  # 大于\n&lt;  # 小于\n\n\n文件测试\n\n-z string 测试指定字符是否为空，空着真，非空为假\n-n string 测试指定字符串是否为不空，空为假 非空为真\n-e FILE 测试文件是否存在\n-f file 测试文件是否为普通文件\n-d file 测试指定路径是否为目录\n-r file 测试文件对当前用户是否可读\n-w file 测试文件对当前用户是否可写\n-x file 测试文件对当前用户是都可执行\n-z  是否为空  为空则为真\n-a  是否不空\n\niconv 命令iconv 命令是linux下用于文件转编码的常用命令，对于同时使用windows系统和linux系统的同学来说文件转编码也是经常遇到的操作。\n # 输入&#x2F;输出格式规范：\n  -f, --from-code&#x3D;名称     #原始文本编$$码\n  -t, --to-code&#x3D;名称         #输出编码\n\n# 信息：\n  -l, --list                 　　 #列举所有已知的字符集\n\n# 输出控制：\n  -c                         　　#从输出中忽略无效的字符\n  -o, --output&#x3D;FILE        #输出文件\n  -s, --silent                   #关闭警告\n      --verbose                #打印进度信息\n  -?, --help                    #给出该系统求助列表\n      --usage                   #给出简要的用法信息\n  -V, --version                #打印程序版本号\n\n\nSCP\n#  本地向服务器上传文件\nscp -r &#x2F;path&#x2F;to&#x2F;file username@host:&#x2F;path&#x2F;to.file\n\n# 从服务器下载文件\n\nscp -r username@host:&#x2F;path&#x2F;to.file &#x2F;path&#x2F;to&#x2F;file\n\n\n","slug":"Linux常用命令","date":"2019-07-20T07:03:53.000Z","categories_index":"linux","tags_index":"linux,centos7","author_index":"majm"},{"id":"536c69a65ba648fdf100fa15f3717346","title":"Kafka-Consumer","content":"kafka-consumer\n\n\n参数配置 以及默认值参数配置以及默认值\nConsumer 一些概念消费者 Consumerkafka 消费者，消费kafka队列里的消息，可以有多种语言实现， python  java  scala Go …,\nconsumer group  即是由多个独立消费者组成，消费 Topic 下的消息， 独立消费者 standalong consumer 执行独立的消费。\n消费者组 Consuemer groupKafka消费者是消费组的一部分，当多个消费者形成一个消费组来消费主题时，每个消费者会收到不同分区的消息。\n\nconsumer group 可能有若干个 consumer 实例\n对于同一个  group 而言， topic 的每一条消息只能被发送到该 group 下的一个 consumer 实例上\ntopic 消息可以发送到 订阅该 topic 的 多个 group\n\nkafkaConsuemr 是非线程安全的，与 kafkaProducer 是不同的。所以无法在多线程中使用同一个 kafkaConsuemr 进行消费。\n\n每个线程维护一个 kafkaonsumer  用户创建多线程消费kafka分区数据， 每个线程中创建一个单独的 kafkaConsumer 实例。\n\n\n\n\n\n\n\n\n\n\n为什么要使用 Consumer Group?consumer Group 是实现高伸缩性，高容错性的 consumer 机制，而且一旦某个 consumer 挂了，cosnuemr Group 会立即将已经崩溃的  consumer 负责的分区转交给 其他 consumer 负责，从而保证了整个 group 可以继续工作，不丢失数据，这个过程被称为–重平衡(reblance)\n\n\n\n\n\n\n\n\n\n消费顺序kafka 目前只保证单个分区内的消息消费顺序，而不会维护全局的消息顺序，如果用户要实现 topic 全局的消息顺序读取，就只能通过让每个 consumer group 下只包含一个 consumer 来实现。\n总结\n\nconsumer 下 可以有一或者多个 consumer , 一个 consuemr 可以是一个线程，也可以是运行在其他机器上的进程\ngroup.id 唯一标志一个 consumer group\n对于某个 consumer group 而言，订阅 topic 的每个分区只能分配给订阅该 consumer group 下的一个 consumer\n\noffset(位移)\n\n\n\n\n\n\n\n\n这里的 offset 指的是 consumer 端的位移，与分区日志中的 offset 是不同的含义\n每个 consumer实例都会为它消费的分区维护属于自己的位置信息来记录当前消费了多少消息。—- offset很多消息引擎都把消费端的  offset 保存在服务端(broker)， 这样做的好处当谈事实现简单，但可能会有如下三个问题：\n\nbroker 变成了有状态，增加了同步成本，影响伸缩性\n需要引入应答机制(acknowledgement)，来确认消息消费成功\n由于需要保存很多的 consumer 的 offset故必然会引入复杂的数据结构，从而造成不必要的资源浪费\n\nkafka consumer 端引入了 检查点机制(checkpoint), 定期对offset 持久化，从而简化了应答机制的实现\n位移提交 (offset commit)\n\n\n\n\n\n\n\n\nconsumer 客户端需要定期向 kafka 集群汇报自己的消费进度，这一过程称为 —– 位移提交.\n位移提交对于 consumer 而言非常重要,它不仅表征了 consumer 的消费进度，同时也直接决定了 consuemr 端消费语义的保证.\n新版本 consumer 把位移提交到 Kafka 内部的一个 topic(__consumer_offset) 上。因此consumer 不在依赖 Zookeeper(位移提交这件事). 这就是为什么开发新版本 consumer 不需要配置 zookeeper 地址的原因。\n__consumer_offset__consumer_offset 是 kafak 一个 内部 topic, \n消费者组重平衡 (Consumer group reblance)relbance 只对 consumer group 有效。\n\n\n\n\n\n\n\n\n\nrelbance规定了一个consumer group 下的 consuemr 如何达成一致来分配订阅 topic的所有分区。\n资料Kafka分区分配策略（1）——RangeAssignorKafka分区分配策略（2）——RoundRobinAssignor和StickyAssignor\n构建 kafka Consumer参考kafka消费者Consumer参数设置及参数调优建议-kafka 商业环境实战\n消息轮询poll()\nKafka Consumer是费线程安全的！如果没有显示的同步锁保护机制，kafka 会抛出 异常。(将同一个kafkaConsumer 实例用在了多个线程中)\nkafka 的 poll() 在用户主线程中执行，，这也同时表明 消费者组执行 relbance，消息获取， coordinator 管理 异步任务结果的处理 甚至 唯一提交等操作都是运行在用户主线程中。因此仔细调优这个 poll() 相关的\n\n\n\n\n\n\n\n\n\nkafka poll 为什么会有一个超时参数?poll()满足以下任一个条件，即可返回1：获取足够多的可用数据2：等待时间超过指定的超时时间。目的在于让Consumer主线程定期的””苏醒”去做其他事情。比如：定期的执行常规任务，（比如写日志，写库等）。\n位移管理\n\n\n\n\n\n\n\n\nkafka 要为每个他要读取的 分区保存消费进度，即分区当中的当前消费信息的位置 &#x3D;&#x3D;&gt; 位移 offsetconsumer定期向kafak 提交自己的位置信息。\noffset 对于 kafka consuemr非常重要，因为他是实现消息交语义的保证(message semantic)。常见的三种消息交付语义：\n\n最多一次 (at most once) 消息可能丢失,但不会重复消费\n最少一次 (at least once) 消息可能会重复消费，但不会丢失消息 (default)\n精确一次 (only once)    消息一定会被处理，且只会被处理一次\n\n自动提交 与 手动提交自动提交默认时间间隔 为 5s自动提交减少了开发成本，但不能细粒度的控制处理位移的提交，特别是精确一次处理语义时，在这种情况下，用户可以使用手动提交位移。通过设置 auto.commit.interval.ms 参数可以控制自动提交的时间间隔\n手动提交：参数配置： enable.auto.commit = false然后调用 commitSync() commitAsync()\n\n重平衡 rebalancerebalance 分区分配策略：\n\nrange 策略\nround-robin 策略\nsticky 策略\n\nKafka分区分配策略（1）——RangeAssignorKafka分区分配策略（2）——RoundRobinAssignor和StickyAssignor\nrebalanc 监听器新版本 consumer默认提交 offset 到 __consumer_offsets 中，其实，Kafka 也支持用户把位移提交到外部存储中,比如数据库。如要实现这个功能，用户就必须使用 rebalance 监听器. 使用 rebalance 监听器的前提是用户使用 consumer group. 如果使用得是独立的 consumer 或是直接手动分配分区，那么 rebalance 监听器是无效的\nrebalance 监听器有一个主要的接口回调类 ConsumerRebalanceListener, 里面有两个方法 onPartitionsRevoked() onPartitionAssigned().在开启新一轮的 rebalance 之前 会调用 onPartitionsRevoked()rebalance 完成后   会调用 onPartitionAssigned()\nrebalance 监听器常见的用法就是 手动提交位移到第三方存储以及在 rebalance 前后执行一些必要的神级操作\n解序列化 deserializer","slug":"Kafka-Consumer","date":"2019-07-17T12:22:08.000Z","categories_index":"kafka","tags_index":"kafka,consumer","author_index":"majm"},{"id":"4b07e4e83f2c420c552350b44033d1ab","title":"Kafka-Producer","content":"\n\n\n\n\n\n\n\n\nkafka 负责向消息队列 写入消息。\n\n\nkafka producer 要比 kafka consumer 简单一点，因为它不涉及复杂的组件管理，与其他的 producer 之间没有关联， 因此实现起来也比较简单。目前， kafka producer 的首要功能就是向某个 topic 中的某个分区发送一条消息。分区器(partitioner) 的作用就是决定消息要向 topic 的哪个的分区写入数据。\njava-kafka-producer工作流程\n配置项Producer 配置参数参数配置以及默认值\n常见配置参数\nbootstrap.servers配置连接代理列表，不必包含Kafka集群的所有代理地址，当连接上一个代理后，会从集群元数据信息中获取其他存活的代理信息。但为了保证能够成功连上Kafka集群，在多代理集群的情况下，建议至少配置两个代理。\n\nkey.serializer该参数就是为消息的key做序列化用的。这个参数指定的是实现了org.apache.kafka.common.serialization.Serializer接口的全限定名称。Kafka为大部分的初始类型（primitive type）默认提供了现成的序列化器。用户可以自定义序列化器，只要实现Serializer接口即可\n\n\n即使producer程序在发送消息时不指定key，这个参数也是必须要设置的，否则程序会抛出ConfigException异常，提示“key.serializer”参数无默认值，必须要配置\n\nvalue.serializer类似 key.serializer\n\n这两个参数都必须是全限定名，只使用单独的类名是不行的。\n\nclient_id客户端名称,用来追查日志的,默认是kafka-pythson-producer-# (#是个唯一编号)\n\nacks acks 指定了在给 producer 发送响应前，leader broker 必须要确保已成功写入该消息的副本数。当前 acks 有3个取值： 0 、1 和 all\n acks&#x3D;0: 设置成0表示producer完全不理睬leader broker端的处理结果。此时，producer发送消息后立即开启下一条消息的发送，根本不等待leader broker端返回结果。由于不接收发送结果，因此在这种情况下producer.send的回调也就完全失去了作用，即用户无法通过回调机制感知任何发送过程中的失败，所以acks&#x3D;0时producer并不保证消息会被发送成功。但凡是有利有弊，由于不需要等待响应结果，通常这种设置下producer的吞吐量是最高的。\n acks&#x3D;all或者-1: 表示当发送消息时，leader broker不仅会将消息写入本地日志，同时还会等待ISR中所有其他副本都成功写入它们各自的本地日志后，才发送响应结果给producer。显然当设置acks&#x3D;all时，只要ISR中至少有一个副本是处于“存活”状态的，那么这条消息就肯定不会丢失，因而可以达到很高的消息持久性，但通常这种设置下producer的吞吐量也是最低的。\n acks&#x3D;1: 是0和all折中的方案，也是默认的参数值。producer发送消息后leader broker仅将该消息写入本地日志，然后便发送响应结果给producer，而无须等待ISR中其他副本写入该消息。那么此时只要该leader broker一直存活，Kafka就能保证这条消息不丢失。这实际上是一种折中方案，既可以达到适当的消息持久性，同时也保证了producer端的吞吐量。\n\n\n\nacks\nproducer吞吐量\n消息持久性\n使用场景\n\n\n\n0\n最高\n最差\n1.完全不关心消息是否发送成功 2.允许消息丢失（比如统计服务器日志等）\n\n\n1\n适中\n适中\n一般场景即可\n\n\nall或-1\n最差\n最高\n不能容忍消息丢失\n\n\n\nbuffer.memory\n 该参数指定了producer端用于缓存消息的缓冲区大小，单位是字节，默认值是33554432，即32MB。由于采用了异步发送消息的设计架构，Java版本producer启动时会首先创建一块内存缓冲区用于保存待发送的消息，然后由另一个专属线程负责从缓冲区中读取消息执行真正的发送。这部分内存空间的大小即是由buffer.memory参数指定的。若producer向缓冲区写消息的速度超过了专属I&#x2F;O线程发送消息的速度，那么必然造成该缓冲区空间的不断增大。此时producer会停止手头的工作等待I&#x2F;O线程追上来，若一段时间之后I&#x2F;O线程还是无法追上producer的进度，那么producer就会抛出异常并期望用户介入进行处理。\n 虽说producer在工作过程中会用到很多部分的内存，但我们几乎可以认为该参数指定的内存大小就是producer程序使用的内存大小。若producer程序要给很多分区发送消息，那么就需要仔细地设置这个参数以防止过小的内存缓冲区降低了producer程序整体的吞吐量\n\nbatch.size batch.size是producer最重要的参数之一。 producer会将发往同一分区的多条消息封装进一个batch中。当batch满了的时候，producer会发送batch中的所有消息。 不过，producer并不总是等待batch满了才发送消息，很有可能当batch还有很多空闲空间时producer就发送该batch。 通常来说，一个小的batch中包含的消息数很少，因而一次发送请求能够写入的消息数也很少，所以producer的吞吐量会很低；但若一个batch非常之巨大，那么会给内存使用带来极大的压力，因为不管是否能够填满，producer都会为该batch分配固定大小的内存。因此batch.size参数的设置其实是一种时间与空间权衡的体现。\n\nretries\n 重试发送次数,有时候网络出现短暂的问题的时候,会自动重发消息,前面提到了这个值是需要在acks&#x3D;1或all时候才有效. 如果设置了该参数,但是s etting max_in_flight_requests_per_connection 没有设置为1的话,可能造成消息顺序的改变,因为如果2个 batches 发到同一个 partition, 但是第一个失败重发了,那么就会造成第二个 batches 跑到前面去了. 默认值 0\n\n重试可能造成消息的重复发送比如由于瞬时的网络抖动使得broker端已成功写入消息但没有成功发送响应给producer，因此producer会认为消息发送失败，从而开启重试机制。为了应对这一风险，Kafka要求用户在consumer端必须执行去重处理。另0.11.0.0版本开始支持“精确一次”处理语义。\n\n重试可能造成消息乱序当前 producer 会将多个消息发送请求（默认是5个）缓存再内存中，如果由于某种原因发生了消息发送重试，就可能造成消息流的乱序。为了避免乱序发生，Java版本 producer 提供了max.in.flight.request.per.connection 参数。一旦用户将此参数设置成1，producer将确保某一时刻只能发送一个请求。\n\n\n\ncompression.type compression.type参数设置producer端是否压缩消息，默认值是none，即不压缩消息。Kafka的producer端引入压缩后可以显著地降低网络I&#x2F;O传输开销从而提升整体的吞吐量，但也会增加producer端机器的CPU开销。另外，如果broker端的压缩参数设置的与producer不同，broker端在写入消息时也会额外使用CPU资源对消息进行对应的解压缩-重压缩操作。\n 根据实际使用经验来看， producer 结合 LZ4 的性能是最好的\n\ninger.mslinger.ms 参数就是控制消息发送延时行为的。该参数默认值是0，表示消息需要被立即发送，无须关心 batch 是否被填满，大多数情况下这是合理的，毕竟我们总是希望消息被尽可能快地发送。不过这样做会拉低 producer 吞吐量，毕竟 producer 发送的每次请求中包含的消息数越多，producer 就越能将发送请求的开销摊薄到更多的消息上，从而提升吞吐量。\n\nrequest.timeout.ms当producer发送请求给 broker 后，broker 需要在规定的时间范围内将处理结果返还给producer。这段时间便由该参数控制的，默认是30秒。这就是说，如果broker在30秒内都没有给 producer 发送响应，那么 producer就会认为该请求超时了，并在回调函数中显示地抛出 TimeoutException 异常交由用户处理。\n默认的30秒对于一般的情况而言是足够的，但如果 producer 发送的负载很大，超时的情况就很容易碰到，此时就应该适当调整该参数值。\n\nmax.request.size该参数用于控制 producer 发送请求的大小。实际上该参数控制的是 producer 端能够发送的最大消息的大小。由于请求有一些头部数据结构，因此包含一条消息的请求大小要比消息本身大。不过姑且把它当做请求的最大尺寸是安全的。如果 producer 要发送尺寸很大的消息，那么这个参数就是要被设置的。默认的1048576字节大小了，通常无法满足企业级消息的大小要求。\n\n\nProducer 分区机制kafka 提供了分区策略 以及对应的分区器(partiotioner) 供用户使用。随着 kafka 发布的默认的 partitioner 会尽力保证具有相同 key 的所有信息都会发送到相同的分区上。如果没有指定 key, 则 该 partitioner 会选择 轮询 的方式来确保消息在 topic 的所有分区上均匀分配。\n自定义分区机制java 版本 producer 自带的 partitioner 会根据 murmur2 算法计算消息 key 的 hash 值，然后对总分区数球模得到消息要被发送到的目标分区号。\n要完成 自定的分区策略， 需要完成 2 件事\n\n实现 org.apache.kafka.clients.producer.Partitioner 接口\n在 KafkaProducer 的 Properties 对象设置 partitioner.class 参数\n\npublic interface Partitioner extends Configurable, Closeable &#123;\n\n    /**\n     * 计算消息要被发送到那个分区\n     *\n     * @param topic The topic name\n     * @param key The key to partition on (or null if no key)\n     * @param keyBytes The serialized key to partition on( or null if no key)\n     * @param value The value to partition on or null\n     * @param valueBytes The serialized value to partition on or null\n     * @param cluster The current cluster metadata 集群元数据\n     */\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n\n    /**\n     * 关闭 partitioner\n     */\n    public void close();\n\n&#125;\n\n这两篇博客讲的挺好的Kafka分区分配策略（1）——RangeAssignorKafka分区分配策略（2）——RoundRobinAssignor和StickyAssignor\nProducer 消息序列化Producer 拦截器定义消息拦截器 需要实现的接口是 org.apache.kafka.clients.producerProducerInterceptor\nKafka Producer拦截器\nProducer 消息压缩kafka 支持的压缩算法  lz4 &gt;&gt; snappy &gt;&gt; gzip\nProducer 消息多线程处理实际生产环境中， 一个朱用户线程 无法满足所需的吞吐量目标，因此需要构建多个线程同时给 kafka集群发送消息。\n\n多线程 单 kafkaPrducer 实例这种方法 就是在多线程中共享一个 kafkaPrducer实例， 由于 kafkaPrducer 是线程安全的，所以这种方式也是线程安全的\n多线程 多 kafkaPrducer 实例在每个Producer 主线程中构建一个 kafkaPrducer实例， 并且保证该实例在主线程中是线程封闭(thread confinement)的。thread confinement 是保证线程安全的重要手段\n\n\n对于分区数目较少的， 使用第一种方式较为合适，多个线程共享一个kafkaProducer实例。如果分区数目超多， 使用第二种方式有较高的可控性\n","slug":"Kafka-Producer","date":"2019-07-10T10:26:01.000Z","categories_index":"kafka","tags_index":"kafak,producer","author_index":"majm"},{"id":"802c655d6d6544d494d9d5e09a52a6ba","title":"自己写一个spring-boot-start","content":"\n\n\n\n\n\n\n\n\nSpring Boot由众多Starter组成，随着版本的推移Starter家族成员也与日俱增。在传统Maven项目中通常将一些层、组件拆分为模块来管理， 以便相互依赖复用，在Spring Boot项目中我们则可以创建自定义Spring Boot Starter来达成该目的。\n\n\n1. 创建一个 maven 工程pom 文件如下\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  &lt;modelVersion>4.0.0&lt;/modelVersion>\n\n  &lt;groupId>com.majm&lt;/groupId>\n  &lt;artifactId>sample-spring-boot-starter&lt;/artifactId>\n  &lt;version>1.0.0-SNAPSHOT&lt;/version>\n  &lt;name>sample-spring-boot-starter&lt;/name>\n\n  &lt;parent>\n    &lt;groupId>org.springframework.boot&lt;/groupId>\n    &lt;artifactId>spring-boot-starter-parent&lt;/artifactId>\n    &lt;version>2.1.6.RELEASE&lt;/version>\n  &lt;/parent>\n\n  &lt;properties>\n    &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding>\n    &lt;maven.compiler.source>1.8&lt;/maven.compiler.source>\n    &lt;maven.compiler.target>1.8&lt;/maven.compiler.target>\n  &lt;/properties>\n\n  &lt;dependencies>\n\n    &lt;!-- @ConfigurationProperties annotation processing (metadata for IDEs)\n                 生成spring-configuration-metadata.json类，需要引入此类-->\n    &lt;dependency>\n      &lt;groupId>org.springframework.boot&lt;/groupId>\n      &lt;artifactId>spring-boot-configuration-processor&lt;/artifactId>\n      &lt;optional>true&lt;/optional>\n    &lt;/dependency>\n\n    &lt;dependency>\n      &lt;groupId>org.springframework.boot&lt;/groupId>\n      &lt;artifactId>spring-boot-autoconfigure&lt;/artifactId>\n    &lt;/dependency>\n    \n  &lt;/dependencies>\n&lt;/project>\n\n\n注意 依赖 spring-boot-configuration-processor 是为了在编译时生成 spring-configuration-metadata.json文件，此文件主要是给 IDE 使用，用于提示使用。example: 如在Intellij idea中，当配置此 jar 相关配置属性在application.yml,你可以用cmd + 鼠标左键，IDE会跳转到你配置此属性的类中。\n这里说一下 artifactId 命名问题， spring 官方Start 通用命名规则为 spring-boot-starter-&#123;name&#125;                              spring 官方建议非官方 start 命名规范  &#123;name&#125;-spring-boot-starter\n2.  编写 Service/**\n * 业务类 &lt;/br>\n *\n * @author majunmin\n * @description\n * @datetime 2019-07-04 17:59\n * @since\n */\n@AllArgsConstructor\npublic class ExampleService &#123;\n\n    private String name;\n\n    private String desc;\n\n    public String desc()&#123;\n        return name + \":\" + desc;\n    &#125;\n\n&#125;\n\n\n3. 编写属性类/**\n * 属性类 &lt;/br>\n *\n * @author majunmin\n * @description\n * @datetime 2019-07-04 17:53\n * @since\n */\n@Getter\n@Setter\n@ConfigurationProperties(\"com.service\")\npublic class ExampleProperties &#123;\n\n    private String name;\n\n    private String desc;\n\n&#125;\n\n4. 编写自动配置类/**\n * 自动配置类 &lt;/br>\n *\n * 1. @ConditionalOnClass，当classpath下发现该类的情况下进行自动配置。\n * 2. @ConditionalOnMissingBean，当Spring Context中不存在该Bean时。\n * 3. @ConditionalOnProperty(prefix = \"example.service\",value = \"enabled\",havingValue = \"true\")，当配置文件中example.service.enabled=true时。\n *\n * @author majunmin\n * @description\n * @datetime 2019-07-04 17:57\n * @since\n */\n@Configuration\n@ConditionalOnClass(ExampleService.class)\n@EnableConfigurationProperties(ExampleProperties.class)\npublic class ExampleAutoConfig &#123;\n\n    private final ExampleProperties exampleProperties;\n\n    @Autowired\n    public ExampleAutoConfig(ExampleProperties exampleProperties) &#123;\n        this.exampleProperties = exampleProperties;\n    &#125;\n\n\n    @Bean\n    @ConditionalOnMissingBean\n    @ConditionalOnProperty(prefix = \"example.service\", value = \"enabled\", havingValue = \"true\")\n    ExampleService exampleService()&#123;\n        return new ExampleService(exampleProperties.getName(), exampleProperties.getDesc());\n    &#125;\n\n\n&#125;\n\n\n5. 添加spring.factories在resources/META-INF/下创建 spring.factories 文件\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\n  com.majm.config.ExampleAutoConfig\n\nok 完成， 执行 mvn clean install -DskipTests,打包安装到本地\n6. Test好了 来测试一下。\n另外创建一个SpringBoot工程，在maven中引入这个starter依赖， 然后在单元测试中引入这个Service看看效果。\n\npom文件 引入依赖···xml\n \n     com.majm\n     sample-spring-boot-starter\n     1.0.0-SNAPSHOT\n \n···\n\n在 application.yml 中 添加属性\ncom.service:\n  enabled: true\n  name: aaa\n  desc: bbb\n\n编写 Controller\n@Autowired\nprivate ExampleService exampleService;\n\n@GetMapping(\"/test\")\npublic Object getUser() &#123;\n    return exampleService.desc();\n&#125;\n返回结果如下\nOK！\n总结总结下Starter的工作原理:\n\nSpring Boot在启动时扫描项目所依赖的JAR包，寻找包含 spring.factories 文件的JAR包\n根据 spring.factories 配置加载AutoConfigure类\n根据 @Conditional 注解的条件，进行自动配置并将Bean注入Spring Context\n\n代码地址Github\n","slug":"自己写一个spring-boot-start","date":"2019-07-04T11:33:13.000Z","categories_index":"spring","tags_index":"spring,springboot","author_index":"majm"},{"id":"d876370ed0a462e054a9f9f7d4c5e0de","title":"Mysql锁概念","content":"INNODB 存储引擎中的锁\n\n类型InnoDB 实现了如下两种类型的行锁：\n\n共享锁(S Lock)允许事务读取一行数据\n\n排它锁(X Lock)允许事务更新或者删除一行数据\n\n\n\n\n\n\n\n\n\n\n\n锁的兼容性如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务: 反之, 如果两者不兼容,该事务就要等待锁释放.\n排它锁和共享锁的兼容性\n\n\n\n\nX\nS\n\n\n\nX\n不兼容\n不兼容\n\n\nS\n不兼容\n兼容\n\n\nX S 锁都是行锁，兼容指的是对同一条记录(row)锁的兼容性\n此外，InnoDB存储引擎还支持多粒度(granular)锁定，这种锁定允许事务在 行级上的锁 和 表级上的锁 同时锁定。为了支持在不同粒度上的进行加锁操作，InnoDB存储引擎支持一种额外的加锁方式 意向锁(Intention Lock).意向锁将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁。\n\n意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。\n意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。\n\n表级意向锁和行级意向锁的兼容性\n\n\n\n\nIS\nIX\nS\nX\n\n\n\nIS\n兼容\n兼容\n兼容\n不兼容\n\n\nIX\n兼容\n兼容\n不兼容\n不兼容\n\n\nS\n兼容\n不兼容\n兼容\n不兼容\n\n\nX\n不兼容\n不兼容\n不兼容\n不兼容\n\n\nInnoDB 加锁方式\n意向锁是 InnoDB 自动加的， 不需用户干预。\n对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB会自动给涉及数据集加排他锁（X)；\n对于普通 SELECT 语句，InnoDB 不会加任何锁；事务可以通过以下语句显式给记录集加共享锁或排他锁：\n共享锁（S）：SELECT * FROM table_name WHERE … LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。\n排他锁（X)：SELECT * FROM table_name WHERE … FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁\n\n\n\n一致性非锁定读一致性非锁定读是InnoDB存储引擎通过多版本控制（multi versioning 的方式来读取当前执行时间数据库中的数据。如果被读的数据行被加了排他锁，在读取这行数据的时候并不会等待锁释放，而是读取该行的一个快照数据。 之所以称为非锁定读，因为不需要等待被访问行的X锁的释放。快照数据是指修改行之前的数据版本，该实现通过undo段来完成。非锁定读的方式极大提高了数据库的并发性。在InnoDB存储引擎中，这是默认的读取方式。\n快照数据其实就是当前行数据的一个历史版本，每行记录可能有多个版本。这种技术成为行多版本技术。由此带来的并发控制，称为多版本并发控制(MVCC)\n在事务的隔离级别 READ COMMITED和REPEATABLE READ *(InnoDB存储引擎默认的事物隔离级别)*下，对快照数据的定义不同。\n\n在READ COMMITTED事务隔离级别下同一事务内的一致性读均会读取到该事务中第一个读创建的快照，其他事务在之后提交或未提交的更新对当前事务的读均不可见，除非提交了该事务并开启新事务发起新查询。\n在REPEATABLE READ事务隔离级别下事务内的每个一致性读均会设置和读取自己新鲜的快照。其他事务在之后提交的更新对当前事务的读可见，未提交的更新对当前事务不可见。\n\n一致性读 是 InnoDB引擎 处理 READ COMMIT 和 REPEATABLE READ 隔离级别中 SELECT 的默认方式，不需要对 SELECT 访问的对象加锁，其他 session 中的事务可以在另一 session 中的事务读去的同时自由的修改相关对象，因此称为非锁定一致性读。\n# 查看当前数据库的 事务隔离级别\nSELECT @@tx_isolation\n\n\n起初事务的隔离级别均为REPEATABLE-READ。SESSION 读取的内容为i&#x3D;1,2,3的行，在 SESSION B 中的事务更新了 i&#x3D;3 的行后 SESSION A 查询到的内容并没有改变，即时在 SESSION B 提交了该更新后 SESSION A 仍只能看到最开始的一致性读创建的快照。但是，在 SESSION A 中的事务执行UPDATE语句更新了被 SESSION B 更新的记录后（数据库快照只适用于SELECT语句，不适用与DML语句，所以事务中的DML语句是可以看到 其他session 中的事务的更新的，即使SELECT并不能看到这些）再次执行SELECT语句不仅可以看到快照中的数据，还可以看到更新后的数据。\n上述提到的一致性读由多版本并发控制（MVCC）原理实现（利用了InnoDB的undo log）。需要注意的是，一致性读不适用于特定的DDL语句如DROP TABLE、ALTER TABLE。另外，对于 INSERT INTO … SELECT, UPDATE … (SELECT)和CREATE TABLE … SELECT 中未指定FOR UPDATE或LOCK IN SHARE MODE的SELECT默认情况下行为和READ COMMIT隔离级别下的普通SELECT一样，同一事务内设置和读取自己的新鲜快照。\n一致性锁定读锁定读。顾名思义，非锁定一致性读在某个事务读取记录时不加任何锁其他事务可以修改记录，而锁定读意味着某个事务读取记录时会加锁。锁定读分为两种类型：SELECT...FOR UPDATE 和 SELECT...LOCK IN SHARE MODE，前者会对读取的记录加X锁，阻塞其他事务的读请求和修改请求，直至事务提交释放锁资源；后者会对读取的记录加S锁，阻塞其他事务的修改请求但不会阻塞读取请求，直至事务提交释放锁资源。也正因为SELECT...FOR UPDATE 和 SELECT...LOCK IN SHARE MODE 分别需要对查询的记录加X锁和S锁，因此分别会被其他正在读写和写的事务阻塞，直到这些事务结束。需要注意的是SELECT...FOR UPDATE仅适用于autocommit=0 或者通过START TRANSACTION明确开启事务的情况。\n因为锁定读会阻塞其他事务的修改请求，因此可以有效解决非锁定一致性读中提到的”异常”，也即，一个事务执行了普通SELECT后若其他的事务更新、插入了记录并提交，那么该事务内执行DML操作更新被其他事务更新或插入的记录后再次执行SELECT操作会看到更新后的结果。(非锁定一致性读的示例)\n锁定读的一个典型应用常场景(先查询, 后更新 的操作)\n假如要往子表插入一条记录，插入前首先要确认一下父表有无相关记录，只有在父表有对应记录时插入才能满足引用完整性约束。如果使用一致性读来查询父表来验证相关行存在，此时往子表插入时 其他的session 有可能更新或者删除刚才父表中查到的行，这样在子表中插入后就违反了引用完整性约束。为了避免该问题可使用锁定读SELECT...LOCK IN SHARE MODE，在事务中读取父表进行验证时，对相关记录加S锁，这样其他事务无法对相关记录进行DML操作，此时可在事务中安全的插入相关记录，待此操作完成并提交或回滚后其他事务才能对记录进行DML操作。\n还有一种情况，比如有 两个session 需要读取某表中的一行，在成功读取后在同一事务中更新该行，并在另外的表中插入刚开始读取到的行。若此时使用SELECT...LOCK IN SHARE MODE则会对读取到的记录加S锁，两个session在同时申请X锁进行更新时便发生死锁。另外，由于读取到了同一行内容，两个session在向同一表插入数据时会导致键重复的错误。这种情况下用SELECT…FOR UPDATE较合适，在读取的时候阻塞其他事物的读和更新请求。\n\n\n[参考]（三）MySQL InnoDB非锁定一致性读与锁定读数据库第一类第二类丢失更新\n","slug":"Mysql锁概念","date":"2019-06-13T12:31:15.000Z","categories_index":"mysql,锁","tags_index":"mysql,锁","author_index":"majm"},{"id":"ce52f41a783fc1c1eec924862c197938","title":"Mysql索引原理","content":"索引\n\n\n\n\n\n\n\n\n在系统中，为了提高查询性能，这里 主要记录 InnoDB存储引擎的索引，InnoDB 支持一下几种常见的索引 B+Tree索引  全文索引  Hash索引\n\n\n为什么要有索引？索引在MySQL中也叫做 键，是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能非常关键，尤其是当表中的数据量越来越大时，索引对于性能的影响愈发重要。索引优化应该是对查询性能优化最有效的手段了。索引能够轻易将查询性能提高好几个数量级。\n索引的数据结构任何一种数据结构都不是凭空产生的，一定会有它的背景和使用场景，我们现在总结一下，我们需要这种数据结构能够做些什么，其实很简单，那就是：每次查找数据时把磁盘IO次数控制在一个很小的数量级，最好是常数数量级。那么我们就想到如果一个高度可控的多路搜索树是否能满足需求呢？ –&gt; B+树 应运而生。\n\n\n\n\n\n\n\n\n\n\n叶子节点通过双向链表进行连接\nB+Tree的查找过程\n浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。\n如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。\n\n\n\n\n\n\n\n\n\n真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高. \nB+Tree 性质\n索引字段要尽量的小(树的高度越低,IO次数就少):通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h&#x3D;㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m &#x3D; 磁盘块的大小 &#x2F; 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比 bigint 8字节少一半。这也是为什么 B+Tree 要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。\n\n索引的最左匹配特性(即从左往右匹配):当 B+Tree 的数据项是复合的数据结构，比如idx_name_age_sex(name,age,sex)的时候，B+Tree 是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，B+Tree 会优先比较 name 来确定下一步的所搜方向，如果 name 相同再依次比较 age 和 sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，B+Tree 就不知道下一步该查哪个节点，因为建立搜索树的时候 name 就是第一个比较因子，必须要先根据 name 来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，B+Tree 可以用 name 来指定搜索方向，但下一个字段 age 的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。\n\n\n索引的类型\nB+Tree 索引(innoDB 默认支持的索引)\nHash索引hash类型的索引: 查询单条快，范围查询慢B+Tree类型的索引: B+Tree,层数越多,数据量指数级增长（我们就用它，因为innodb默认支持它）\n\n#不同的存储引擎支持的索引类型也不一样\nInnoDB 支持事务，支持行级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引；\nMyISAM 不支持事务，支持表级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引；\nMemory 不支持事务，支持表级别锁定，支持 B-tree、Hash 等索引，不支持 Full-text 索引；\nNDB 支持事务，支持行级别锁定，支持 Hash 索引，不支持 B-tree、Full-text 等索引；\nArchive 不支持事务，支持表级别锁定，不支持 B-tree、Hash、Full-text 等索引；\n\n\nB+Tree 索引B+Tree 索引 是 B+Tree 在数据库中的实现，但是 B+tree 索引在数据库中有一个特点是高扇出性，因此在数据库中， B+Tree 的高度一般在 2-4 层.数据库中 B+Tree 索引一般可以分为 聚簇索引(cluster index) 和 辅助索引(secondary index),但是不管是聚簇索引 还是 辅助索引，其内部都是B+Tree， 即高度平衡的，叶子节点存放着所有的数据。 聚簇索引 与 辅助索引不同的是叶子节点存放的是一整行的数据。\n聚簇索引InnoDB 存储引擎表是索引组织表， 即表中数据按照主键顺序存放。 而聚簇索引(cluster index)就是按照每张表的主键构造一颗 B+Tree 同时叶子节点存放的是整张表的行记录数据。也将聚簇索引的叶子节点称为数据页。聚簇索引的这个特性决定了索引组织表中数据也是索引表的一部分，同 B+Tree 数据结构一样，每个数据页都通过一个双向链表进行连接。\n由于实际数据页只能按照一课B+Tree 进行排序，因此每张表只能有一个聚簇索引。 大多数情况下，查询优化器倾向于采用聚簇索引。因为聚簇索引能够在叶子节点上直接查找到数据。此外，由于定义了数据的逻辑顺序，聚簇索引能够很快的访问针对范围值的查询。查询优化器能够快速的发现这一范围的数据页需要扫描。\n辅助索引对于辅助索引(secondary Index), 叶子节点并不包含航记录的全部数据。 叶子节点除了包含键值以外，每个叶子节点的中的所银行中还包含了一个书签(bookMark)。 该 bookMark 用来告诉InnoDB 存储引擎可以在哪里找到与索引相对应的行数据。由于INnoDB存储引擎表是索引组织表，因此 InnoDB 存储引擎的辅助索引的书签就是相应的行数据的聚簇索引键。下图显示了 InnoDB中 聚簇索引 与 辅助索引的关系。\n辅助索引的存在并不影响数据在聚簇索引中的组织，因此每张表中可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶子级别的指针获得主键索引的主键，然后通过主键索引找到一个完成的行记录。假设辅助索引树高3层，聚集索引树为3层，那么根据辅助索引查找数据，需要先经过3次IO找到主键，再经过3次IO找到行做在的数据页，共6次\n联合索引本质上说 联合索引内部也是一棵B+Tree ，不同的是联合索引的键值数量不是1 而是 &gt;=2.\n最左匹配原则\n覆盖索引 (Covering index)\n\n\n\n\n\n\n\n\n即 通过辅助索引中就可以查询到记录，而不需要通过聚簇索引。使用覆盖索引的好处是辅助索引不包含整行记录的所有信息，故其大小远小于聚簇索引，因此可以减少大量的IO操作\n\n从辅助索引中直接获取记录\n对于统计操作，例如count(1)，有可能联合索引，右边也会匹配（优化器自己会做），因为count(1)操作不需要获取整行的详细数据，所以不需要去聚集索引的叶子节点去获取数据，直接在辅助索引树中就完成了操作\nselect username from xxx where username&#x3D;’lisi’，如果username是辅助索引，那么整个查询在辅助索引树上就可以完成，因为辅助索引树上虽然没有保存完整的行，但是保存着&lt;username,lisi&gt;这个key-value对；如果select username, age from xxx where username&#x3D;’lisi’，那么就要走聚集索引了\n\nHash 算法Hash 算法是一种常见的算法，时间复杂度为 O(1), 每个数据库应用中都存在这种数据库结构。\n对于可能产生的 Hash碰撞， mysql 采用链表的方式解决。\n全文检索由于 B+Tree 索引的特点， 可以通过索引字段的前缀(prefix)进行查找。\n# 如下语句 B+Tree 索引是支持的\nSELECT * FROM blog WHERE content like 'xxx%'\n\n\n\n\n\n\n\n\n\n\nMySQL5.6版本开始支持 InnoDB引擎 的全文索引，语法层面上大多数兼容之前 MyISAM s的全文索引模式。所谓全文索引，是一种通过建立倒排索引，快速匹配文档的方式。\n# 创建全文索引\ncreate table tb_name (a int auto_increment primary key, b text, fulltext(b));\n\n详细了解: InnoDB 全文索引简介\n倒排索引全文检索通常使用倒排索引(inverted index)实现。倒排索引同 B+Tree 索引一样，也是一种索引结构。他在辅助表中存储了单词与单词自身在一个或者多个文档中所在位置之间的映射。这种关联关系通过关联那数组实现。\n","slug":"Mysql索引原理","date":"2019-06-12T14:18:19.000Z","categories_index":"mysql","tags_index":"mysql,索引","author_index":"majm"},{"id":"2702307c6aa4465d038db73bd559dfd1","title":"Tomcat源码导入-IntelijIdea","content":"\n\n\n\n\n\n\n\n\n最近有兴趣阅读一下 Tomcat 源码  先把准备工作做一下， 有时间在深入阅读。  嘻嘻maven   tomcat  idea\n\n\n官网下载 Tomcat 源码包官网 我这里用到的 tomcat 版本是 8.5.41.\n项目结构\n新建一个 目录 tomcat8.5-src将源码包解压到该目录下新建文件 pom.xml新建目录 catalina-home, 然后将apache-tomcat-8.5.41-src目录下的 conf 文件夹拷贝到此处\n\n配置 maven\n\n我们采用module的形式来组织目录在 pom.xml 文件中添加内容\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>    \n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    \n        xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">    \n    \n    &lt;modelVersion>4.0.0&lt;/modelVersion>    \n    &lt;groupId>gxf&lt;/groupId>    \n    &lt;artifactId>apache-tomcat-8&lt;/artifactId>    \n    &lt;name>apache-tomcat-8-source&lt;/name>    \n    &lt;version>1.0&lt;/version>    \n    &lt;packaging>pom&lt;/packaging>    \n    \n    &lt;modules>    \n        &lt;module>apache-tomcat-8.5.41-src&lt;/module>    \n    &lt;/modules>    \n&lt;/project>\n\n这里主要指定 module 为 Tomcat 的源码目录,然后在 apache-tomcat-8.5.41-src配置 Tomcat 源码依赖，在该目录创建pom.xml\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?>    \n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"    \n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"    \n        xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">    \n    \n    \n    &lt;modelVersion>4.0.0&lt;/modelVersion>    \n    &lt;groupId>org.apache.tomcat&lt;/groupId>    \n    &lt;artifactId>Tomcat8.0&lt;/artifactId>    \n    &lt;name>Tomcat8.0&lt;/name>    \n    &lt;version>8.0&lt;/version>    \n    \n    &lt;build>    \n        &lt;finalName>Tomcat8.0&lt;/finalName>    \n        &lt;sourceDirectory>java&lt;/sourceDirectory>    \n        &lt;testSourceDirectory>test&lt;/testSourceDirectory>    \n        &lt;resources>    \n            &lt;resource>    \n                &lt;directory>java&lt;/directory>    \n            &lt;/resource>    \n        &lt;/resources>    \n        &lt;testResources>    \n            &lt;testResource>    \n                &lt;directory>test&lt;/directory>    \n            &lt;/testResource>    \n        &lt;/testResources>    \n        &lt;plugins>    \n            &lt;plugin>    \n                &lt;groupId>org.apache.maven.plugins&lt;/groupId>    \n                &lt;artifactId>maven-compiler-plugin&lt;/artifactId>    \n                &lt;version>3.5.1&lt;/version>\n                &lt;configuration>    \n                    &lt;encoding>UTF-8&lt;/encoding>    \n                    &lt;source>1.8&lt;/source>    \n                    &lt;target>1.8&lt;/target>    \n                &lt;/configuration>    \n            &lt;/plugin>\n\n            &lt;plugin>\n                &lt;groupId>org.apache.maven.plugins&lt;/groupId>\n                &lt;artifactId>maven-jar-plugin&lt;/artifactId>\n                &lt;version>2.6&lt;/version>\n            &lt;/plugin>\n        &lt;/plugins>    \n    &lt;/build>    \n    \n    &lt;dependencies>  \n        &lt;dependency>  \n            &lt;groupId>org.easymock&lt;/groupId>  \n            &lt;artifactId>easymock&lt;/artifactId>  \n            &lt;version>3.5&lt;/version>  \n            &lt;scope>test&lt;/scope>  \n        &lt;/dependency>  \n\n        &lt;dependency>    \n            &lt;groupId>junit&lt;/groupId>    \n            &lt;artifactId>junit&lt;/artifactId>    \n            &lt;version>4.12&lt;/version>  \n            &lt;scope>test&lt;/scope>    \n        &lt;/dependency>    \n        &lt;dependency>    \n            &lt;groupId>ant&lt;/groupId>    \n            &lt;artifactId>ant&lt;/artifactId>    \n            &lt;version>1.7.0&lt;/version>    \n        &lt;/dependency>    \n        &lt;dependency>    \n            &lt;groupId>wsdl4j&lt;/groupId>    \n            &lt;artifactId>wsdl4j&lt;/artifactId>    \n            &lt;version>1.6.2&lt;/version>    \n        &lt;/dependency>    \n        &lt;dependency>    \n            &lt;groupId>javax.xml&lt;/groupId>    \n            &lt;artifactId>jaxrpc&lt;/artifactId>    \n            &lt;version>1.1&lt;/version>    \n        &lt;/dependency>    \n        &lt;dependency>    \n            &lt;groupId>org.eclipse.jdt&lt;/groupId>\n            &lt;artifactId>ecj&lt;/artifactId>    \n            &lt;version>3.13.102&lt;/version>\n        &lt;/dependency>    \n    &lt;/dependencies>    \n    \n&lt;/project>\n\n到此 Tomcat 源码的基本结构已经搭建完成\n\n\n\n\n构建准备打开 Idea, 直接带开项目，定位到  tomcat8.5-src 目录\n便已配置环境，如果编译的时候 测试代码报错， 直接将 测试代码注释就好这里将 TestCookieFilter.java 注释了 \n\n\n打开项目的Run&#x2F;Debug配置界面，Main class设置为org.apache.catalina.startup.Bootstrap\n添加VM options -Dcatalina.home&#x3D;catalina-home \n-Dcatalina.base&#x3D;catalina-home \n-Djava.endorsed.dirs&#x3D;catalina-home&#x2F;endorsed \n-Djava.io.tmpdir&#x3D;catalina-home&#x2F;temp \n-Djava.util.logging.manager&#x3D;org.apache.juli.ClassLoaderLogManager \n-Djava.util.logging.config.file&#x3D;catalina-home&#x2F;conf&#x2F;logging.properties\n选择module为Tomcat8.0（源码所在的module）\n点击Debug按钮启动程序\n\n运行项目当运行项目后 访问地址 http://localhost:8080会报 NPE\n原因是我们直接启动org.apache.catalina.startup.Bootstrap的时候没有加载org.apache.jasper.servlet.JasperInitializer，从而无法编译JSP。这在Tomcat6&#x2F;7是没有这个问题的。解决办法是在tomcat的源码org.apache.catalina.startup.ContextConfig中手动将JSP解析器初始化：\ncontext.addServletContainerInitializer(new JasperInitializer(), null);\n\n至此，我们可以将项目直接放到Tomcat来启动调试了。\n\n[参考]【基于IntelliJ IDEA环境】Tomcat8源码的调试和项目部署\n","slug":"Tomcat源码导入-IntelijIdea","date":"2019-06-06T06:18:45.000Z","categories_index":"tomcat","tags_index":"maven,tomcat,idea","author_index":"majm"},{"id":"d50659b13cff259d9728e80e6b8aee70","title":"mysql查询计划查看","content":"MySql提供了EXPLAIN语法用来进行查询分析，在SQL语句前加一个”EXPLAIN”即可。比如我们要分析如下SQL语句：\nexplain select * from table where table.id = 1 \n\n\n\n运行上面的sql语句后你会看到，下面的表头信息：\n\nidQuery Optimizer 所选定的执行计划中查询的序列号。\n\nselect_type所使用的查询类型，主要有以下这几种查询类型\n\nDEPENDENT SUBQUERY：子查询中内层的第一个SELECT，依赖于外部查询的结果集。\nDEPENDENT UNION：子查询中的UNION，且为UNION 中从第二个SELECT 开始的后面所有SELECT，同样依赖于外部查询的结果集。\nPRIMARY：子查询中的最外层查询，注意并不是主键查询。\nSIMPLE：除子查询或者UNION 之外的其他查询。\nSUBQUERY：子查询内层查询的第一个SELECT，结果不依赖于外部查询结果集。\nUNCACHEABLE SUBQUERY：结果集无法缓存的子查询。\nUNION：UNION 语句中第二个SELECT 开始的后面所有SELECT，第一个SELECT 为PRIMARY\nUNION RESULT：UNION 中的合并结果。\n\n\ntable 表名\n\ntype 告诉我们对表所使用的访问方式，all 全表扫描index：全索引扫描。range：索引范围扫描。ref：Join 语句中被驱动表索引引用查询。\n从最好到最差的连接类型为system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge\n\n\n\n\n\n\n\n\n\nunique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL\n一般来说，好的sql查询至少达到range级别，最好能达到ref\n\npossible_keys  显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句\n\nkey 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MYSQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MYSQL忽略索引\n\nkey_len  使用的索引的长度。在不损失精确性的情况下，长度越短越好\n\nref  显示索引的哪一列被使用了，如果可能的话，是一个常数\n\nrows  MYSQL认为必须检查的用来返回请求数据的行数\n\nExtra 关于MYSQL如何解析查询的额外信息。 可能取值如下\n\nDistinct：查找distinct 值，所以当mysql 找到了第一条匹配的结果后，将停止该值的查询而转为后面其他值的查询。\nFull scan on NULL key：子查询中的一种优化方式，主要在遇到无法通过索引访问null值的使用使用。\nImpossible WHERE noticed after reading const tables：MySQL Query Optimizer 通过收集到的统计信息判断出不可能存在结果。\nNo tables：Query 语句中使用FROM DUAL 或者不包含任何FROM 子句。\nNot exists：在某些左连接中MySQL Query Optimizer 所通过改变原有Query 的组成而使用的优化方法，可以部分减少数据访问次数。\nRange checked for each record (index map: N)：通过MySQL 官方手册的描述，当MySQL Query Optimizer 没有发现好的可以使用的索引的时候，如果发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL 检查是否可以使用range 或index_merge 访问方法来索取行。\nSelect tables optimized away：当我们使用某些聚合函数来访问存在索引的某个字段的时候，MySQL Query Optimizer 会通过索引而直接一次定位到所需的数据行完成整个查询。当然，前提是在Query 中不能有GROUP BY 操作。如使用MIN()或者MAX（）的时候。\nUsing filesort：当我们的Query 中包含ORDER BY 操作，而且无法利用索引完成排序操作的时候，MySQL Query Optimizer 不得不选择相应的排序算法来实现。\nUsing index：所需要的数据只需要在Index 即可全部获得而不需要再到表中取数据。\nUsing index for group-by：数据访问和Using index 一样，所需数据只需要读取索引即可，而当Query 中使用了GROUP BY 或者DISTINCT 子句的时候，如果分组字段也在索引中，Extra 中的信息就会是Using index for group-by。\nUsing temporary：当MySQL 在某些操作中必须使用临时表的时候，在Extra 信息中就会出现Using temporary 。主要常见于GROUP BY 和ORDER BY 等操作中。\nUsing where：如果我们不是读取表的所有数据，或者不是仅仅通过索引就可以获取所有需要的数据，则会出现Using where 信息。\nUsing where with pushed condition：这是一个仅仅在NDBCluster 存储引擎中才会出现的信息，而且还需要通过打开Condition Pushdown 优化功能才可能会被使用。控制参数为engine_condition_pushdown 。\n\n\n\n","slug":"mysql查询计划查看","date":"2019-06-05T08:24:52.000Z","categories_index":"mysql","tags_index":"mysql,查询计划","author_index":"majm"},{"id":"bfa33a5fe2e0aa639906339c30ac4485","title":"Spring-AOP详解","content":"springDOC\n\n\n\n\n\n\n\n\n\n将重复性的逻辑代码横切出来其实很容易(我们简单可认为就是封装成一个类就好了)，但我们要将这些被我们横切出来的逻辑代码融合到业务逻辑中，来完成和之前(没抽取前)一样的功能！这就是AOP首要解决的问题了！这样一来，我们就在写业务时只关心业务代码，而不用关心与业务无关的代码\n\n\n\nSpring Aop 原理\n\n\n\n\n\n\n\n\nSpring AOP 使用纯Java实现，它不需要专门的编译过程，也不需要特殊的类装载器，它在运行期通过代理方式向目标类织入增强代码。在Spring中可以无缝地将 Spring AOP、IoC 和 AspectJ 整合在一起。Spring AOP构建在动态代理基础之上，因此，Spring对AOP的支持局限于方法拦截。\n\n  动态代理\n\nJDK 动态代理  Spring AOP默认是使用JDK动态代理，如果代理的类没有接口则会使用CGLib代理。\ncglib动态代理  CGLib代理其生成的动态代理对象是目标类的子类\n\n** JDK动态代理 和 cglib代理我们应该使用哪个？\n  如果是单例的我们最好使用 CGLib代理，如果是多例的我们最好使用JDK代理\n\n  原因: JDK在创建代理对象时的性能要高于 CGLib代理，而生成代理对象的运行性能却比CGLib的低。\n如果是单例的代理，推荐使用CGLib\n\n\nAOP 的实现\nSpring AOP 而Spring借鉴了AspectJ很多非常有用的做法，融合了AspectJ实现AOP的功能。但Spring AOP本质上底层还是动态代理，所以Spring AOP是不需要有专门的编辑器的\nAspectJ AspectJ是语言级别的AOP实现，扩展了Java语言，定义了AOP语法，能够在编译期提供横切代码的织入，所以它有专门的编译器用来生成遵守Java字节码规范的Class文件。\n\nAOP 术语\n连接点(JoinPoint)能够被拦截的地方: Spring AOP是基于动态代理的，所以是方法拦截的。每个成员方法都可以称之为连接点(JoinPoint)\n\n切点(PointCut)具体定位的连接点: 上面也说了，每个方法都可以称之为连接点(JoinPoint)，我们具体定位到某一个方法就成为 切点(PointCut)。\n\n增强(Advice)表示添加到切点的一段逻辑代码，并定位连接点(JoinPoint)的方位信息。Spring AOP提供了5种Advice类型给我们：前置(Before)、后置(After)、返回(Return)、异常(Exception)、环绕(Around)给我们使用！\n\n切面(Aspect)切面由切点(PointCut)和增强(Advice)组成，它既包括了横切逻辑的定义、也包括了连接点(JoinPoint)的定义。\n\n织入(Weaving)将增强(Advice)添加到目标类的具体连接点(JoinPoint)上的过程。\n\n\n这些概念乍一看可能有点蒙， 当AOP 用的多了以后，自然而然就理解了其中关键是: 切点(PointCut)定位的方法[连接点(JoinPoint)] 会得到 增强(Advice) 代码的织入(Weaving)\n切面类型\n\n普通切面(Pointcut)\n切点切面(PointcutAdvice)\n引介切面(IntroductionAdvisor)\n\n\n基于注解的 AOP 编程\n通配符\n\n\n\n\n\n\n\n\n在定义匹配表达式时，通配符几乎随处可见，如*、.. 、+ ，它们的含义如下：\n\n.. 匹配方法定义中的任意数量的参数，此外还匹配类定义中的任意数量包\n  //任意返回值，任意名称，任意参数的公共方法\nexecution(public * *(..))\n//匹配com.mjm.dao包及其子包中所有类中的所有方法\nwithin(com.mjm.dao..*)\n\n+ 匹配给定类的任意子类\n  //匹配实现了DaoUser接口的所有子类的方法\nwithin(com.mjm.dao.DaoUser+)\n\n* 匹配任意数量字符\n  //匹配com.mjm.service包及其子包中所有类的所有方法\nwithin(com.mjm.service..*)\n//匹配以set开头，参数为int类型，任意返回值的方法\nexecution(* set*(int))\n类型签名表达式\n\n\n\n\n\n\n\n\n\n\n为了方便类型（如接口、类名、包名）过滤方法，Spring AOP 提供了within关键字。\n语法格式如下： \n// type name 则使用包名或者类名替换\nwithin(&lt;type name>)\n\n// example\n//匹配com.mjm.dao包及其子包中所有类中的所有方法\n@Pointcut(\"within(com.mjm.dao..*)\")\n\n//匹配UserDaoImpl类中所有方法\n@Pointcut(\"within(com.mjm.dao.UserDaoImpl)\")\n\n//匹配UserDaoImpl类及其子类中所有方法\n@Pointcut(\"within(com.mjm.dao.UserDaoImpl+)\")\n\n//匹配所有实现UserDao接口的类的所有的方法\n@Pointcut(\"within(com.mjm.dao.UserDao+)\")\n\n方法签名表达式\n\n\n\n\n\n\n\n\n对方发签名进行过滤， 对于给定的作用域、返回值类型、完全限定类名以及参数匹配的方法将会应用切点函数指定的通知 execution\n语法格式如下：\n//scope ：方法作用域，如public,private,protect\n//returnt-type：方法返回值类型\n//fully-qualified-class-name：方法所在类的完全限定名称\n//parameters 方法参数\nexecution(&lt;scope> &lt;return-type> &lt;fully-qualified-class-name>.*(parameters))\n\n// example\n//匹配UserDaoImpl类中的所有方法\n@Pointcut(\"execution(* com.mjm.dao.UserDaoImpl.*(..))\")\n\n//匹配UserDaoImpl类中的所有公共的方法\n@Pointcut(\"execution(public * com.mjm.dao.UserDaoImpl.*(..))\")\n\n//匹配UserDaoImpl类中的所有公共方法并且返回值为int类型\n@Pointcut(\"execution(public int com.mjm.dao.UserDaoImpl.*(..))\")\n\n//匹配UserDaoImpl类中第一个参数为int类型的所有公共的方法\n@Pointcut(\"execution(public * com.mjm.dao.UserDaoImpl.*(int , ..))\")\n\n其他指示符// target: 用于匹配当前目标对象类型的执行方法；\n//匹配了任意实现了UserDao接口的目标对象的方法进行过滤\n@Pointcut(\"target(com.mjm.spring.springAop.dao.UserDao)\")\nprivate void myPointcut3()&#123;&#125;\n\n// @within: 用于匹配所以持有指定注解类型内的方法；请注意与within是有区别的， within是用于匹配指定类型内的方法执行；\n//匹配使用了MarkerAnnotation注解的类(注意是类)\n@Pointcut(\"@within(com.mjm.spring.annotation.MarkerAnnotation)\")\nprivate void myPointcut4()&#123;&#125;\n\n// @annotation(com.mjm.spring.MarkerMethodAnnotation) : 根据所应用的注解进行方法过滤\n//匹配使用了MarkerAnnotation注解的方法(注意是方法)\n@Pointcut(\"@annotation(com.mjm.spring.annotation.MarkerAnnotation)\")\nprivate void myPointcut5()&#123;&#125;\n\n// this : 用于匹配当前AOP代理对象类型的执行方法；请注意是AOP代理对象的类型匹配，这样就可能包括引入接口也类型匹配\n//匹配了任意实现了UserDao接口的代理对象的方法进行过滤\n@Pointcut(\"this(com.mjm.spring.springAop.dao.UserDao)\")\nprivate void myPointcut2()&#123;&#125;\n\n\n5种增强类型\n\n\n注解\n含义ßß\n\n\n\n@Before\n前置通知，在连接点方法前调用\n\n\n@Around\n环绕通知，它将覆盖原有方法，但是允许你通过反射调用原有方法，后面会讲\n\n\n@After\n后置通知，在连接点方法后调用\n\n\n@AfterReturning\n返回通知，在连接点方法执行并正常返回后调用，要求连接点方法在执行过程中没有发生异常\n\n\n@AfterThrowing\n异常通知，当连接点方法异常时调用\n\n\n\n参考关于 Spring AOP (AspectJ) 你该知晓的一切Spring AOP就是这么简单啦\n","slug":"Spring-AOP详解","date":"2019-06-04T06:51:48.000Z","categories_index":"spring","tags_index":"spring,aop,动态代理","author_index":"majm"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new \"My New Post\"\n\nMore info: Writing\n\n\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2019-04-28T10:07:13.000Z","categories_index":"","tags_index":"","author_index":"majm"},{"id":"ff81db1204df3c00c93bb459f070d6f2","title":"Apache-AB性能测试工具","content":"ApacheAB 官方Doc\n\n\n\n\n\n\n\n\n\nApache AB 性能测试工具，这是 apache 免费自带的 性能测试工具, 就在 apache bin目录下，他能模拟多个并发请求，主要用来测试你的 服务每秒能承受多少并发请求。\n\n\n命令ab -n 3000 -c 3000 http:&#x2F;&#x2F;www.test.com&#x2F;\n# -c 3000 每次发送3000 个请求\n# -n 3000 共3000 个请求\n\nab -t 60 -c 100 http:&#x2F;&#x2F;www.test.com&#x2F;\n# -t 60 在 60s内发送请求，每次发送 100 个请求\n\n\n带参数的的请求ab -t 60 -c 100 -T &quot;application&#x2F;x-www-form-urlencoded&quot; p p.txt http:&#x2F;&#x2F;www.test.com&#x2F;\n# application&#x2F;x-www-form-urlencoded (默认值)\n#  就是设置表单传输的编码,典型的post请求\n# multipart&#x2F;form-data\n#  用来指定传输数据的特殊类型的，主要就是我们上传的非文本的内容，比如图片、mp3,文件等等\n# text&#x2F;plain\n#  是纯文本传输的意思\n\n发送 json 数据ab -n 100000 -c 400 -p tempPara.txt -T application&#x2F;json http:&#x2F;&#x2F;www.test.com&#x2F;\n\n\n# tempPara.txt\n&#123;\"driverId\": 17,\"pageNo\": 1,\"pageSize\": 20,\"status\": 1&#125;\n\n常用参数说明参数说明\n-A auth-username:password\n# 对服务器提供BASIC认证信任。 \n# 用户名和密码由一个:隔开，并以base64编码形式发送。 无论服务器是否需要(即, 是否发送了401认证需求代码)，此字符串都会被发送。\n\n-c concurrency\n#  一次产生的请求个数。默认是一次一个。\n\n-n\n# 一共请求多少次\n\n-t timelimit \n# 测试所进行的最大秒数。\n# 其内部隐含值是-n 50000。 它可以使对服务器的测试限制在一个固定的总时间以内。默认时，没有时间限制。\n\n-T \n# content-type POST数据所使用的Content-type头信息。\n\n-p \n# POST-file包含了需要POST的数据的文件.\n\n结果解析This is ApacheBench, Version 2.3\nCopyright 1996 Adam Twiss, Zeus Technology Ltd, http:&#x2F;&#x2F;www.zeustech.net&#x2F;\nLicensed to The Apache Software Foundation, http:&#x2F;&#x2F;www.apache.org&#x2F;\n\nBenchmarking 192.168.80.157 (be patient)\nCompleted 400 requests\nCompleted 800 requests\nCompleted 1200 requests\nCompleted 1600 requests\nCompleted 2000 requests\nCompleted 2400 requests\nCompleted 2800 requests\nCompleted 3200 requests\nCompleted 3600 requests\nCompleted 4000 requests\nFinished 4000 requests\n\nServer Software: Apache&#x2F;2.2.15\nServer Hostname: 192.168.80.157\nServer Port: 80\n\nDocument Path: &#x2F;phpinfo.php\n#测试的页面\nDocument Length: 50797 bytes\n#页面大小\n\nConcurrency Level: 1000\n#测试的并发数\nTime taken for tests: 11.846 seconds\n#整个测试持续的时间\nComplete requests: 4000\n#完成的请求数量\nFailed requests: 0\n#失败的请求数量\nWrite errors: 0\nTotal transferred: 204586997 bytes\n#整个过程中的网络传输量\nHTML transferred: 203479961 bytes\n#整个过程中的HTML内容传输量\nRequests per second: 337.67 [#&#x2F;sec] (mean)\n#最重要的指标之一，相当于LR中的每秒事务数，后面括号中的mean表示这是一个平均值\nTime per request: 2961.449 [ms] (mean)\n#最重要的指标之二，相当于LR中的平均事务响应时间，后面括号中的mean表示这是一个平均值\nTime per request: 2.961 [ms] (mean, across all concurrent requests)\n#每个连接请求实际运行时间的平均值\nTransfer rate: 16866.07 [Kbytes&#x2F;sec] received\n#平均每秒网络上的流量，可以帮助排除是否存在网络流量过大导致响应时间延长的问题\nConnection Times (ms)\nmin mean[+&#x2F;-sd] median max\nConnect: 0 483 1773.5 11 9052\nProcessing: 2 556 1459.1 255 11763\nWaiting: 1 515 1459.8 220 11756\nTotal: 139 1039 2296.6 275 11843\n#网络上消耗的时间的分解，各项数据的具体算法还不是很清楚\n\nPercentage of the requests served within a certain time (ms)\n50% 275\n66% 298\n75% 328\n80% 373\n90% 3260\n95% 9075\n98% 9267\n99% 11713\n100% 11843 (longest request)\n#整个场景中所有请求的响应情况。在场景中每个请求都有一个响应时间，其中50％的用户响应时间小于275毫秒，66％的用户响应时间小于298毫秒，最大的响应时间小于11843毫秒。对于并发请求，cpu实际上并不是同时处理的，而是按照每个请求获得的时间片逐个轮转处理的，所以基本上第一个Time per request时间约等于第二个Time per request时间乘以并发请求数。","slug":"Apache-AB性能测试工具","date":"2019-04-28T10:03:21.000Z","categories_index":"","tags_index":"apacheAB,并发,性能测试工具","author_index":"majm"},{"id":"937bc65e7fc0650a79730217f9c7b325","title":"Kafka 入门","content":"英文文档 | 中文文档\n\n\n\n\n\n\n\n\n\nKafka 是由 LinkedIn 开发的一个分布式的消息系统，使用 Scala 编写，它以可水平扩展和高吞吐率而被广泛使用。\n\n\nMac 安装kafka# 会自动 安装会依赖zookeeper\nbrew install kafka\n\n# 启动 zookeeper\nzookeeper-server-start &#x2F;usr&#x2F;local&#x2F;etc&#x2F;kafka&#x2F;zookeeper.properties &amp;\n\n# 启动 kafka\nkafka-server-start &#x2F;usr&#x2F;local&#x2F;etc&#x2F;kafka&#x2F;server.properties &amp;\n\n#创建 topic\nkafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n\n# 查看创建的topic\nkafka-topics --list --zookeeper localhost:2181\n\n# 发送消息 输入\nkafka-console-producer --broker-list localhost:9092 --topic test\n# 在命令行输入消息并回车即可发送消息。\n# 默认每一行都是一条消息\n\n#kafka也提供了一个命令行消费者，接受消息并打印到标准输出。\nkafka-console-consume --bootstrap-server localhost:2181 --topic test --from-beginning\n\n\n配置文件位置\n&#x2F;usr&#x2F;local&#x2F;etc&#x2F;kafka&#x2F;server.properties\n&#x2F;usr&#x2F;local&#x2F;etc&#x2F;kafka&#x2F;zookeeper.properties\n\nKafka 架构BrokerKafka 集群包含一个或多个服务器，这种服务器被称为 brokerTopic 逻辑上的概念,每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）Partition 是物理上的概念，每个 Topic 包含一个或多个 Partition.Producer 负责发布消息到 Kafka brokerConsumer 消息消费者，向 Kafka broker 读取消息的客户端。Consumer Group 每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。\n\n\n\n\n\n\n\n\n\n对于传统的 message queue 而言，一般会删除已经被消费的消息，而 Kafka 集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此 Kafka 提供两种策略删除旧数据。\n\n一是基于时间，二是基于 Partition 文件大小。\n例如可以通过配置 $KAFKA_HOME&#x2F;config&#x2F;server.properties，让 Kafka 删除一周前的数据，也可在 Partition 文件超过 1GB 时删除旧数据\n\nKafka 特性\n高可用 HA\n 通过 Zookeeper, 主节点挂了，从节点进行选举\n\n负载均衡 fail over\n 通过hash 算法 将 key 路由到 不同的分区 Zookeeper允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）\n\n可扩展\n kafka集群支持 broker 水平扩展，热扩展\n\n高吞吐率,低延时\n kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。 高吞吐率 与 延时 是两个 相悖的概念，如果没2ms 处理 1条消息， 吞吐率 &#x3D; 500条消息&#x2F;s 如果采用批处理，延时8ms发送100 条消息，相当于 （8+2）ms发送了 100 条消息， 吞吐率 &#x3D; 10,000&#x2F;s\n Kafka 发送数据：\n\nkafka 收到消息 现将消息写入页缓存中，而后由操作系统将消息写入磁盘\n\nKafka不予文件系统打交道,是交由操作系统将缓存中的数据写入磁盘\n\n将数据写入磁盘采用append方式，顺序写入磁盘，效率高\n \n\n\n Kafka 消费数据： 4. kafka 消费数据 先从页缓存中读取，如果命中直接返回，不往硬盘中读取 零拷贝技术\n\n可靠性\n 消息被持久化到本地磁盘，并且支持数据备份防止数据丢失\n\n数据分区\n 消息可以被路由到不同的分区(hash 算法), 分区有 replica, 容错性\n\n消费者多线程并行消费,高并发\n 支持数千个客户端同时读写\n\n\nKafka 基本概念Message\nkey: 消息键值  分区时使用value: 消息内容timestamp: 消息发送时间戳,用于流式处理或其他依赖时间的处理语义\n属性: 1字节， 目前只是用了 最低三位 用于保存消息压缩类型，其余五位未使用。     0 无压缩  1 gzip  2 Snappy 3 LZ4\n\n为什么 kafka 消息缓存放在了页缓存,而不是放在 java 堆上\n\n\n\n\n\n\n\n\n\nJMM 中,对象内存开销相当大。 堆上的数据量越大，GC的性能会下降很多JAVA操作系统默认开启了页缓存机制，也就是说对上保存的对象很可能在页缓存中保留一份，开销大Kafka 直接使用 ByteBuffer,而不是直接使用对象，占用空间少大量使用页缓存而不是使用堆内存，当kafka broker进程崩溃时，堆上数据会消失一部分，而页缓存中的数据依然存在\n\n\ntopicTopic 是一个逻辑概念,是一个逻辑概念，我们通常用topic来区分业务，\nkafka 中的topic 会被多个消费者订阅，出于性能的考量，kafka 消息并不是 topic-message 两级结构，而是 topic-partation-message 三级结构来分散负载\ntopic 下面可以有 多个 partation, 一般 partation 数目 大于等于 3\npartationkafka 引入分区的概念 并没有太多的业务含义，而只是单纯的想提高吞吐量，因此创建kafka topic的时候， 可以根据集群配置设置具体的partation数，实现整体性最大化\npartation有自己专属的 分区号，用户唯一能对partation 的操作就是在partation尾部追加写入消息。partation 上的消息都有一个唯一的 offset.用来定位消息\noffset显然，每条消息在 partation 的位置是固定的，但消费该partation 的消费者位移随着消费进度不断前移。\n综上，topic partation offset, 我们 可以通过 &lt;topic, partation, offset&gt; 唯一确定一条消息的位置。\nreplicakafka  partation 是 有序消息日志， 那么一定不能只有一份日志。否则一旦持有该partaion的broker down了，就会造成数据丢失。 分布式系统必然要实现高可靠性。目前有效地方式–&gt; 数据冗余，也就是备份多份日志。这些备份的日志 在 kafka里称谓 replic。\n\n当某个topic的replication-factor为N且N大于1时，每个Partition都会有N个副本(Replica)。kafka的replica包含leader与follower。\nReplica的个数小于等于Broker的个数，也就是说，对于每个Partition而言，每个Broker上最多只会有一个Replica，因此可以使用Broker id 指定Partition的Replica。\n所有Partition的Replica默认情况会均匀分布到所有Broker上。\n\nleader replica 供客户端读写，follower replica 读客户端不可见，一旦 leader replica 所在 broker宕机，就从follower 中通过选举方式 选出一个 leader.\nLeader 和 followerkafka 的 replica 分为 leader 和 follower, (取代了 之前的 master slave)\nleader 负责对外提供读写 服务，follower从 leader 同步数据，充当leader的 候补\nkafka保证 同一个 topic 的 多个 partation 一定不会再 同一个 broker上。\nISRIN-SYNC Replica 与 leader replica 保持同步的 replica 集合\nkafka 承诺 只要这个集合中 至少存在一个 replica, 那些‘已提交’状态的数据就不会丢失。 两个关键点:\n\nISR 中 至少存在一个 ‘活着的’ replica\n‘已提交’的消息\n\n\nKafka 使用场景消息队列message Queue\n网络行为日志追踪重建用户行为追踪，用户对网站的点击量大，这时kafka的 超强吞吐量就有了用武之地\n审计数据收集日志收集kafka 最常用的 使用方式,日志收集 汇总 统计\nEvent Sourcing流式处理spark streaming, apache fliink, apache storm\n","slug":"Kafka-入门","date":"2019-04-28T07:08:15.000Z","categories_index":"kafka","tags_index":"kafka","author_index":"majm"},{"id":"be477fe08f671338b34bfe6576dd4bfb","title":"Spring Bean生命周期","content":"\n\n\n\n\n\n\n\n\n本篇文章记录一下Spring中,BeanFactory 与 ApplicationContext 中 bean 的生命周期过程，参考网上资料,总结如下\n\n\nBeanFactory\n\n\n当调用者调用 getBean() 想容器请求一个bean时,如果容器注册了 InstantiationAwareBeanPostProcessor(实现了BeanPostProcessor)接口,则实例化bean之前，调用该接口的 postProcessBeforeInstantiation()\n\n根据配置调用bean的构造器&#x2F;工厂方法 实例化bean\n\n如果容器注册了 InstantiationAwareBeanPostProcessor(实现了BeanPostProcessor)接口, 则实例化bean之后，调用该接口的 postProcessAfterInstantiation()\n\n如果bean配置了 属性信息， 则 这一步将属性设置到bean对应的属性中， 在设置每一个属性值之前, 调用 InstantiationAwareBeanPostProcessor 的 postProcessPropertyValues()\n\n设置属性值\n\n如果bean  实现了 BeanNameAware 接口，则  执行 setBeanName()，将xml文件里的 beanid 设置到 bean中\n\n如果bean  实现了 BeanFactoryAware 接口，则  执行 setBeanFactory()，将BeanFactory 容器实例 设置到 bean中\n\n如果 beanFactory 装配了 BeanPostProcessor 接口，则 调用 BeanPostProcessor.postProcessBeforeInitialization(Object bean, String beanName)对bean进行加工 bean: 当前增在处理的 bean  beanName: 当前bean的配置名  返回值为 加工处理后的bean\n\n\n\n\n\n\n\n\n\n\n\n要使用BeanPostProcessor回调，就必须先在容器中注册实现该接口的类，那么如何注册呢？BeanFactory和ApplicationContext容器的注册方式不大一样：若使用BeanFactory，则必须要显示的调用其addBeanPostProcessor()方法进行注册，参数为BeanPostProcessor实现类的实例；如果是使用ApplicationContext，那么容器会在配置文件在中自动寻找实现了BeanPostProcessor接口的Bean，然后自动注册，我们要做的只是配置一个BeanPostProcessor实现类的Bean就可以了。\n\n如果bean实现了 InitializingBean 接口 ，则调用 InitializingBean#afterProperiesSet\n\n如果在bean中通过init-method属性定义了初始化方法，则将执行这个方法。\n\nBeanPostProcessor 后处理利器定义了两个方法， postProcessBeforeInitialization(8 中调用)  postProcessAfterInitialization(Object bean, String beanName)此方法调用时 spring 再次获得 对bean进行加工处理的机会\n\n如果  中定义 bean 的作用范围是 scope&#x3D;’prototype’, 则将bean返回给调用者，由调用者负责bean后续生命周期管理，spring不在管理这个bean的生命周期如果  中定义 bean 的作用范围是 scope&#x3D;’singleton’,当将bean 放入SpringIOC容器的缓存池中， 并将 bean 引用返回给调用者，spring继续对 bean 进行后续的生命周期管理\n\n如果当前的bean的作用范围是singleton，且bean实现了DisposableBean接口，在容器关闭的时候，则将调用接口的destory方法。\n\n对于singleton的bean，如果bean通过destory-method属性指定了bean的销毁方法，那么在spring容器关闭的时候，就会执行该方法。\n\n\n这些方法大致可以归为四类：\nBean自身的方法：自身的方法也就是在bean中通过init-method和destory-method指定的方法。\nBean级生命周期接口方法：如BeanNameAware，BeanFactoryAware，InitializingBean和DisposableBean，这些接口方法由Bean类直接实现。\n容器级生命周期接口方法：InstantiationAwareBeanPostProcessor和BeanPostProcessor接口实现，一般称它们的实现类为“后处理器”。\n后处理器接口一般不由bean实现, 他们独立于bean, 一般以容器附加的形式注册到 spring容器中，并通过接口反射为spring容器扫描识别，\n当容器创建任何bean的时候后处理器都会发生作用。所以这些后处理器的影响是全局性的\n当然用户可以合理的编写后处理器，使其只对感兴趣的bean进行处理\n\n\n工厂处理器接口方法：包括AspectJWeavingEnabler，CustomAutowireConfigurer，ConfigurationClassPostProcessor等方法。工厂后处理器也是容器级的，在应用上下文装配文件后立即调用。\n\nApplicationContext使用ApplicationContext &amp; bean(scope&#x3D;singleton) ,name容器加载时这些bean 就会被实例化。好处是可以预先加载，缺点是耗内存如果使用的是 BeanFactory, 当实例化bean时不会直接实例化，而是等到使用(调动 getBean(String beanName))时才会实例化. BeanFactory会延迟初始化所投的的Bean. 好处是节约内存, 缺点是速度慢\n一般没有特殊要求，使用ApplicationContext. ApplicationContext 实现了 ListableBeanFactory &amp; HierarchicalBeanFactory,具有BeanFactory的所有功能， 并且还额外提供了 许多高级功能\npublic interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory,\n\t\tMessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123;\n\n&#125;\n\n\n\n提供文本解析工具，包括对国际化的支持\n提供载入资源文件的通用方法，图片\n可以向注册为监听器的Bean 发送事件\n\nApplicationContext 经常见到的三种实现    ClassPathXmlApplicationContext   从类路径中加载。    FileSystemXmlApplicationContext  从文件系统加载。    XmlWebApplicationContext         从Web系统中加载。\nApplicationContext中 bean生命周期 与 BeanFactory中 Bean生命周期类似不同得是 如果bean实现了 ApplicationContextAware 接口， 将调用 setApplicationContext()\n此外如果配置文件中配置了工厂后处理器接口,BeanFactoryPostProcessor 的实现类,则应用上下文装配完配置文件之后,初始化bean之前，会调用这些BeanFactoryPostProcessor对配置信息进行加工处理,如CustomerEditorConfigure, PropertyPlaceHolderConfigure. 如果配置了多个最好实现 Order 接口,spring可以按顺序执行他们。这些实现的作用是什么呢？工厂后处理器是容器级别的,仅在应用上下文初始化时调用一次,其目的是完成一些配置文件的加工处理工作。\nApplicationContext在启动时,将首先为配置文件中的每个bean生成BeanDefination对象，BeanDefination在spirng容器中的内部表示。当配置文件中所有的bean都被解析成BeanDefination时，ApplicationContext将调用工厂后处理器方法。因此我们有机会通过程序的方式调整bean的配置信息。\n\n\nbean的生命周期不但和其实现的接口有关，还和它的作用范围相关。\n","slug":"Spring-Bean生命周期","date":"2019-04-16T15:02:12.000Z","categories_index":"spring","tags_index":"spring,bean生命周期,ApplicationContext,BeanFactory","author_index":"majm"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"","slug":"Hello-World-0","date":"2018-12-16T12:17:14.000Z","categories_index":"test","tags_index":"test,md","author_index":"majm"}]