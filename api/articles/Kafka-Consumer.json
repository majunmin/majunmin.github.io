{"title":"Kafka-Consumer","uid":"536c69a65ba648fdf100fa15f3717346","slug":"Kafka-Consumer","date":"2019-07-17T12:22:08.000Z","updated":"2022-03-03T15:50:06.276Z","comments":true,"path":"api/articles/Kafka-Consumer.json","keywords":null,"cover":[],"content":"<p>kafka-consumer</p>\n<span id=\"more\"></span>\n\n<h2 id=\"参数配置-以及默认值\"><a href=\"#参数配置-以及默认值\" class=\"headerlink\" title=\"参数配置 以及默认值\"></a>参数配置 以及默认值</h2><p><a href=\"http://kafka.apache.org/documentation/#consumerconfigs\">参数配置以及默认值</a></p>\n<h2 id=\"Consumer-一些概念\"><a href=\"#Consumer-一些概念\" class=\"headerlink\" title=\"Consumer 一些概念\"></a>Consumer 一些概念</h2><h3 id=\"消费者-Consumer\"><a href=\"#消费者-Consumer\" class=\"headerlink\" title=\"消费者 Consumer\"></a>消费者 Consumer</h3><p>kafka 消费者，消费kafka队列里的消息，可以有多种语言实现， <code>python</code>  <code>java</code>  <code>scala</code> <code>Go</code> …,</p>\n<p><code>consumer group</code>  即是由多个独立消费者组成，消费 Topic 下的消息， 独立消费者 <code>standalong consumer</code> 执行独立的消费。</p>\n<h3 id=\"消费者组-Consuemer-group\"><a href=\"#消费者组-Consuemer-group\" class=\"headerlink\" title=\"消费者组 Consuemer group\"></a>消费者组 Consuemer group</h3><p>Kafka消费者是<code>消费组</code>的一部分，当多个消费者形成一个消费组来消费<code>主题</code>时，每个消费者会收到不同<code>分区</code>的消息。</p>\n<ul>\n<li><code>consumer group</code> 可能有若干个 <code>consumer</code> 实例</li>\n<li>对于同一个  <code>group</code> 而言， <code>topic</code> 的每一条消息只能被发送到该 <code>group</code> 下的一个 <code>consumer</code> 实例上</li>\n<li><code>topic</code> 消息可以发送到 订阅该 <code>topic</code> 的 多个 <code>group</code></li>\n</ul>\n<p>kafkaConsuemr 是非线程安全的，与 kafkaProducer 是不同的。<br>所以无法在多线程中使用同一个 kafkaConsuemr 进行消费。</p>\n<ol>\n<li>每个线程维护一个 kafkaonsumer<br>  用户创建多线程消费kafka分区数据， 每个线程中创建一个单独的 kafkaConsumer 实例。</li>\n</ol>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>为什么要使用 <code>Consumer Group</code>?<br><code>consumer Group</code> 是实现高伸缩性，高容错性的 <code>consumer</code> 机制，而且一旦某个 <code>consumer</code> 挂了，<code>cosnuemr Group</code> 会立即将已经崩溃的  <code>consumer</code> 负责的分区转交给 其他 <code>consumer</code> 负责，从而保证了整个 group 可以继续工作，不丢失数据，这个过程被称为–<code>重平衡(reblance)</code></p></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>消费顺序</strong><br>kafka 目前只保证单个分区内的消息消费顺序，而不会维护全局的消息顺序，如果用户要实现 topic 全局的消息顺序读取，就只能通过让每个 consumer group 下只包含一个 consumer 来实现。</p></blockquote>\n<p><strong>总结</strong></p>\n<ul>\n<li><code>consumer</code> 下 可以有一或者多个 <code>consumer</code> , 一个 <code>consuemr</code> 可以是一个线程，也可以是运行在其他机器上的进程</li>\n<li><code>group.id</code> 唯一标志一个 <code>consumer group</code></li>\n<li>对于某个 <code>consumer group</code> 而言，订阅 <code>topic</code> 的每个分区只能分配给订阅该 <code>consumer group</code> 下的一个 <code>consumer</code></li>\n</ul>\n<h3 id=\"offset-位移\"><a href=\"#offset-位移\" class=\"headerlink\" title=\"offset(位移)\"></a>offset(位移)</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>这里的 offset 指的是 consumer 端的位移，与分区日志中的 offset 是不同的含义</p></blockquote>\n<p>每个 consumer实例都会为它消费的分区维护属于自己的位置信息来记录当前消费了多少消息。—- offset<br>很多消息引擎都把消费端的  offset 保存在服务端(broker)， 这样做的好处当谈事实现简单，但可能会有如下三个问题：</p>\n<ol>\n<li>broker 变成了有状态，增加了同步成本，影响伸缩性</li>\n<li>需要引入应答机制(acknowledgement)，来确认消息消费成功</li>\n<li>由于需要保存很多的 consumer 的 offset故必然会引入复杂的数据结构，从而造成不必要的资源浪费</li>\n</ol>\n<p>kafka consumer 端引入了 检查点机制(checkpoint), 定期对offset 持久化，从而简化了应答机制的实现</p>\n<h4 id=\"位移提交-offset-commit\"><a href=\"#位移提交-offset-commit\" class=\"headerlink\" title=\"位移提交 (offset commit)\"></a>位移提交 (offset commit)</h4><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>consumer 客户端需要定期向 kafka 集群汇报自己的消费进度，这一过程称为 —– 位移提交.</p></blockquote>\n<p>位移提交对于 consumer 而言非常重要,它不仅表征了 consumer 的消费进度，同时也直接决定了 consuemr 端消费语义的保证.</p>\n<p>新版本 consumer 把位移提交到 Kafka 内部的一个 topic(__consumer_offset) 上。因此consumer 不在依赖 Zookeeper(位移提交这件事). 这就是为什么开发新版本 consumer 不需要配置 zookeeper 地址的原因。</p>\n<h3 id=\"consumer-offset\"><a href=\"#consumer-offset\" class=\"headerlink\" title=\"__consumer_offset\"></a>__consumer_offset</h3><p>__consumer_offset 是 kafak 一个 内部 topic, </p>\n<h3 id=\"消费者组重平衡-Consumer-group-reblance\"><a href=\"#消费者组重平衡-Consumer-group-reblance\" class=\"headerlink\" title=\"消费者组重平衡 (Consumer group reblance)\"></a>消费者组重平衡 (Consumer group reblance)</h3><p>relbance 只对 consumer group 有效。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>relbance<br>规定了一个consumer group 下的 consuemr 如何达成一致来分配订阅 topic的所有分区。</p></blockquote>\n<p>资料<br><a href=\"https://blog.csdn.net/u013256816/article/details/81123600\">Kafka分区分配策略（1）——RangeAssignor</a><br><a href=\"https://blog.csdn.net/u013256816/article/details/81123625\">Kafka分区分配策略（2）——RoundRobinAssignor和StickyAssignor</a></p>\n<h2 id=\"构建-kafka-Consumer\"><a href=\"#构建-kafka-Consumer\" class=\"headerlink\" title=\"构建 kafka Consumer\"></a>构建 kafka Consumer</h2><p>参考<br><a href=\"https://juejin.im/post/5bec10ca6fb9a049b13dc1e4\">kafka消费者Consumer参数设置及参数调优建议-kafka 商业环境实战</a></p>\n<h2 id=\"消息轮询\"><a href=\"#消息轮询\" class=\"headerlink\" title=\"消息轮询\"></a>消息轮询</h2><p>poll()</p>\n<p>Kafka Consumer是费线程安全的！如果没有显示的同步锁保护机制，kafka 会抛出 异常。<br>(将同一个kafkaConsumer 实例用在了多个线程中)</p>\n<p>kafka 的 poll() 在用户主线程中执行，，这也同时表明 消费者组执行 relbance，消息获取， coordinator 管理 异步任务结果的处理 甚至 唯一提交等操作都是运行在用户主线程中。因此仔细调优这个 poll() 相关的</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>kafka poll 为什么会有一个超时参数?</strong><br>poll()满足以下任一个条件，即可返回<br>1：获取足够多的可用数据<br>2：等待时间超过指定的超时时间。<br>目的在于让Consumer主线程定期的””苏醒”去做其他事情。比如：定期的执行常规任务，（比如写日志，写库等）。</p></blockquote>\n<h2 id=\"位移管理\"><a href=\"#位移管理\" class=\"headerlink\" title=\"位移管理\"></a>位移管理</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>kafka 要为每个他要读取的 分区保存消费进度，即分区当中的当前消费信息的位置 &#x3D;&#x3D;&gt; 位移 offset<br>consumer定期向kafak 提交自己的位置信息。</p></blockquote>\n<p>offset 对于 kafka consuemr非常重要，因为他是实现消息交语义的保证(message semantic)。常见的三种消息交付语义：</p>\n<ul>\n<li>最多一次 (at most once) 消息可能丢失,但不会重复消费</li>\n<li>最少一次 (at least once) 消息可能会重复消费，但不会丢失消息 (<strong>default</strong>)</li>\n<li>精确一次 (only once)    消息一定会被处理，且只会被处理一次</li>\n</ul>\n<h3 id=\"自动提交-与-手动提交\"><a href=\"#自动提交-与-手动提交\" class=\"headerlink\" title=\"自动提交 与 手动提交\"></a>自动提交 与 手动提交</h3><p>自动提交默认时间间隔 为 5s<br>自动提交减少了开发成本，但不能细粒度的控制处理位移的提交，特别是<strong>精确一次</strong>处理语义时，在这种情况下，用户可以使用手动提交位移。<br>通过设置 <code>auto.commit.interval.ms</code> 参数可以控制自动提交的时间间隔</p>\n<p>手动提交：<br>参数配置： <code>enable.auto.commit = false</code><br>然后调用 <code>commitSync()</code> <code>commitAsync()</code></p>\n<p><img src=\"/post/Kafka-Consumer/%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E4%B8%8E%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%AF%B9%E6%AF%94.jpg\" alt=\"自动提交与手动提交对比\"></p>\n<h2 id=\"重平衡-rebalance\"><a href=\"#重平衡-rebalance\" class=\"headerlink\" title=\"重平衡 rebalance\"></a>重平衡 rebalance</h2><p>rebalance 分区分配策略：</p>\n<ol>\n<li>range 策略</li>\n<li>round-robin 策略</li>\n<li>sticky 策略</li>\n</ol>\n<p><a href=\"https://blog.csdn.net/u013256816/article/details/81123600\">Kafka分区分配策略（1）——RangeAssignor</a><br><a href=\"https://blog.csdn.net/u013256816/article/details/81123625\">Kafka分区分配策略（2）——RoundRobinAssignor和StickyAssignor</a></p>\n<h3 id=\"rebalanc-监听器\"><a href=\"#rebalanc-监听器\" class=\"headerlink\" title=\"rebalanc 监听器\"></a>rebalanc 监听器</h3><p>新版本 consumer<br>默认提交 <code>offset</code> 到 <code>__consumer_offsets</code> 中，其实，Kafka 也支持用户把位移提交到<code>外部存储</code>中,比如数据库。如要实现这个功能，用户就必须使用 <code>rebalance 监听器</code>. 使用 rebalance 监听器的前提是用户使用 <code>consumer group</code>. 如果使用得是独立的 consumer 或是直接手动分配分区，那么 <code>rebalance 监听器</code>是无效的</p>\n<p>rebalance 监听器有一个主要的接口回调类 <code>ConsumerRebalanceListener</code>, 里面有两个方法 <code>onPartitionsRevoked()</code> <code>onPartitionAssigned()</code>.<br>在开启新一轮的 rebalance 之前 会调用 <code>onPartitionsRevoked()</code><br>rebalance 完成后   会调用 <code>onPartitionAssigned()</code></p>\n<p>rebalance 监听器常见的用法就是 手动提交位移到第三方存储以及在 rebalance 前后执行一些必要的神级操作</p>\n<h2 id=\"解序列化-deserializer\"><a href=\"#解序列化-deserializer\" class=\"headerlink\" title=\"解序列化 deserializer\"></a>解序列化 deserializer</h2>","text":"kafka-consumer 参数配置 以及默认值参数配置以及默认值 Consumer 一些概念消费者 Consumerkafka 消费者，消费kafka队列里的消息，可以有多种语言实现， python java scala Go …, consumer group 即是由多个独...","link":"","photos":[],"count_time":{"symbolsCount":"3.6k","symbolsTime":"3 mins."},"categories":[{"name":"kafka","slug":"kafka","count":4,"path":"api/categories/kafka.json"}],"tags":[{"name":"kafka","slug":"kafka","count":3,"path":"api/tags/kafka.json"},{"name":"consumer","slug":"consumer","count":1,"path":"api/tags/consumer.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE-%E4%BB%A5%E5%8F%8A%E9%BB%98%E8%AE%A4%E5%80%BC\"><span class=\"toc-text\">参数配置 以及默认值</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Consumer-%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5\"><span class=\"toc-text\">Consumer 一些概念</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B6%88%E8%B4%B9%E8%80%85-Consumer\"><span class=\"toc-text\">消费者 Consumer</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84-Consuemer-group\"><span class=\"toc-text\">消费者组 Consuemer group</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#offset-%E4%BD%8D%E7%A7%BB\"><span class=\"toc-text\">offset(位移)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4-offset-commit\"><span class=\"toc-text\">位移提交 (offset commit)</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#consumer-offset\"><span class=\"toc-text\">__consumer_offset</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1-Consumer-group-reblance\"><span class=\"toc-text\">消费者组重平衡 (Consumer group reblance)</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%9E%84%E5%BB%BA-kafka-Consumer\"><span class=\"toc-text\">构建 kafka Consumer</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%B6%88%E6%81%AF%E8%BD%AE%E8%AF%A2\"><span class=\"toc-text\">消息轮询</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BD%8D%E7%A7%BB%E7%AE%A1%E7%90%86\"><span class=\"toc-text\">位移管理</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4-%E4%B8%8E-%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4\"><span class=\"toc-text\">自动提交 与 手动提交</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%87%8D%E5%B9%B3%E8%A1%A1-rebalance\"><span class=\"toc-text\">重平衡 rebalance</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#rebalanc-%E7%9B%91%E5%90%AC%E5%99%A8\"><span class=\"toc-text\">rebalanc 监听器</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%A7%A3%E5%BA%8F%E5%88%97%E5%8C%96-deserializer\"><span class=\"toc-text\">解序列化 deserializer</span></a></li></ol>","author":{"name":"majm","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"技术分享","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Linux常用命令","uid":"596309cd0250881615133cb44c237a29","slug":"Linux常用命令","date":"2019-07-20T07:03:53.000Z","updated":"2022-10-08T10:36:09.639Z","comments":true,"path":"api/articles/Linux常用命令.json","keywords":null,"cover":[],"text":" 记录一下 CentO7 中常用的命令 命令： rpm -q package-name #检查包是否被安装 rpm -qa #列出所有安装的包 shell 脚本参数 传参数$$$ 变量 含义 $0 当前脚本的文件名 $n 传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例...","link":"","photos":[],"count_time":{"symbolsCount":"8.2k","symbolsTime":"7 mins."},"categories":[{"name":"linux","slug":"linux","count":2,"path":"api/categories/linux.json"}],"tags":[{"name":"linux","slug":"linux","count":2,"path":"api/tags/linux.json"},{"name":"centos7","slug":"centos7","count":1,"path":"api/tags/centos7.json"}],"author":{"name":"majm","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"技术分享","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Kafka-Producer","uid":"4b07e4e83f2c420c552350b44033d1ab","slug":"Kafka-Producer","date":"2019-07-10T10:26:01.000Z","updated":"2022-08-31T03:41:51.579Z","comments":true,"path":"api/articles/Kafka-Producer.json","keywords":null,"cover":[],"text":" kafka 负责向消息队列 写入消息。 kafka producer 要比 kafka consumer 简单一点，因为它不涉及复杂的组件管理，与其他的 producer 之间没有关联， 因此实现起来也比较简单。目前， kafka producer 的首要功能就是向某个 top...","link":"","photos":[],"count_time":{"symbolsCount":"5.7k","symbolsTime":"5 mins."},"categories":[{"name":"kafka","slug":"kafka","count":4,"path":"api/categories/kafka.json"}],"tags":[{"name":"kafak","slug":"kafak","count":1,"path":"api/tags/kafak.json"},{"name":"producer","slug":"producer","count":1,"path":"api/tags/producer.json"}],"author":{"name":"majm","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"技术分享","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}